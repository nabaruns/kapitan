{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Kapitan: Keep your ship together Kapitan aims to be your one-stop tool to help you manage the ever growing complexity of your configurations. Join the community #kapitan Help us grow: give us a star or even better sponsor our project Why do I need Kapitan ? I use Helm / Kustomize /that-new-kid-on-the-block Kapitan allows you to bring all your configuration needs under one home, creating a uniform way to manage your configuration that no other tool provides. Seamlessly manage configurations for Kubernetes, Terraform and any other application. Integrate with Helm (and even Kustomize). Safely store your secrets using a range of Secret Backends Longer answer Info We are working hard to update all our documentation. Please reach out if you notice something that needs improving or you have other questions or comments. Dazzle me with a demo Install Kapitan recommended Docker Linux Mac alias kapitan = \"docker run -t --rm -u $( id -u ) -v $( pwd ) :/src:delegated kapicorp/kapitan\" kapitan -h alias kapitan = \"docker run -t --rm -v $( pwd ) :/src:delegated kapicorp/kapitan\" kapitan -h Pip Install Python Linux Mac sudo apt-get update && sudo apt-get install -y python3.8-dev python3-pip python3-yaml brew install python3 libyaml libmagic Install Kapitan using pip User Linux Mac kapitan will be installed in $HOME/.local/lib/python3.7/bin pip3 install --user --upgrade kapitan kapitan will be installed in $HOME/Library/Python/3.7/bin pip3 install --user --upgrade kapitan System-wide not recommended sudo pip3 install --upgrade kapitan Related projects Tesoro - Kubernetes Admission Controller for Kapitan Secrets Kapitan Reference - our reference repository to get started with Kapitan","title":"Home"},{"location":"#kapitan-keep-your-ship-together","text":"Kapitan aims to be your one-stop tool to help you manage the ever growing complexity of your configurations. Join the community #kapitan Help us grow: give us a star or even better sponsor our project","title":" Kapitan: Keep your ship together"},{"location":"#why-do-i-need-kapitan","text":"I use Helm / Kustomize /that-new-kid-on-the-block Kapitan allows you to bring all your configuration needs under one home, creating a uniform way to manage your configuration that no other tool provides. Seamlessly manage configurations for Kubernetes, Terraform and any other application. Integrate with Helm (and even Kustomize). Safely store your secrets using a range of Secret Backends Longer answer Info We are working hard to update all our documentation. Please reach out if you notice something that needs improving or you have other questions or comments.","title":"Why do I need Kapitan?"},{"location":"#dazzle-me-with-a-demo","text":"","title":"Dazzle me with a demo"},{"location":"#install-kapitan","text":"recommended","title":"Install Kapitan"},{"location":"#docker","text":"Linux Mac alias kapitan = \"docker run -t --rm -u $( id -u ) -v $( pwd ) :/src:delegated kapicorp/kapitan\" kapitan -h alias kapitan = \"docker run -t --rm -v $( pwd ) :/src:delegated kapicorp/kapitan\" kapitan -h","title":"Docker"},{"location":"#pip","text":"","title":"Pip"},{"location":"#install-python","text":"Linux Mac sudo apt-get update && sudo apt-get install -y python3.8-dev python3-pip python3-yaml brew install python3 libyaml libmagic","title":"Install Python"},{"location":"#install-kapitan-using-pip","text":"","title":"Install Kapitan using pip"},{"location":"#user","text":"Linux Mac kapitan will be installed in $HOME/.local/lib/python3.7/bin pip3 install --user --upgrade kapitan kapitan will be installed in $HOME/Library/Python/3.7/bin pip3 install --user --upgrade kapitan","title":"User"},{"location":"#system-wide","text":"not recommended sudo pip3 install --upgrade kapitan","title":"System-wide"},{"location":"#related-projects","text":"Tesoro - Kubernetes Admission Controller for Kapitan Secrets Kapitan Reference - our reference repository to get started with Kapitan","title":"Related projects"},{"location":"FAQ/","text":"FAQ Why do I need Kapitan ? See Why do I need Kapitan ? Ask your question Please use the comments facility below to ask your question","title":"FAQ"},{"location":"FAQ/#faq","text":"","title":" FAQ"},{"location":"FAQ/#why-do-i-need-kapitan","text":"See Why do I need Kapitan ?","title":"Why do I need Kapitan?"},{"location":"FAQ/#ask-your-question","text":"Please use the comments facility below to ask your question","title":"Ask your question"},{"location":"getting_started/","text":"Kapitan Overview Setup your repository Note We are currently working on improving the experience to give you an even quicker experience with Kapitan Quickstart kapicorp/kapitan-reference repository is meant to be a way to bootstrap your Kapitan setup to get you up and running. It is meant to help you make use of best practices and libraries that can make Kapitan the ultimate tool for all your configuration needs. $ git clone git@github.com:kapicorp/kapitan-reference.git kapitan-templates $ cd kapitan-templates $ ./kapitan compile Compiled postgres-proxy (1.51s) Compiled tesoro (1.70s) Compiled echo-server (1.64s) Compiled mysql (1.67s) Compiled gke-pvm-killer (1.17s) Compiled prod-sockshop (4.74s) Compiled dev-sockshop (4.74s) Compiled tutorial (1.68s) Compiled global (0.76s) Compiled examples (2.60s) Compiled pritunl (2.03s) Compiled sock-shop (4.36s) From Scratch (Advanced) Warning the kapitan init command leaves you with a bare configuration. Setting up Kapitan might require time. Please use the Quickstart setup if you want to get started quicker. If you want to start off with a clean kapitan project, you can run kapitan init --directory <directory> to populate a new directory with the recommended kapitan folder structure. The bare minimum structure that makes use of kapitan features may look as follows: . \u251c\u2500\u2500 components \u2502 \u251c\u2500\u2500 mycomponent.jsonnet \u251c\u2500\u2500 templates \u251c\u2500\u2500 \u251c\u2500\u2500 README.md \u251c\u2500\u2500 inventory \u2502 \u251c\u2500\u2500 classes \u2502 \u2502 \u251c\u2500\u2500 common.yml \u2502 \u2514\u2500\u2500 targets \u2502 \u251c\u2500\u2500 dev.yml \u2502 \u251c\u2500\u2500 staging.yml \u2502 \u2514\u2500\u2500 prod.yml \u251c\u2500\u2500 refs \u2502 \u251c\u2500\u2500 targets \u2502 \u2502 \u251c\u2500\u2500 prod \u2502 \u2502 \u2502 \u2514\u2500\u2500 password \u2514\u2500\u2500\u2500\u251c\u2500\u2500 common \u2514\u2500\u2500 example-com-tls.key components : template files for kadet, jsonnet and helm templates : stores Jinja2 templates for scripts and documentation inventory/targets : target files inventory/classes : inventory classes to be inherited by targets refs : references files","title":"Getting started"},{"location":"getting_started/#kapitan-overview","text":"","title":" Kapitan Overview"},{"location":"getting_started/#setup-your-repository","text":"Note We are currently working on improving the experience to give you an even quicker experience with Kapitan","title":"Setup your repository"},{"location":"getting_started/#quickstart","text":"kapicorp/kapitan-reference repository is meant to be a way to bootstrap your Kapitan setup to get you up and running. It is meant to help you make use of best practices and libraries that can make Kapitan the ultimate tool for all your configuration needs. $ git clone git@github.com:kapicorp/kapitan-reference.git kapitan-templates $ cd kapitan-templates $ ./kapitan compile Compiled postgres-proxy (1.51s) Compiled tesoro (1.70s) Compiled echo-server (1.64s) Compiled mysql (1.67s) Compiled gke-pvm-killer (1.17s) Compiled prod-sockshop (4.74s) Compiled dev-sockshop (4.74s) Compiled tutorial (1.68s) Compiled global (0.76s) Compiled examples (2.60s) Compiled pritunl (2.03s) Compiled sock-shop (4.36s)","title":"Quickstart"},{"location":"getting_started/#from-scratch-advanced","text":"Warning the kapitan init command leaves you with a bare configuration. Setting up Kapitan might require time. Please use the Quickstart setup if you want to get started quicker. If you want to start off with a clean kapitan project, you can run kapitan init --directory <directory> to populate a new directory with the recommended kapitan folder structure. The bare minimum structure that makes use of kapitan features may look as follows: . \u251c\u2500\u2500 components \u2502 \u251c\u2500\u2500 mycomponent.jsonnet \u251c\u2500\u2500 templates \u251c\u2500\u2500 \u251c\u2500\u2500 README.md \u251c\u2500\u2500 inventory \u2502 \u251c\u2500\u2500 classes \u2502 \u2502 \u251c\u2500\u2500 common.yml \u2502 \u2514\u2500\u2500 targets \u2502 \u251c\u2500\u2500 dev.yml \u2502 \u251c\u2500\u2500 staging.yml \u2502 \u2514\u2500\u2500 prod.yml \u251c\u2500\u2500 refs \u2502 \u251c\u2500\u2500 targets \u2502 \u2502 \u251c\u2500\u2500 prod \u2502 \u2502 \u2502 \u2514\u2500\u2500 password \u2514\u2500\u2500\u2500\u251c\u2500\u2500 common \u2514\u2500\u2500 example-com-tls.key components : template files for kadet, jsonnet and helm templates : stores Jinja2 templates for scripts and documentation inventory/targets : target files inventory/classes : inventory classes to be inherited by targets refs : references files","title":"From Scratch (Advanced)"},{"location":"proposals/","tags":["community"],"text":"Kapitan proposals Introduction Proposals can be submitted for review by performing a pull request against this repository. If approved the proposal will be published here for further review by the Kapitan community. Proposals tend to be improvements or design consideration for new features. Existing proposals Kadet input type External dependency management Helm charts input type Kubernetes scheme validation Portable standalone Kapitan executable Ref types redesign Hashicorp vault secrets","title":"Proposals"},{"location":"proposals/#kapitan-proposals","text":"","title":" Kapitan proposals"},{"location":"proposals/#introduction","text":"Proposals can be submitted for review by performing a pull request against this repository. If approved the proposal will be published here for further review by the Kapitan community. Proposals tend to be improvements or design consideration for new features.","title":"Introduction"},{"location":"proposals/#existing-proposals","text":"Kadet input type External dependency management Helm charts input type Kubernetes scheme validation Portable standalone Kapitan executable Ref types redesign Hashicorp vault secrets","title":"Existing proposals"},{"location":"references/","text":"Kapitan References (formally Secrets ) One of the motivations behing Kapitan's design is that we believe that everything about your setup should be tracked, and Kapitan takes this to the extreme. Sometimes, however, we have to manage values that we do not think they belong to the Inventory : perhaps they are either too variable (for instance, a Git commit sha that changes with every build) or too sensitive, like a password or a generic secret, and then they should always be encrypted. Kapitan has a built in support for References , which you can use to manage both these use cases. Kapitan References supports the following backends: Backend Description Encrypted plain Plain text, (e.g. commit sha) base64 Base64, non confidential but with base64 encoding gpg Support for https://gnupg.org/ gkms GCP KMS awskms AWS KMS azkms Azure Key Vault env Environment vaultkv Hashicorp Vault (RO) vaulttransit Hashicorp Vault (encrypt, decrypt, update_key, rotate_key) Setup Some reference backends require configuration, both in the Inventory and to configure the actual backend. Get started If you want to get started with references but don't want to deal with the initial setup, you can use the plain and base64 reference types. These are great for demos, but we will see they are extremely helpful even in Production environments. Danger Both plain and base64 references do not support encryption: they are intended for development or demo purposes only. DO NOT use plain or base64 for storing sensitive information! Backend configuration Configuration for each backend varies, and it is perfomed by configuring the inventory under parameters.kapitan.secrets . plain base64 gpg gkms awskms azkms env vaultkv vaulttransit No configuration needed No configuration needed parameters : kapitan : secrets : gpg : recipients : - name : example@kapitan.dev fingerprint : D9234C61F58BEB3ED8552A57E28DC07A3CBFAE7C parameters : kapitan : secrets : gkms : key : 'projects/<project>/locations/<location>/keyRings/<keyRing>/cryptoKeys/<key>' parameters : kapitan : secrets : awskms : key : 'alias/nameOfKey' parameters : kapitan : secrets : azkms : key : 'https://<keyvault-name>.vault.azure.net/keys/<object-name>/<object-version>' parameters : ... mysql : root_password : ?{env:targets/${target_name}/mysql/root_password} ... parameters : kapitan : secrets : vaultkv : VAULT_ADDR : http://127.0.0.1:8200 auth : token parameters : kapitan : secrets : vaulttransit : VAULT_ADDR : https://vault.example.com VAULT_TOKEN : s.mqWkI0uB6So0aHH0v0jyDs97 VAULT_SKIP_VERIFY : \"False\" # Recommended auth : token mount : mytransit key : 2022-02-13-test Organize your configuration in classes Just like any other inventory parameters, these configurations can be inherited from a common class or defined per target. inventory/classes/common.yml classes : - security.backend ... inventory/classes/security/backend.yml parameters : kapitan : secrets : <backend> : <configuration> ADVANCED: Mix-and-Match backends Remember that you can use multiple backends at the same time, and also use variable interpolation for an even greater flexibility. In a multi-cloud setup, for instance, you could configure both GKMS GCP configuration inventory/classes/cloud/gcp.yml classes : - security.backends.gkms ... inventory/classes/security/backends/gkms.yml # Configuration for GCP targets parameters : backend : gkms kapitan : secrets : gkms : <configuration> AWS configuration inventory/classes/security/backends/awskms.yml # Configuration for AWS targets parameters : backend : awskms kapitan : secrets : awskms : <configuration> inventory/classes/cloud/aws.yml classes : - security.backends.awskms ... Now because they both set the parameters.backend variable, you can define a reference whose backend changes based on what class is assigned to the target inventory/targets/cloud/gcp/acme.yml classes : - cloud.aws parameters : ... mysql : # the secret backend will change based on the cloud assigned to this target root_password : ?{${backend}:targets/${target_name}/mysql/root_password} ... Define references References can be defined in the inventory following the syntax spaces added for clarity : ?{ <backend_id> : <reference_path> } expand for advanced features The syntax also supports for process functions and create_functions which we will discuss later, which brings the full syntax to ?{ <backend_id> : <reference_path> } | <process_function> || <create_function> plain base64 gpg gkms awskms azkms env vaultkv vaulttransit parameters : ... mysql : root_password : ?{plain:targets/${target_name}/mysql/root_password} ... not encrypted This reference type does not support encryption: it is intended for non sensitive data only. DO NOT use plain for storing sensitive information! parameters : ... mysql : root_password : ?{base64:targets/${target_name}/mysql/root_password} ... not encrypted This reference type does not support encryption: it is intended for non sensitive data only. DO NOT use base64 for storing sensitive information! parameters : ... mysql : root_password : ?{gpg:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{gkms:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{awskms:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{azkms:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{env:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{vaultkv:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{vaulttransit:targets/${target_name}/mysql/root_password} ... Assign a value Manually You can assign values to your reference using the command line. Both reading from a file and pipes are supported. Please Note Kapitan will fail compilation if a reference is not found. Please see how to assign a value automatically in the next section plain base64 gpg gkms awskms azkms env vaultkv vaulttransit kapitan refs --write plain:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write plain:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - kapitan refs --write base64:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write base64:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - kapitan refs --write gpg:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write gpg:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - kapitan refs --write gkms:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write gkms:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - kapitan refs --write vaulttransit:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write vaulttransit:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - kapitan refs --write azkms:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write azkms:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - Setting default value only The env backend works in a slightly different ways, as it allows you to reference environment variables at runtime. For example, for a reference called {?env:targets/envs_defaults/mysql_port_${target_name}} , Kapitan would look for an environment variable called KAPITAN_ENV_mysql_port_${TARGET_NAME} . If that variable cannot be found in the Kapitan environment, the default will be taken from the refs/targets/envs_defaults/mysql_port_${TARGET_NAME} file instead. kapitan refs --write env:refs/targets/envs_defaults/mysql_port_ ${ TARGET_NAME } -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write env:refs/targets/envs_defaults/mysql_port_ ${ TARGET_NAME } -t ${ TARGET_NAME } -f - kapitan refs --write vaultkv:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write vaultkv:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - This backend expects the value to be stored as a key:value pair. echo \"a_key:a_value\" | kapitan refs --write vaulttransit:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - When reading from disk, the input file should be formatted accordingly. Automatically Kapitan has built in capabilities to initialise its references on creation, using an elegant combination of primary and secondary functions. This is extremely powerful because it allows for you to make sure they are always initialised with sensible values. Limitations of the vaultkv backend vaultkv does not support automatical generation of secrets: Please use the manual mode primary functions To automate the creation of the reference, you can add one of the following primary functions to the reference tag by using the syntax ||primary_function:param1:param2 For instance, to automatically initialise a reference with a random string with a lenght of 32 characters, you can use the random primary function parameters : ... mysql : root_password : ?{${backend}:targets/${target_name}/mysql/root_password||random:str:32} ... Initialise non existent references The first operator here || is more similar to a logical OR . If the reference file does not exist, Kapitan will use the function to initialise it If the reference file exists, no functions will run. Automate secret rotation with ease You can take advantage of it to implement easy rotation of secrets. Simply delete the reference files, and run kapitan compile : let Kapitan do the rest. random private keys basicauth reveal str int loweralpha upperalpha loweralphanum upperalphanum special Generator function for alphanumeric characters, will be url-token-safe ?{${backend}:targets/${target_name}/mysql/root_password||random:str} generator function for digits (0-9) ?{${backend}:targets/${target_name}/mysql/root_password||random:int} generator function for lowercase letters (a-z) ?{${backend}:targets/${target_name}/mysql/root_password||random:loweralpha} generator function for uppercase letters (A-Z) ?{${backend}:targets/${target_name}/mysql/root_password||random:upperalpha} generator function for lowercase letters and numbers (a-z and 0-9) ?{${backend}:targets/${target_name}/mysql/root_password||random:loweralphanum} generator function for uppercase letters and numbers (A-Z and 0-9) ?{${backend}:targets/${target_name}/mysql/root_password||random:upperalphanum} generator function for alphanumeric characters and given special characters ?{${backend}:targets/${target_name}/mysql/root_password||random:special} rsa ed25519 publickey rsapublic Generates an RSA 4096 private key (PKCS#8). You can optionally pass the key size ?{${backend}:targets/${target_name}/private_key||rsa} Generates a ed25519 private key (PKCS#8) ?{${backend}:targets/${target_name}/private_key||ed25519} Derives the public key from a revealed private key ?{${backend}:targets/${target_name}/private_key||rsa} ?{${backend}:targets/${target_name}/public_key||reveal:targets/${target_name}/private_key|publickey} DEPRECATED: use ||publickey Generates a base64 encoded pair of username:password ?{${backend}:targets/${target_name}/apache_basicauth||basicauth:username:password} Reveals the content of another reference, useful when deriving public keys or a reference requires a different encoding or the same value. ?{${backend}:targets/${target_name}/secret||random:str} ?{${backend}:targets/${target_name}/base64_secret||reveal:targets/${target_name}/secret|base64} attention when rotating secrets used with reveal If you use reveal to initialise a reference, like my_reference||reveal:source_reference the my_reference will not be automatically updated if source_reference changes. Please make sure you also re-initialise my_reference correctly secondary functions base64 sha256 base64 encodes your reference ?{${backend}:targets/${target_name}/secret||random:str|base64} sha256 hashes your reference param1 : salt ?{${backend}:targets/${target_name}/secret||random:str|sha256} Reveal references You can reveal the secrets referenced in the outputs of kapitan compile via: kapitan refs --reveal -f path/to/rendered/template For example, compiled/minikube-mysql/manifests/mysql_secret.yml with the following content: apiVersion : v1 data : MYSQL_ROOT_PASSWORD : ?{gpg:targets/minikube-mysql/mysql/password:ec3d54de} MYSQL_ROOT_PASSWORD_SHA256 : ?{gpg:targets/minikube-mysql/mysql/password_sha256:122d2732} kind : Secret metadata : annotations : {} labels : name : example-mysql name : example-mysql namespace : minikube-mysql type : Opaque can be revealed as follows: kapitan refs --reveal -f compiled/minikube-mysql/manifests/mysql_secret.yml This will substitute the referenced secrets with the actual decrypted secrets stored at the referenced paths and display the file content. You can also use: kapitan refs --reveal --ref-file refs/targets/all-glob/mysql/password or kapitan refs --reveal --tag \"?{base64:targets/all-glob/mysql/password}\" # or kapitan refs --reveal --tag \"?{base64:targets/all-glob/mysql/password:3192c15c}\" for more convenience. Embedded refs Please refer to the CLI reference YAML SubVars References Kapitan is also able to use access specific keys in YAML content by using subvars. For instance given a reference plain:larder with content: food : apples : 1 I could now have an inventory variable like: parameters : number_of_apples : ?{plain:larder@food.apple} Using subvars to ingest yaml from command line tools Subvars can have a very practical use for storing YAML outputs coming straight from other tools. For instance, I could use the GCP gcloud command to get all the information about a cluster, and write it into a reference gcloud container clusters describe \\ --project ${ TARGET_NAME } -project \\ gke-cluster --zone europe-west1 --format yaml \\ | kapitan refs --write plain:clusters/ ${ TARGET_NAME } /cluster -t ${ TARGET_NAME } -f - knowing the output of gcloud to produce yaml that contain the following values: ... name : gke-cluster releaseChannel : channel : REGULAR selfLink : https://container.googleapis.com/v1/projects/kapicorp/locations/europe-west1/clusters/gke-cluster ... I can not reference the link to the cluster in the inventory using: parameters : cluster : name : ?{plain:clusters/${target_name}/cluster@name} release_channel : ?{plain:clusters/${target_name}/cluster@releaseChannel.channel} link : ?{plain:clusters/${target_name}/cluster@selfLink} Combined with a Jinja template, I could write automatically documentation containing the details of the clusters I use. {% set p = inventory.parameters %} # Documentation for {{p.target_name}} Cluster [{{p.cluster.name}}]({{p.cluster.link}}) has release channel {{p.cluster.release_channel}} Hashicorp Vault vaultkv Currently Kapitan supports only ReadOnly mode for this backend Considering a key-value pair like my_key : my_secret in the path secret/foo/bar in a kv-v2(KV version 2) secret engine on the vault server, to use this as a secret use: echo \"foo/bar:my_key\" | kapitan refs --write vaultkv:path/to/secret_inside_kapitan -t <target_name> -f - Parameters in the secret file are collected from the inventory of the target we gave from CLI -t <target_name> . If target isn't provided then kapitan will identify the variables from the environment when revealing secret. Environment variables that can be defined in kapitan inventory are VAULT_ADDR , VAULT_NAMESPACE , VAULT_SKIP_VERIFY , VAULT_CLIENT_CERT , VAULT_CLIENT_KEY , VAULT_CAPATH & VAULT_CACERT . Extra parameters that can be defined in inventory are: auth : specify which authentication method to use like token , userpass , ldap , github & approle mount : specify the mount point of key's path. e.g if path= alpha-secret/foo/bar then mount: alpha-secret (default secret ) engine : secret engine used, either kv-v2 or kv (default kv-v2 ) Environment variables cannot be defined in inventory are VAULT_TOKEN , VAULT_USERNAME , VAULT_PASSWORD , VAULT_ROLE_ID , VAULT_SECRET_ID . parameters : kapitan : secrets : vaultkv : auth : userpass engine : kv-v2 mount : team-alpha-secret VAULT_ADDR : http://127.0.0.1:8200 VAULT_NAMESPACE : CICD-alpha VAULT_SKIP_VERIFY : false VAULT_CLIENT_KEY : /path/to/key VAULT_CLIENT_CERT : /path/to/cert vaulttransit Considering a key-value pair like my_key : my_secret in the path secret/foo/bar in a transit secret engine on the vault server, to use this as a secret use: echo \"any.value:whatever-you_may*like\" | kapitan refs --write vaulttransit:my_target/to/secret_inside_kapitan -t <target_name> -f - Parameters in the secret file are collected from the inventory of the target we gave from CLI -t <target_name> . If target isn't provided then kapitan will identify the variables from the environment when revealing secret. Environment variables that can be defined in kapitan inventory are VAULT_ADDR , VAULT_NAMESPACE , VAULT_SKIP_VERIFY , VAULT_CLIENT_CERT , VAULT_CLIENT_KEY , VAULT_CAPATH & VAULT_CACERT . Extra parameters that can be defined in inventory are: auth : specify which authentication method to use like token , userpass , ldap , github & approle mount : specify the mount point of key's path. e.g if path= my_mount (default transit ) crypto_key : Name of the encryption key defined in vault always_latest : Always rewrap ciphertext to latest rotated crypto_key version Environment variables cannot be defined in inventory are VAULT_TOKEN , VAULT_USERNAME , VAULT_PASSWORD , VAULT_ROLE_ID , VAULT_SECRET_ID . parameters : kapitan : vars : target : my_target namespace : my_namespace secrets : vaulttransit : VAULT_ADDR : http://vault.example.com:8200 VAULT_TOKEN : s.i53a1DL83REM61UxlJKLdQDY VAULT_SKIP_VERIFY : \"True\" auth : token mount : transit crypto_key : new_key always_latest : False parameters : target_name : secrets kapitan : secrets : vaulttransit : VAULT_ADDR : http://127.0.0.1:8200 VAULT_TOKEN : s.i53a1DL83REM61UxlJKLdQDY VAULT_SKIP_VERIFY : \"True\" auth : token mount : transit crypto_key : key always_latest : False Azure KMS Secret Backend To encrypt secrets using keys stored in Azure's Key Vault, a key_id is required to identify an Azure key object uniquely. It should be of the form https://{keyvault-name}.vault.azure.net/{object-type}/{object-name}/{object-version} . Defining the KMS key This is done in the inventory under parameters.kapitan.secrets . parameters : kapitan : vars : target : ${target_name} namespace : ${target_name} secrets : azkms : key : 'https://<keyvault-name>.vault.azure.net/keys/<object-name>/<object-version>' The key can also be specified using the --key flag Creating a secret Secrets can be created using any of the methods described in the \"creating your secret\" section. For example, if the key is defined in the prod target file echo \"my_encrypted_secret\" | kapitan refs --write azkms:path/to/secret_inside_kapitan -t prod -f - Using the --key flag and a key_id echo \"my_encrypted_secret\" | kapitan refs --write azkms:path/to/secret_inside_kapitan --key = <key_id> -f - Referencing and revealing a secret Secrets can be referenced and revealed in any of the ways described above. For example, to reveal the secret stored at path/to/secret_inside_kapitan kapitan refs --reveal --tag \"?{azkms:path/to/secret_inside_kapitan}\" Note: Cryptographic algorithm used for encryption is rsa-oaep-256 .","title":"References"},{"location":"references/#kapitan-references-formally-secrets","text":"One of the motivations behing Kapitan's design is that we believe that everything about your setup should be tracked, and Kapitan takes this to the extreme. Sometimes, however, we have to manage values that we do not think they belong to the Inventory : perhaps they are either too variable (for instance, a Git commit sha that changes with every build) or too sensitive, like a password or a generic secret, and then they should always be encrypted. Kapitan has a built in support for References , which you can use to manage both these use cases. Kapitan References supports the following backends: Backend Description Encrypted plain Plain text, (e.g. commit sha) base64 Base64, non confidential but with base64 encoding gpg Support for https://gnupg.org/ gkms GCP KMS awskms AWS KMS azkms Azure Key Vault env Environment vaultkv Hashicorp Vault (RO) vaulttransit Hashicorp Vault (encrypt, decrypt, update_key, rotate_key)","title":" Kapitan References (formally Secrets)"},{"location":"references/#setup","text":"Some reference backends require configuration, both in the Inventory and to configure the actual backend. Get started If you want to get started with references but don't want to deal with the initial setup, you can use the plain and base64 reference types. These are great for demos, but we will see they are extremely helpful even in Production environments. Danger Both plain and base64 references do not support encryption: they are intended for development or demo purposes only. DO NOT use plain or base64 for storing sensitive information! Backend configuration Configuration for each backend varies, and it is perfomed by configuring the inventory under parameters.kapitan.secrets . plain base64 gpg gkms awskms azkms env vaultkv vaulttransit No configuration needed No configuration needed parameters : kapitan : secrets : gpg : recipients : - name : example@kapitan.dev fingerprint : D9234C61F58BEB3ED8552A57E28DC07A3CBFAE7C parameters : kapitan : secrets : gkms : key : 'projects/<project>/locations/<location>/keyRings/<keyRing>/cryptoKeys/<key>' parameters : kapitan : secrets : awskms : key : 'alias/nameOfKey' parameters : kapitan : secrets : azkms : key : 'https://<keyvault-name>.vault.azure.net/keys/<object-name>/<object-version>' parameters : ... mysql : root_password : ?{env:targets/${target_name}/mysql/root_password} ... parameters : kapitan : secrets : vaultkv : VAULT_ADDR : http://127.0.0.1:8200 auth : token parameters : kapitan : secrets : vaulttransit : VAULT_ADDR : https://vault.example.com VAULT_TOKEN : s.mqWkI0uB6So0aHH0v0jyDs97 VAULT_SKIP_VERIFY : \"False\" # Recommended auth : token mount : mytransit key : 2022-02-13-test Organize your configuration in classes Just like any other inventory parameters, these configurations can be inherited from a common class or defined per target. inventory/classes/common.yml classes : - security.backend ... inventory/classes/security/backend.yml parameters : kapitan : secrets : <backend> : <configuration> ADVANCED: Mix-and-Match backends Remember that you can use multiple backends at the same time, and also use variable interpolation for an even greater flexibility. In a multi-cloud setup, for instance, you could configure both GKMS GCP configuration inventory/classes/cloud/gcp.yml classes : - security.backends.gkms ... inventory/classes/security/backends/gkms.yml # Configuration for GCP targets parameters : backend : gkms kapitan : secrets : gkms : <configuration> AWS configuration inventory/classes/security/backends/awskms.yml # Configuration for AWS targets parameters : backend : awskms kapitan : secrets : awskms : <configuration> inventory/classes/cloud/aws.yml classes : - security.backends.awskms ... Now because they both set the parameters.backend variable, you can define a reference whose backend changes based on what class is assigned to the target inventory/targets/cloud/gcp/acme.yml classes : - cloud.aws parameters : ... mysql : # the secret backend will change based on the cloud assigned to this target root_password : ?{${backend}:targets/${target_name}/mysql/root_password} ...","title":"Setup"},{"location":"references/#define-references","text":"References can be defined in the inventory following the syntax spaces added for clarity : ?{ <backend_id> : <reference_path> } expand for advanced features The syntax also supports for process functions and create_functions which we will discuss later, which brings the full syntax to ?{ <backend_id> : <reference_path> } | <process_function> || <create_function> plain base64 gpg gkms awskms azkms env vaultkv vaulttransit parameters : ... mysql : root_password : ?{plain:targets/${target_name}/mysql/root_password} ... not encrypted This reference type does not support encryption: it is intended for non sensitive data only. DO NOT use plain for storing sensitive information! parameters : ... mysql : root_password : ?{base64:targets/${target_name}/mysql/root_password} ... not encrypted This reference type does not support encryption: it is intended for non sensitive data only. DO NOT use base64 for storing sensitive information! parameters : ... mysql : root_password : ?{gpg:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{gkms:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{awskms:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{azkms:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{env:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{vaultkv:targets/${target_name}/mysql/root_password} ... parameters : ... mysql : root_password : ?{vaulttransit:targets/${target_name}/mysql/root_password} ...","title":"Define references"},{"location":"references/#assign-a-value","text":"","title":"Assign a value"},{"location":"references/#manually","text":"You can assign values to your reference using the command line. Both reading from a file and pipes are supported. Please Note Kapitan will fail compilation if a reference is not found. Please see how to assign a value automatically in the next section plain base64 gpg gkms awskms azkms env vaultkv vaulttransit kapitan refs --write plain:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write plain:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - kapitan refs --write base64:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write base64:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - kapitan refs --write gpg:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write gpg:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - kapitan refs --write gkms:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write gkms:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - kapitan refs --write vaulttransit:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write vaulttransit:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - kapitan refs --write azkms:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write azkms:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - Setting default value only The env backend works in a slightly different ways, as it allows you to reference environment variables at runtime. For example, for a reference called {?env:targets/envs_defaults/mysql_port_${target_name}} , Kapitan would look for an environment variable called KAPITAN_ENV_mysql_port_${TARGET_NAME} . If that variable cannot be found in the Kapitan environment, the default will be taken from the refs/targets/envs_defaults/mysql_port_${TARGET_NAME} file instead. kapitan refs --write env:refs/targets/envs_defaults/mysql_port_ ${ TARGET_NAME } -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write env:refs/targets/envs_defaults/mysql_port_ ${ TARGET_NAME } -t ${ TARGET_NAME } -f - kapitan refs --write vaultkv:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f <input file> which also works with pipes cat input_file | kapitan refs --write vaultkv:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - This backend expects the value to be stored as a key:value pair. echo \"a_key:a_value\" | kapitan refs --write vaulttransit:refs/targets/ ${ TARGET_NAME } /mysql/root_password -t ${ TARGET_NAME } -f - When reading from disk, the input file should be formatted accordingly.","title":"Manually"},{"location":"references/#automatically","text":"Kapitan has built in capabilities to initialise its references on creation, using an elegant combination of primary and secondary functions. This is extremely powerful because it allows for you to make sure they are always initialised with sensible values. Limitations of the vaultkv backend vaultkv does not support automatical generation of secrets: Please use the manual mode","title":"Automatically"},{"location":"references/#primary-functions","text":"To automate the creation of the reference, you can add one of the following primary functions to the reference tag by using the syntax ||primary_function:param1:param2 For instance, to automatically initialise a reference with a random string with a lenght of 32 characters, you can use the random primary function parameters : ... mysql : root_password : ?{${backend}:targets/${target_name}/mysql/root_password||random:str:32} ... Initialise non existent references The first operator here || is more similar to a logical OR . If the reference file does not exist, Kapitan will use the function to initialise it If the reference file exists, no functions will run. Automate secret rotation with ease You can take advantage of it to implement easy rotation of secrets. Simply delete the reference files, and run kapitan compile : let Kapitan do the rest. random private keys basicauth reveal str int loweralpha upperalpha loweralphanum upperalphanum special Generator function for alphanumeric characters, will be url-token-safe ?{${backend}:targets/${target_name}/mysql/root_password||random:str} generator function for digits (0-9) ?{${backend}:targets/${target_name}/mysql/root_password||random:int} generator function for lowercase letters (a-z) ?{${backend}:targets/${target_name}/mysql/root_password||random:loweralpha} generator function for uppercase letters (A-Z) ?{${backend}:targets/${target_name}/mysql/root_password||random:upperalpha} generator function for lowercase letters and numbers (a-z and 0-9) ?{${backend}:targets/${target_name}/mysql/root_password||random:loweralphanum} generator function for uppercase letters and numbers (A-Z and 0-9) ?{${backend}:targets/${target_name}/mysql/root_password||random:upperalphanum} generator function for alphanumeric characters and given special characters ?{${backend}:targets/${target_name}/mysql/root_password||random:special} rsa ed25519 publickey rsapublic Generates an RSA 4096 private key (PKCS#8). You can optionally pass the key size ?{${backend}:targets/${target_name}/private_key||rsa} Generates a ed25519 private key (PKCS#8) ?{${backend}:targets/${target_name}/private_key||ed25519} Derives the public key from a revealed private key ?{${backend}:targets/${target_name}/private_key||rsa} ?{${backend}:targets/${target_name}/public_key||reveal:targets/${target_name}/private_key|publickey} DEPRECATED: use ||publickey Generates a base64 encoded pair of username:password ?{${backend}:targets/${target_name}/apache_basicauth||basicauth:username:password} Reveals the content of another reference, useful when deriving public keys or a reference requires a different encoding or the same value. ?{${backend}:targets/${target_name}/secret||random:str} ?{${backend}:targets/${target_name}/base64_secret||reveal:targets/${target_name}/secret|base64} attention when rotating secrets used with reveal If you use reveal to initialise a reference, like my_reference||reveal:source_reference the my_reference will not be automatically updated if source_reference changes. Please make sure you also re-initialise my_reference correctly","title":"primary functions"},{"location":"references/#secondary-functions","text":"base64 sha256 base64 encodes your reference ?{${backend}:targets/${target_name}/secret||random:str|base64} sha256 hashes your reference param1 : salt ?{${backend}:targets/${target_name}/secret||random:str|sha256}","title":"secondary functions"},{"location":"references/#reveal-references","text":"You can reveal the secrets referenced in the outputs of kapitan compile via: kapitan refs --reveal -f path/to/rendered/template For example, compiled/minikube-mysql/manifests/mysql_secret.yml with the following content: apiVersion : v1 data : MYSQL_ROOT_PASSWORD : ?{gpg:targets/minikube-mysql/mysql/password:ec3d54de} MYSQL_ROOT_PASSWORD_SHA256 : ?{gpg:targets/minikube-mysql/mysql/password_sha256:122d2732} kind : Secret metadata : annotations : {} labels : name : example-mysql name : example-mysql namespace : minikube-mysql type : Opaque can be revealed as follows: kapitan refs --reveal -f compiled/minikube-mysql/manifests/mysql_secret.yml This will substitute the referenced secrets with the actual decrypted secrets stored at the referenced paths and display the file content. You can also use: kapitan refs --reveal --ref-file refs/targets/all-glob/mysql/password or kapitan refs --reveal --tag \"?{base64:targets/all-glob/mysql/password}\" # or kapitan refs --reveal --tag \"?{base64:targets/all-glob/mysql/password:3192c15c}\" for more convenience.","title":"Reveal references"},{"location":"references/#embedded-refs","text":"Please refer to the CLI reference","title":"Embedded refs"},{"location":"references/#yaml-subvars-references","text":"Kapitan is also able to use access specific keys in YAML content by using subvars. For instance given a reference plain:larder with content: food : apples : 1 I could now have an inventory variable like: parameters : number_of_apples : ?{plain:larder@food.apple}","title":"YAML SubVars References"},{"location":"references/#using-subvars-to-ingest-yaml-from-command-line-tools","text":"Subvars can have a very practical use for storing YAML outputs coming straight from other tools. For instance, I could use the GCP gcloud command to get all the information about a cluster, and write it into a reference gcloud container clusters describe \\ --project ${ TARGET_NAME } -project \\ gke-cluster --zone europe-west1 --format yaml \\ | kapitan refs --write plain:clusters/ ${ TARGET_NAME } /cluster -t ${ TARGET_NAME } -f - knowing the output of gcloud to produce yaml that contain the following values: ... name : gke-cluster releaseChannel : channel : REGULAR selfLink : https://container.googleapis.com/v1/projects/kapicorp/locations/europe-west1/clusters/gke-cluster ... I can not reference the link to the cluster in the inventory using: parameters : cluster : name : ?{plain:clusters/${target_name}/cluster@name} release_channel : ?{plain:clusters/${target_name}/cluster@releaseChannel.channel} link : ?{plain:clusters/${target_name}/cluster@selfLink} Combined with a Jinja template, I could write automatically documentation containing the details of the clusters I use. {% set p = inventory.parameters %} # Documentation for {{p.target_name}} Cluster [{{p.cluster.name}}]({{p.cluster.link}}) has release channel {{p.cluster.release_channel}}","title":"Using subvars to ingest yaml from command line tools"},{"location":"references/#hashicorp-vault","text":"","title":"Hashicorp Vault"},{"location":"references/#vaultkv","text":"Currently Kapitan supports only ReadOnly mode for this backend Considering a key-value pair like my_key : my_secret in the path secret/foo/bar in a kv-v2(KV version 2) secret engine on the vault server, to use this as a secret use: echo \"foo/bar:my_key\" | kapitan refs --write vaultkv:path/to/secret_inside_kapitan -t <target_name> -f - Parameters in the secret file are collected from the inventory of the target we gave from CLI -t <target_name> . If target isn't provided then kapitan will identify the variables from the environment when revealing secret. Environment variables that can be defined in kapitan inventory are VAULT_ADDR , VAULT_NAMESPACE , VAULT_SKIP_VERIFY , VAULT_CLIENT_CERT , VAULT_CLIENT_KEY , VAULT_CAPATH & VAULT_CACERT . Extra parameters that can be defined in inventory are: auth : specify which authentication method to use like token , userpass , ldap , github & approle mount : specify the mount point of key's path. e.g if path= alpha-secret/foo/bar then mount: alpha-secret (default secret ) engine : secret engine used, either kv-v2 or kv (default kv-v2 ) Environment variables cannot be defined in inventory are VAULT_TOKEN , VAULT_USERNAME , VAULT_PASSWORD , VAULT_ROLE_ID , VAULT_SECRET_ID . parameters : kapitan : secrets : vaultkv : auth : userpass engine : kv-v2 mount : team-alpha-secret VAULT_ADDR : http://127.0.0.1:8200 VAULT_NAMESPACE : CICD-alpha VAULT_SKIP_VERIFY : false VAULT_CLIENT_KEY : /path/to/key VAULT_CLIENT_CERT : /path/to/cert","title":"vaultkv"},{"location":"references/#vaulttransit","text":"Considering a key-value pair like my_key : my_secret in the path secret/foo/bar in a transit secret engine on the vault server, to use this as a secret use: echo \"any.value:whatever-you_may*like\" | kapitan refs --write vaulttransit:my_target/to/secret_inside_kapitan -t <target_name> -f - Parameters in the secret file are collected from the inventory of the target we gave from CLI -t <target_name> . If target isn't provided then kapitan will identify the variables from the environment when revealing secret. Environment variables that can be defined in kapitan inventory are VAULT_ADDR , VAULT_NAMESPACE , VAULT_SKIP_VERIFY , VAULT_CLIENT_CERT , VAULT_CLIENT_KEY , VAULT_CAPATH & VAULT_CACERT . Extra parameters that can be defined in inventory are: auth : specify which authentication method to use like token , userpass , ldap , github & approle mount : specify the mount point of key's path. e.g if path= my_mount (default transit ) crypto_key : Name of the encryption key defined in vault always_latest : Always rewrap ciphertext to latest rotated crypto_key version Environment variables cannot be defined in inventory are VAULT_TOKEN , VAULT_USERNAME , VAULT_PASSWORD , VAULT_ROLE_ID , VAULT_SECRET_ID . parameters : kapitan : vars : target : my_target namespace : my_namespace secrets : vaulttransit : VAULT_ADDR : http://vault.example.com:8200 VAULT_TOKEN : s.i53a1DL83REM61UxlJKLdQDY VAULT_SKIP_VERIFY : \"True\" auth : token mount : transit crypto_key : new_key always_latest : False parameters : target_name : secrets kapitan : secrets : vaulttransit : VAULT_ADDR : http://127.0.0.1:8200 VAULT_TOKEN : s.i53a1DL83REM61UxlJKLdQDY VAULT_SKIP_VERIFY : \"True\" auth : token mount : transit crypto_key : key always_latest : False","title":"vaulttransit"},{"location":"references/#azure-kms-secret-backend","text":"To encrypt secrets using keys stored in Azure's Key Vault, a key_id is required to identify an Azure key object uniquely. It should be of the form https://{keyvault-name}.vault.azure.net/{object-type}/{object-name}/{object-version} .","title":"Azure KMS Secret Backend"},{"location":"references/#defining-the-kms-key","text":"This is done in the inventory under parameters.kapitan.secrets . parameters : kapitan : vars : target : ${target_name} namespace : ${target_name} secrets : azkms : key : 'https://<keyvault-name>.vault.azure.net/keys/<object-name>/<object-version>' The key can also be specified using the --key flag","title":"Defining the KMS key"},{"location":"references/#creating-a-secret","text":"Secrets can be created using any of the methods described in the \"creating your secret\" section. For example, if the key is defined in the prod target file echo \"my_encrypted_secret\" | kapitan refs --write azkms:path/to/secret_inside_kapitan -t prod -f - Using the --key flag and a key_id echo \"my_encrypted_secret\" | kapitan refs --write azkms:path/to/secret_inside_kapitan --key = <key_id> -f -","title":"Creating a secret"},{"location":"references/#referencing-and-revealing-a-secret","text":"Secrets can be referenced and revealed in any of the ways described above. For example, to reveal the secret stored at path/to/secret_inside_kapitan kapitan refs --reveal --tag \"?{azkms:path/to/secret_inside_kapitan}\" Note: Cryptographic algorithm used for encryption is rsa-oaep-256 .","title":"Referencing and revealing a secret"},{"location":"related/","text":"Related projects Tesoro - Kubernetes Admission Controller for Kapitan Secrets Kapitan Reference - Reference repository to get started sublime-jsonnet-syntax - Jsonnet syntax highlighting for Sublime Text language-jsonnet - Jsonnet syntax highlighting for Atom vim-jsonnet - Jsonnet plugin for Vim (requires a vim plugin manager)","title":"Related Projects"},{"location":"related/#related-projects","text":"Tesoro - Kubernetes Admission Controller for Kapitan Secrets Kapitan Reference - Reference repository to get started sublime-jsonnet-syntax - Jsonnet syntax highlighting for Sublime Text language-jsonnet - Jsonnet syntax highlighting for Atom vim-jsonnet - Jsonnet plugin for Vim (requires a vim plugin manager)","title":" Related projects"},{"location":"support/","text":"Get support with Kapitan Community Join us on kubernetes.slack.com #kapitan ( Get invited ) Follow us on Twitter @kapitandev . Website https://kapitan.dev Mailing List kapitan-discuss@googlegroups.com ( Subscribe ) Resources Main Blog, articles and tutorials : Kapitan Blog Generators and reference kapitan repository: Kapitan Reference Kapitan Reference : our reference repository to get started with Kapitan.","title":"Ask for support"},{"location":"support/#get-support-with-kapitan","text":"","title":" Get support with Kapitan"},{"location":"support/#community","text":"Join us on kubernetes.slack.com #kapitan ( Get invited ) Follow us on Twitter @kapitandev . Website https://kapitan.dev Mailing List kapitan-discuss@googlegroups.com ( Subscribe )","title":"Community"},{"location":"support/#resources","text":"Main Blog, articles and tutorials : Kapitan Blog Generators and reference kapitan repository: Kapitan Reference Kapitan Reference : our reference repository to get started with Kapitan.","title":"Resources"},{"location":"tags/","text":"community Proposals Kapitan Code Documentation Sponsor Us kadet Kadet kubernetes Kadet Kubernetes terraform Terraform","title":"Tags"},{"location":"tags/#community","text":"Proposals Kapitan Code Documentation Sponsor Us","title":"community"},{"location":"tags/#kadet","text":"Kadet","title":"kadet"},{"location":"tags/#kubernetes","text":"Kadet Kubernetes","title":"kubernetes"},{"location":"tags/#terraform","text":"Terraform","title":"terraform"},{"location":"kap_proposals/kap_0_kadet/","tags":["kubernetes","kadet"],"text":"Kadet This introduces a new experimental input type called Kadet. Kadet is essentially a Python module offering a set of classes and functions to define objects which will compile to JSON or YAML. A complete example is available in examples/kubernetes/components/nginx . Author: @ramaro Overview BaseObj BaseObj implements the basic object implementation that compiles into JSON or YAML. Setting keys in self.root means they will be in the compiled output. Keys can be set as an hierarchy of attributes (courtesy of addict ) The self.body() method is reserved for setting self.root on instantiation: The example below: class MyApp ( BaseObj ): def body ( self ): self . root . name = \"myapp\" self . root . inner . foo = \"bar\" self . root . list = [ 1 , 2 , 3 ] compiles into: --- name : myapp inner : foo : bar list : - 1 - 2 - 3 The self.new() method can be used to define a basic constructor. self.need() checks if a key is set and errors if it isn't (with an optional custom error message). kwargs that are passed onto a new instance of BaseObj are always accessible via self.kwargs In this example, MyApp needs name and foo to be passed as kwargs. class MyApp ( BaseObj ): def new ( self ): self . need ( \"name\" ) self . need ( \"foo\" , msg = \"please provide a value for foo\" ) def body ( self ): self . root . name = self . kwargs . name self . root . inner . foo = self . kwargs . foo self . root . list = [ 1 , 2 , 3 ] obj = MyApp ( name = \"myapp\" , foo = \"bar\" ) Setting a skeleton Defining a large body with Python can be quite hard and repetitive to read and write. The self.update_root() method allows importing a YAML/JSON file to set the skeleton of self.root. MyApp's skeleton can be set instead like this: #skel.yml --- name : myapp inner : foo : bar list : - 1 - 2 - 3 class MyApp ( BaseObj ): def new ( self ): self . need ( \"name\" ) self . need ( \"foo\" , msg = \"please provide a value for foo\" ) self . update_root ( \"path/to/skel.yml\" ) Extending a skeleton'd MyApp is possible just by implementing self.body() : class MyApp ( BaseObj ): def new ( self ): self . need ( \"name\" ) self . need ( \"foo\" , msg = \"please provide a value for foo\" ) self . update_root ( \"path/to/skel.yml\" ) def body ( self ): self . set_replicas () self . root . metadata . labels = { \"app\" : \"mylabel\" } def set_replicas ( self ): self . root . spec . replicas = 5 Inheritance Python inheritance will work as expected: class MyOtherApp ( MyApp ): def new ( self ): super () . new () # MyApp's new() self . need ( \"size\" ) def body ( self ): super () . body () # we want to extend MyApp's body self . root . size = self . kwargs . size del self . root . list # get rid of \"list\" obj = MyOtherApp ( name = \"otherapp1\" , foo = \"bar2\" , size = 3 ) compiles to: --- name : otherapp1 inner : foo : bar2 replicas : 5 size : 3 Components A component in Kadet is a python module that must implement a main() function returning an instance of BaseObj . The inventory is also available via the inventory() function. For example, a tinyapp component: # components/tinyapp/__init__.py from kapitan.inputs.kadet import BaseOBj , inventory inv = inventory () # returns inventory for target being compiled class TinyApp ( BaseObj ): def body ( self ): self . root . foo = \"bar\" self . root . replicas = inv . parameters . tinyapp . replicas def main (): obj = BaseOb () obj . root . deployment = TinyApp () # will compile into deployment.yml return obj An inventory class must be created for tinyapp : # inventory/classes/components/tinyapp.yml parameters : tinyapp : replicas : 1 kapitan : compile : - output_path : manifests input_type : kadet output_type : yaml input_paths : - components/tinyapp Common components A library in --search-paths (which now defaults to . and lib/ ) can also be a module that kadet components import. It is loaded using the load_from_search_paths() : kubelib = load_from_search_paths ( \"kubelib\" ) # lib/kubelib/__init__.py def main (): obj = BaseObj () obj . root . example_app_deployment = kubelib . Deployment ( name = \"example-app\" ) return obj","title":"Kadet"},{"location":"kap_proposals/kap_0_kadet/#kadet","text":"This introduces a new experimental input type called Kadet. Kadet is essentially a Python module offering a set of classes and functions to define objects which will compile to JSON or YAML. A complete example is available in examples/kubernetes/components/nginx . Author: @ramaro","title":"Kadet"},{"location":"kap_proposals/kap_0_kadet/#overview","text":"","title":"Overview"},{"location":"kap_proposals/kap_0_kadet/#baseobj","text":"BaseObj implements the basic object implementation that compiles into JSON or YAML. Setting keys in self.root means they will be in the compiled output. Keys can be set as an hierarchy of attributes (courtesy of addict ) The self.body() method is reserved for setting self.root on instantiation: The example below: class MyApp ( BaseObj ): def body ( self ): self . root . name = \"myapp\" self . root . inner . foo = \"bar\" self . root . list = [ 1 , 2 , 3 ] compiles into: --- name : myapp inner : foo : bar list : - 1 - 2 - 3 The self.new() method can be used to define a basic constructor. self.need() checks if a key is set and errors if it isn't (with an optional custom error message). kwargs that are passed onto a new instance of BaseObj are always accessible via self.kwargs In this example, MyApp needs name and foo to be passed as kwargs. class MyApp ( BaseObj ): def new ( self ): self . need ( \"name\" ) self . need ( \"foo\" , msg = \"please provide a value for foo\" ) def body ( self ): self . root . name = self . kwargs . name self . root . inner . foo = self . kwargs . foo self . root . list = [ 1 , 2 , 3 ] obj = MyApp ( name = \"myapp\" , foo = \"bar\" )","title":"BaseObj"},{"location":"kap_proposals/kap_0_kadet/#setting-a-skeleton","text":"Defining a large body with Python can be quite hard and repetitive to read and write. The self.update_root() method allows importing a YAML/JSON file to set the skeleton of self.root. MyApp's skeleton can be set instead like this: #skel.yml --- name : myapp inner : foo : bar list : - 1 - 2 - 3 class MyApp ( BaseObj ): def new ( self ): self . need ( \"name\" ) self . need ( \"foo\" , msg = \"please provide a value for foo\" ) self . update_root ( \"path/to/skel.yml\" ) Extending a skeleton'd MyApp is possible just by implementing self.body() : class MyApp ( BaseObj ): def new ( self ): self . need ( \"name\" ) self . need ( \"foo\" , msg = \"please provide a value for foo\" ) self . update_root ( \"path/to/skel.yml\" ) def body ( self ): self . set_replicas () self . root . metadata . labels = { \"app\" : \"mylabel\" } def set_replicas ( self ): self . root . spec . replicas = 5","title":"Setting a skeleton"},{"location":"kap_proposals/kap_0_kadet/#inheritance","text":"Python inheritance will work as expected: class MyOtherApp ( MyApp ): def new ( self ): super () . new () # MyApp's new() self . need ( \"size\" ) def body ( self ): super () . body () # we want to extend MyApp's body self . root . size = self . kwargs . size del self . root . list # get rid of \"list\" obj = MyOtherApp ( name = \"otherapp1\" , foo = \"bar2\" , size = 3 ) compiles to: --- name : otherapp1 inner : foo : bar2 replicas : 5 size : 3","title":"Inheritance"},{"location":"kap_proposals/kap_0_kadet/#components","text":"A component in Kadet is a python module that must implement a main() function returning an instance of BaseObj . The inventory is also available via the inventory() function. For example, a tinyapp component: # components/tinyapp/__init__.py from kapitan.inputs.kadet import BaseOBj , inventory inv = inventory () # returns inventory for target being compiled class TinyApp ( BaseObj ): def body ( self ): self . root . foo = \"bar\" self . root . replicas = inv . parameters . tinyapp . replicas def main (): obj = BaseOb () obj . root . deployment = TinyApp () # will compile into deployment.yml return obj An inventory class must be created for tinyapp : # inventory/classes/components/tinyapp.yml parameters : tinyapp : replicas : 1 kapitan : compile : - output_path : manifests input_type : kadet output_type : yaml input_paths : - components/tinyapp","title":"Components"},{"location":"kap_proposals/kap_0_kadet/#common-components","text":"A library in --search-paths (which now defaults to . and lib/ ) can also be a module that kadet components import. It is loaded using the load_from_search_paths() : kubelib = load_from_search_paths ( \"kubelib\" ) # lib/kubelib/__init__.py def main (): obj = BaseObj () obj . root . example_app_deployment = kubelib . Deployment ( name = \"example-app\" ) return obj","title":"Common components"},{"location":"kap_proposals/kap_10_azure_key_vault/","text":"Support for Azure Key Management This feature will enable users to encrypt secrets using keys stored in Azure's Key Vault. The azkms keyword will be used to access the azure key management backend. Specification key_id uniquely identifies an Azure key object and it's version stored in Key Vault. It is of the form https://{keyvault-name}.vault.azure.net/{object-type}/{object-name}/{object-version} . It needs to be made accessible to kapitan in one of the following ways: As a part of target parameters : kapitan : secrets : azkms : key : key_id #eg https://kapitanbackend.vault.azure.net/keys/myKey/deadbeef As a flag kapitan refs --key = <key_id> --write azkms:/path/to/secret -f file_with_secret_data.txt Using a key to encrypt a secret The following command will be used to encrypt a secret (using the specified key from Key Vault) and save it in the refs-path along with it's metadata echo \"my_treasured_secret\" | kapitan refs --write azkms:path/to/secret_inside_kapitan -t <target_name> -f - The -t <target_name> is used to get the information about key_id. Once the secret is Base64 encoded and encrypted using the key, it will be stored in path/to/secret_inside_kapitan as data : bXlfdHJlYXN1cmVkX3NlY3JldAo= encoding : original key : https://kapitanbackend.vault.azure.net/keys/myKey/deadbeef type : azkms note Cryptographic algorithm used for encryption would be rsa-oaep-256 . Optimal Asymmetric Encryption Padding (OAEP) is a padding scheme often used together with RSA encryption. referencing a secret Secrets can be refered using ?{azkms:path/to/secret_id} e.g. parameter : mysql : storage : 10G storage_class : standard image : mysql:latest users : root : password : ?{azkms:path/to/secret} Revealing a secret After compilation, the secret reference will be postfixed with 8 characters from the sha256 hash of the retrieved password/secret apiVersion : v1 data : MYSQL_ROOT_PASSWORD : ?{azkms:path/to/secret:deadbeef} kind : Secret metadata : labels : name : example-mysql name : example-mysql namespace : minikube-mysql type : Opaque To reveal the secret, the following command will be used $ kapitan ref --reveal -f compiled/file/containing/secret Dependencies azure-keyvault-keys azure-identity note Kapitan will not be responsible for authentication or access management to Azure","title":"Support for [Azure Key Management](https://docs.microsoft.com/en-us/azure/key-vault/)"},{"location":"kap_proposals/kap_10_azure_key_vault/#support-for-azure-key-management","text":"This feature will enable users to encrypt secrets using keys stored in Azure's Key Vault. The azkms keyword will be used to access the azure key management backend.","title":"Support for Azure Key Management"},{"location":"kap_proposals/kap_10_azure_key_vault/#specification","text":"key_id uniquely identifies an Azure key object and it's version stored in Key Vault. It is of the form https://{keyvault-name}.vault.azure.net/{object-type}/{object-name}/{object-version} . It needs to be made accessible to kapitan in one of the following ways: As a part of target parameters : kapitan : secrets : azkms : key : key_id #eg https://kapitanbackend.vault.azure.net/keys/myKey/deadbeef As a flag kapitan refs --key = <key_id> --write azkms:/path/to/secret -f file_with_secret_data.txt","title":"Specification"},{"location":"kap_proposals/kap_10_azure_key_vault/#using-a-key-to-encrypt-a-secret","text":"The following command will be used to encrypt a secret (using the specified key from Key Vault) and save it in the refs-path along with it's metadata echo \"my_treasured_secret\" | kapitan refs --write azkms:path/to/secret_inside_kapitan -t <target_name> -f - The -t <target_name> is used to get the information about key_id. Once the secret is Base64 encoded and encrypted using the key, it will be stored in path/to/secret_inside_kapitan as data : bXlfdHJlYXN1cmVkX3NlY3JldAo= encoding : original key : https://kapitanbackend.vault.azure.net/keys/myKey/deadbeef type : azkms note Cryptographic algorithm used for encryption would be rsa-oaep-256 . Optimal Asymmetric Encryption Padding (OAEP) is a padding scheme often used together with RSA encryption.","title":"Using a key to encrypt a secret"},{"location":"kap_proposals/kap_10_azure_key_vault/#referencing-a-secret","text":"Secrets can be refered using ?{azkms:path/to/secret_id} e.g. parameter : mysql : storage : 10G storage_class : standard image : mysql:latest users : root : password : ?{azkms:path/to/secret}","title":"referencing a secret"},{"location":"kap_proposals/kap_10_azure_key_vault/#revealing-a-secret","text":"After compilation, the secret reference will be postfixed with 8 characters from the sha256 hash of the retrieved password/secret apiVersion : v1 data : MYSQL_ROOT_PASSWORD : ?{azkms:path/to/secret:deadbeef} kind : Secret metadata : labels : name : example-mysql name : example-mysql namespace : minikube-mysql type : Opaque To reveal the secret, the following command will be used $ kapitan ref --reveal -f compiled/file/containing/secret","title":"Revealing a secret"},{"location":"kap_proposals/kap_10_azure_key_vault/#dependencies","text":"azure-keyvault-keys azure-identity note Kapitan will not be responsible for authentication or access management to Azure","title":"Dependencies"},{"location":"kap_proposals/kap_11_hashicorp_vault_transit/","text":"Hashicorp Vault Transit This feature allows the user to fetch secrets from Hashicorp Vault , with the new secret backend keyword 'vaulttransit'. Author: @xqp @Moep90 Specification The following variables need to be exported to the environment(depending on authentication used) where you will run kapitan refs --reveal in order to authenticate to your HashiCorp Vault instance: VAULT_ADDR: URL for vault VAULT_SKIP_VERIFY=true: if set, do not verify presented TLS certificate before communicating with Vault server. Setting this variable is not recommended except during testing VAULT_TOKEN: token for vault or file (~/.vault-tokens) VAULT_ROLE_ID: required by approle VAULT_SECRET_ID: required by approle VAULT_USERNAME: username to login to vault VAULT_PASSWORD: password to login to vault VAULT_CLIENT_KEY: the path to an unencrypted PEM-encoded private key matching the client certificate VAULT_CLIENT_CERT: the path to a PEM-encoded client certificate for TLS authentication to the Vault server VAULT_CACERT: the path to a PEM-encoded CA cert file to use to verify the Vault server TLS certificate VAULT_CAPATH: the path to a directory of PEM-encoded CA cert files to verify the Vault server TLS certificate VAULT_NAMESPACE: specify the Vault Namespace, if you have one Considering any stringdata like any.value:whatever-you_may*like ( in our case let\u2019s encrypt any.value:whatever-you_may*like with vault transit ) using the key 2022-02-13-test in a transit secret engine with mount mytransit on the vault server, to use this as a secret either follow: echo \"any.value:whatever-you_may*like\" > somefile.txt kapitan refs --write vaulttransit:<target_name>/to/secret_inside_kapitan --file somefile.txt --target <target_name> or in a single line echo \"any.value:whatever-you_may*like\" | kapitan refs --write vaulttransit:<target_name>/to/secret_inside_kapitan -t <target_name> -f - The entire string \"any.value:whatever-you_may*like\" will be encrypted by vault and looks like this in return: vault:v2:Jhn3UzthKcJ2s+sEiO60EUiDmuzqUC4mMBWp2Vjg/DGl+GDFEDIPmAQpc5BdIefkplb6yrJZq63xQ9s= . This then gets base64 encoded and stored in the secret_inside_kapitan. Now secret_inside_kapitan contains the following data : dmF1bHQ6djI6SmhuM1V6dGhLY0oycytzRWlPNjBFVWlEbXV6cVVDNG1NQldwMlZqZy9ER2wrR0RGRURJUG1BUXBjNUJkSWVma3BsYjZ5ckpacTYzeFE5cz0= encoding : original type : vaulttransit vault_params : VAULT_ADDR : http://127.0.0.1:8200 VAULT_SKIP_VERIFY : 'True' VAULT_TOKEN : s.i53a1DL83REM61UxlJKLdQDY auth : token crypto_key : key mount : transit always_latest : false Encoding tells the type of data given to kapitan, if it is original then after decoding base64 we'll get the original secret and if it is base64 then after decoding once we still have a base64 encoded secret and have to decode again. Parameters in the secret file are collected from the inventory of the target we gave from CLI --target my_target . If target isn't provided then kapitan will identify the variables from the environment, but providing auth is necessary as a key inside target parameters like the one shown: parameters : kapitan : vars : target : my_target namespace : my_namespace secrets : vaulttransit : VAULT_ADDR : http://vault.example.com:8200 VAULT_TOKEN : s.i53a1DL83REM61UxlJKLdQDY VAULT_SKIP_VERIFY : \"True\" auth : token mount : transit crypto_key : new_key always_latest : False Environment variables that can be defined in kapitan inventory are VAULT_ADDR , VAULT_NAMESPACE , VAULT_SKIP_VERIFY , VAULT_CLIENT_CERT , VAULT_CLIENT_KEY , VAULT_CAPATH & VAULT_CACERT . Extra parameters that can be defined in inventory are: auth : specify which authentication method to use like token , userpass , ldap , github & approle mount : specify the mount point of key's path. e.g if path= alpha-secret/foo/bar then mount: alpha-secret (default secret ) crypto_key : Name of the encryption key defined in vault always_latest : Always rewrap ciphertext to latest rotated crypto_key version Environment variables should NOT be defined in inventory are VAULT_TOKEN , VAULT_USERNAME , VAULT_PASSWORD , VAULT_ROLE_ID , VAULT_SECRET_ID . This makes the secret_inside_kapitan file accessible throughout the inventory, where we can use the secret whenever necessary like ?{vaulttransit:${target_name}/secret_inside_kapitan} Following is the example file having a secret and pointing to the vault ?{vaulttransit:${target_name}/secret_inside_kapitan} parameters : releases : app_version : latest app : image : app:app-tag release : ${releases:app_version} replicas : ${replicas} args : - --verbose=${verbose} - --password=?{vaulttransit:${target_name}/secret_inside_kapitan||random:str} when ?{vaulttransit:${target_name}/secret_inside_kapitan} is compiled, it will look same with an 8 character prefix of sha256 hash added at the end like: kind : Deployment metadata : name : app namespace : my_namespace spec : replicas : 1 template : metadata : labels : app : app spec : containers : - args : - --verbose=True - --password=?{vaulttransit:${target_name}/secret_inside_kapitan||random:str} image : app:app-tag name : app Only the user with the required tokens/permissions can reveal the secrets. Please note that the roles and permissions will be handled at the Vault level. We need not worry about it within Kapitan. Use the following command to reveal the secrets: kapitan refs --reveal -f compile/file/containing/secret Following is the result of the app-deployment.md file after Kapitan reveal. kind : Deployment metadata : name : app namespace : my_namespace spec : replicas : 1 template : metadata : labels : app : app spec : containers : - args : - --verbose=True - --password=\"any.value:whatever-you_may*like\" image : app:app-tag name : app Vault policies path \"mytransit/encrypt/2022-02-13-test\" { capabilities = [ \"create\", \"update\" ] } path \"mytransit/decrypt/2022-02-13-test\" { capabilities = [ \"create\", \"update\" ] } Dependencies hvac is a python client for Hashicorp Vault","title":"Hashicorp Vault Transit"},{"location":"kap_proposals/kap_11_hashicorp_vault_transit/#hashicorp-vault-transit","text":"This feature allows the user to fetch secrets from Hashicorp Vault , with the new secret backend keyword 'vaulttransit'. Author: @xqp @Moep90","title":"Hashicorp Vault Transit"},{"location":"kap_proposals/kap_11_hashicorp_vault_transit/#specification","text":"The following variables need to be exported to the environment(depending on authentication used) where you will run kapitan refs --reveal in order to authenticate to your HashiCorp Vault instance: VAULT_ADDR: URL for vault VAULT_SKIP_VERIFY=true: if set, do not verify presented TLS certificate before communicating with Vault server. Setting this variable is not recommended except during testing VAULT_TOKEN: token for vault or file (~/.vault-tokens) VAULT_ROLE_ID: required by approle VAULT_SECRET_ID: required by approle VAULT_USERNAME: username to login to vault VAULT_PASSWORD: password to login to vault VAULT_CLIENT_KEY: the path to an unencrypted PEM-encoded private key matching the client certificate VAULT_CLIENT_CERT: the path to a PEM-encoded client certificate for TLS authentication to the Vault server VAULT_CACERT: the path to a PEM-encoded CA cert file to use to verify the Vault server TLS certificate VAULT_CAPATH: the path to a directory of PEM-encoded CA cert files to verify the Vault server TLS certificate VAULT_NAMESPACE: specify the Vault Namespace, if you have one Considering any stringdata like any.value:whatever-you_may*like ( in our case let\u2019s encrypt any.value:whatever-you_may*like with vault transit ) using the key 2022-02-13-test in a transit secret engine with mount mytransit on the vault server, to use this as a secret either follow: echo \"any.value:whatever-you_may*like\" > somefile.txt kapitan refs --write vaulttransit:<target_name>/to/secret_inside_kapitan --file somefile.txt --target <target_name> or in a single line echo \"any.value:whatever-you_may*like\" | kapitan refs --write vaulttransit:<target_name>/to/secret_inside_kapitan -t <target_name> -f - The entire string \"any.value:whatever-you_may*like\" will be encrypted by vault and looks like this in return: vault:v2:Jhn3UzthKcJ2s+sEiO60EUiDmuzqUC4mMBWp2Vjg/DGl+GDFEDIPmAQpc5BdIefkplb6yrJZq63xQ9s= . This then gets base64 encoded and stored in the secret_inside_kapitan. Now secret_inside_kapitan contains the following data : dmF1bHQ6djI6SmhuM1V6dGhLY0oycytzRWlPNjBFVWlEbXV6cVVDNG1NQldwMlZqZy9ER2wrR0RGRURJUG1BUXBjNUJkSWVma3BsYjZ5ckpacTYzeFE5cz0= encoding : original type : vaulttransit vault_params : VAULT_ADDR : http://127.0.0.1:8200 VAULT_SKIP_VERIFY : 'True' VAULT_TOKEN : s.i53a1DL83REM61UxlJKLdQDY auth : token crypto_key : key mount : transit always_latest : false Encoding tells the type of data given to kapitan, if it is original then after decoding base64 we'll get the original secret and if it is base64 then after decoding once we still have a base64 encoded secret and have to decode again. Parameters in the secret file are collected from the inventory of the target we gave from CLI --target my_target . If target isn't provided then kapitan will identify the variables from the environment, but providing auth is necessary as a key inside target parameters like the one shown: parameters : kapitan : vars : target : my_target namespace : my_namespace secrets : vaulttransit : VAULT_ADDR : http://vault.example.com:8200 VAULT_TOKEN : s.i53a1DL83REM61UxlJKLdQDY VAULT_SKIP_VERIFY : \"True\" auth : token mount : transit crypto_key : new_key always_latest : False Environment variables that can be defined in kapitan inventory are VAULT_ADDR , VAULT_NAMESPACE , VAULT_SKIP_VERIFY , VAULT_CLIENT_CERT , VAULT_CLIENT_KEY , VAULT_CAPATH & VAULT_CACERT . Extra parameters that can be defined in inventory are: auth : specify which authentication method to use like token , userpass , ldap , github & approle mount : specify the mount point of key's path. e.g if path= alpha-secret/foo/bar then mount: alpha-secret (default secret ) crypto_key : Name of the encryption key defined in vault always_latest : Always rewrap ciphertext to latest rotated crypto_key version Environment variables should NOT be defined in inventory are VAULT_TOKEN , VAULT_USERNAME , VAULT_PASSWORD , VAULT_ROLE_ID , VAULT_SECRET_ID . This makes the secret_inside_kapitan file accessible throughout the inventory, where we can use the secret whenever necessary like ?{vaulttransit:${target_name}/secret_inside_kapitan} Following is the example file having a secret and pointing to the vault ?{vaulttransit:${target_name}/secret_inside_kapitan} parameters : releases : app_version : latest app : image : app:app-tag release : ${releases:app_version} replicas : ${replicas} args : - --verbose=${verbose} - --password=?{vaulttransit:${target_name}/secret_inside_kapitan||random:str} when ?{vaulttransit:${target_name}/secret_inside_kapitan} is compiled, it will look same with an 8 character prefix of sha256 hash added at the end like: kind : Deployment metadata : name : app namespace : my_namespace spec : replicas : 1 template : metadata : labels : app : app spec : containers : - args : - --verbose=True - --password=?{vaulttransit:${target_name}/secret_inside_kapitan||random:str} image : app:app-tag name : app Only the user with the required tokens/permissions can reveal the secrets. Please note that the roles and permissions will be handled at the Vault level. We need not worry about it within Kapitan. Use the following command to reveal the secrets: kapitan refs --reveal -f compile/file/containing/secret Following is the result of the app-deployment.md file after Kapitan reveal. kind : Deployment metadata : name : app namespace : my_namespace spec : replicas : 1 template : metadata : labels : app : app spec : containers : - args : - --verbose=True - --password=\"any.value:whatever-you_may*like\" image : app:app-tag name : app","title":"Specification"},{"location":"kap_proposals/kap_11_hashicorp_vault_transit/#vault-policies","text":"path \"mytransit/encrypt/2022-02-13-test\" { capabilities = [ \"create\", \"update\" ] } path \"mytransit/decrypt/2022-02-13-test\" { capabilities = [ \"create\", \"update\" ] }","title":"Vault policies"},{"location":"kap_proposals/kap_11_hashicorp_vault_transit/#dependencies","text":"hvac is a python client for Hashicorp Vault","title":"Dependencies"},{"location":"kap_proposals/kap_1_external_dependencies/","text":"External dependencies This features allows kapitan to fetch files from online repositories/sources during compile and store in a particular target directory. Author: @yoshi-1224 Specification Specify the files to be fetched as follows: parameters : kapitan : dependencies : - type : git | http[s] output_path : <output_path> source : <git/http[s]_url> The output path is the path to save the dependency into. For example, it could be /components/external/manifest.jsonnet . Then, the user can specify the fetched file as a kapitan.compile item along with the locally-created files. Git type may also include ref and subdir parameters as illustrated below: - type : git output_path : <output_path> source : <git_url> subdir : relative/path/in/repository ref : <commit_hash/branch/tag> force_fetch : <bool> If the file already exists at output_path , the fetch will be skipped. For fresh fetch of the dependencies, users may add --fetch option as follows: kapitan compile --fetch Users can also add the force_fetch: true option to the kapitan.dependencies in the inventory in order to force fetch of the dependencies of the target every time. Implementation details Dependencies GitPython module (and git executable) for git type requests module for http[s] (optional) tqdm for reporting download progress","title":"External dependencies"},{"location":"kap_proposals/kap_1_external_dependencies/#external-dependencies","text":"This features allows kapitan to fetch files from online repositories/sources during compile and store in a particular target directory. Author: @yoshi-1224","title":"External dependencies"},{"location":"kap_proposals/kap_1_external_dependencies/#specification","text":"Specify the files to be fetched as follows: parameters : kapitan : dependencies : - type : git | http[s] output_path : <output_path> source : <git/http[s]_url> The output path is the path to save the dependency into. For example, it could be /components/external/manifest.jsonnet . Then, the user can specify the fetched file as a kapitan.compile item along with the locally-created files. Git type may also include ref and subdir parameters as illustrated below: - type : git output_path : <output_path> source : <git_url> subdir : relative/path/in/repository ref : <commit_hash/branch/tag> force_fetch : <bool> If the file already exists at output_path , the fetch will be skipped. For fresh fetch of the dependencies, users may add --fetch option as follows: kapitan compile --fetch Users can also add the force_fetch: true option to the kapitan.dependencies in the inventory in order to force fetch of the dependencies of the target every time.","title":"Specification"},{"location":"kap_proposals/kap_1_external_dependencies/#implementation-details","text":"","title":"Implementation details"},{"location":"kap_proposals/kap_1_external_dependencies/#dependencies","text":"GitPython module (and git executable) for git type requests module for http[s] (optional) tqdm for reporting download progress","title":"Dependencies"},{"location":"kap_proposals/kap_2_helm_charts_input_type/","text":"Helm Charts Input Type This will allow kapitan, during compilation, to overwrite the values in user-specified helm charts using its inventory by calling the Go & Sprig template libraries. The helm charts can be specified via local path, and users may download the helm chart via external-dependency feature (of http[s] type). Author: @yoshi-1224 Specification This feature basically follows the helm template command available. This will run after the fetching of the external dependencies takes place, such that users can simultaneously specify the fetch as well as the import of a helm chart dependency. Semantics kapitan : compile : - input_type : helm input_path : <path_to_chart_dir> output_path : <output_path> set-file : - <optional_file_path> - ... values_file : <optional_values_file> namespace : <optional_namespace> This mostly maps to the options available to helm template command (refer to here ). Implementation details C-binding between Helm (Go) and Kapitan (Python) will be created. Helm makes use of two template libraries, namely, text/template and Sprig. The code for helm template command will be converted into shared object (.so) using CGo, which exposes C interface that kapitan (i.e. CPython) could use. The source code for helm template command is found here . This file will be modified to remove redundant options expose C-interface for Kapitan Dependencies (possibly) pybindgen","title":"Helm Charts Input Type"},{"location":"kap_proposals/kap_2_helm_charts_input_type/#helm-charts-input-type","text":"This will allow kapitan, during compilation, to overwrite the values in user-specified helm charts using its inventory by calling the Go & Sprig template libraries. The helm charts can be specified via local path, and users may download the helm chart via external-dependency feature (of http[s] type). Author: @yoshi-1224","title":"Helm Charts Input Type"},{"location":"kap_proposals/kap_2_helm_charts_input_type/#specification","text":"This feature basically follows the helm template command available. This will run after the fetching of the external dependencies takes place, such that users can simultaneously specify the fetch as well as the import of a helm chart dependency.","title":"Specification"},{"location":"kap_proposals/kap_2_helm_charts_input_type/#semantics","text":"kapitan : compile : - input_type : helm input_path : <path_to_chart_dir> output_path : <output_path> set-file : - <optional_file_path> - ... values_file : <optional_values_file> namespace : <optional_namespace> This mostly maps to the options available to helm template command (refer to here ).","title":"Semantics"},{"location":"kap_proposals/kap_2_helm_charts_input_type/#implementation-details","text":"C-binding between Helm (Go) and Kapitan (Python) will be created. Helm makes use of two template libraries, namely, text/template and Sprig. The code for helm template command will be converted into shared object (.so) using CGo, which exposes C interface that kapitan (i.e. CPython) could use. The source code for helm template command is found here . This file will be modified to remove redundant options expose C-interface for Kapitan","title":"Implementation details"},{"location":"kap_proposals/kap_2_helm_charts_input_type/#dependencies","text":"(possibly) pybindgen","title":"Dependencies"},{"location":"kap_proposals/kap_3_schema_validation/","text":"Schema Validation (for k8s) If a yaml/json output is to be used as k8s manifest, users may specify its kind and have kapitan validate its structure during kapitan compile . The plan is to have this validation feature extendable to other outputs as well, such as terraform. Author: @yoshi-1224 Specification The following inventory will validate the structure of Kubernetes Service manifest file in . parameters : kapitan : validate : - output_type : kubernetes.service version : 1.6.6 output_path : relative/path/in/target version parameter is optional: if omitted, the version will be set to the stable release of kubernetes (tbc). Implementation The schemas will be downloaded by requests from this repository . Caching of schema will also be implemented. Dependencies jsonschema to validate the output yaml/json against the correct schema","title":"Schema Validation (for k8s)"},{"location":"kap_proposals/kap_3_schema_validation/#schema-validation-for-k8s","text":"If a yaml/json output is to be used as k8s manifest, users may specify its kind and have kapitan validate its structure during kapitan compile . The plan is to have this validation feature extendable to other outputs as well, such as terraform. Author: @yoshi-1224","title":"Schema Validation (for k8s)"},{"location":"kap_proposals/kap_3_schema_validation/#specification","text":"The following inventory will validate the structure of Kubernetes Service manifest file in . parameters : kapitan : validate : - output_type : kubernetes.service version : 1.6.6 output_path : relative/path/in/target version parameter is optional: if omitted, the version will be set to the stable release of kubernetes (tbc).","title":"Specification"},{"location":"kap_proposals/kap_3_schema_validation/#implementation","text":"The schemas will be downloaded by requests from this repository . Caching of schema will also be implemented.","title":"Implementation"},{"location":"kap_proposals/kap_3_schema_validation/#dependencies","text":"jsonschema to validate the output yaml/json against the correct schema","title":"Dependencies"},{"location":"kap_proposals/kap_4_standalone_executable/","text":"Standalone Kapitan Executable (Discontinued) Create a portable (i.e. static) kapitan binary for users. This executable will be made available for each release on Github. The target/tested platform is Debian 9 (possibly Windows to be supported in the future). Criteria: speed of the resulting binary size of the resulting binary portability of the binary (single-file executable or has an accompanying folder) cross-platform actively maintained supports Python 3.6, 3.7 Author: @yoshi-1224 Tools to be explored (tentative first-choice) Pyinstaller (Alternative) nuitka (also part of GSoC 2019. It might soon support single-file executable output ).","title":"Standalone Kapitan Executable (Discontinued)"},{"location":"kap_proposals/kap_4_standalone_executable/#standalone-kapitan-executable-discontinued","text":"Create a portable (i.e. static) kapitan binary for users. This executable will be made available for each release on Github. The target/tested platform is Debian 9 (possibly Windows to be supported in the future). Criteria: speed of the resulting binary size of the resulting binary portability of the binary (single-file executable or has an accompanying folder) cross-platform actively maintained supports Python 3.6, 3.7 Author: @yoshi-1224","title":"Standalone Kapitan Executable (Discontinued)"},{"location":"kap_proposals/kap_4_standalone_executable/#tools-to-be-explored","text":"(tentative first-choice) Pyinstaller (Alternative) nuitka (also part of GSoC 2019. It might soon support single-file executable output ).","title":"Tools to be explored"},{"location":"kap_proposals/kap_5_ref_types_redesign/","text":"Ref Types Redesign Redesign Kapitan Secrets and rename them as References or Ref . Breaking changes: $ kapitan secrets is replaced with $ kapitan refs the default secrets directory ./secrets/ changes to ./refs/ the --secrets-path flag changes to --refs-path ref ref type is renamed to base64 e.g. ?{ref:some/ref} into ?{base64:some/ref} Status: In progress Author: @ramaro Proposal Rename Secrets into Ref (or References ) to improve consistency and meaning of the backend types by removing the ref backend and introducting new backends: Type Description Encrypted? Compiles To gpg GnuPG Yes hashed tag gkms Google KMS Yes hashed tag awskms Amazon KMS Yes hashed tag base64 base64 No hashed tag plain plain text No plain text The type value will now need to be representative of the way a reference is stored via its backend. A new plain backend type is introduced and will compile into revealed state instead of a hashed tag. A new base64 backend type will store a base64 encoded value as the backend suggests (replacing the old badly named ref backend). The command line for secrets will be instead: kapitan refs --write gpg:my/secret1 ... kapitan refs --write base64:my/file ... kapitan refs --write plain:my/info ... plain backend The plain backend type will allow referring to external state by updating refs programmatically (e.g. in your pipeline) For example, one can update the value of an environment variable and use ?{plain:my/user} as a reference in a template: echo $USER | kapitan refs --write plain:my/user -f - Or update a docker image value as ref ?{plain:images/dev/envoy} : echo 'envoyproxy/envoy:v1.10.0' | kapitan refs --write plain:images/dev/envoy -f - These references will be compiled into their values instead of hashed tags. base64 backend The base64 backend type will function as the original ref type. Except that this time, the name is representative of what is actually happening :) Refs path Refs will be stored by default in the ./refs path set by --refs-path replacing the --secrets-path flag. Background Kapitan Secrets Kapitan Secrets allow referring to restricted information (passwords, private keys, etc...) in templates while also securely storing them. On compile, secret tags are updated into hashed tags which validate and instruct Kapitan how to reveal tags into decrypted or encoded information. Kapitan Secrets example The following command creates a GPG encrypted secret with the contents of file.txt for recipient ramaro@google.com to read: kapitan secrets --write gpg:my/secret1 -f file.txt --recipients ramaro@google.com This secret can be referred to in a jsonnet compoment: { \"type\" : \"app\" , \"name\" : \"test_app\" , \"username\" : \"user_one\" , \"password\" : \"?{gpg:my/secret1}\" } When this compoment is compiled, it looks like (note the hashed tag): type : app name : test_app username : user_one password : ?{gpg:my/secret1:deadbeef} A user with the required permissions can reveal the compiled component: $ kapitan secrets --reveal -f compiled/mytarget/manifests/component.yml type: app name: test_app username: user_one password: secret_content_of_file.txt Secret Backend Comparison Kapitan today offers multiple secret backends: Type Description Encrypted? Compiles To gpg GnuPG Yes hashed tag gkms Google KMS Yes hashed tag awskms Amazon KMS Yes hashed tag ref base64 No hashed tag However, not all backends are encrypted - this is not consistent! The ref type is not encrypted as its purpose is to allow getting started with the Kapitan Secrets workflow without the need of setting up the encryption backends tooling (gpg, gcloud, boto, etc...)","title":"Ref Types Redesign"},{"location":"kap_proposals/kap_5_ref_types_redesign/#ref-types-redesign","text":"Redesign Kapitan Secrets and rename them as References or Ref . Breaking changes: $ kapitan secrets is replaced with $ kapitan refs the default secrets directory ./secrets/ changes to ./refs/ the --secrets-path flag changes to --refs-path ref ref type is renamed to base64 e.g. ?{ref:some/ref} into ?{base64:some/ref} Status: In progress Author: @ramaro","title":"Ref Types Redesign"},{"location":"kap_proposals/kap_5_ref_types_redesign/#proposal","text":"Rename Secrets into Ref (or References ) to improve consistency and meaning of the backend types by removing the ref backend and introducting new backends: Type Description Encrypted? Compiles To gpg GnuPG Yes hashed tag gkms Google KMS Yes hashed tag awskms Amazon KMS Yes hashed tag base64 base64 No hashed tag plain plain text No plain text The type value will now need to be representative of the way a reference is stored via its backend. A new plain backend type is introduced and will compile into revealed state instead of a hashed tag. A new base64 backend type will store a base64 encoded value as the backend suggests (replacing the old badly named ref backend). The command line for secrets will be instead: kapitan refs --write gpg:my/secret1 ... kapitan refs --write base64:my/file ... kapitan refs --write plain:my/info ...","title":"Proposal"},{"location":"kap_proposals/kap_5_ref_types_redesign/#plain-backend","text":"The plain backend type will allow referring to external state by updating refs programmatically (e.g. in your pipeline) For example, one can update the value of an environment variable and use ?{plain:my/user} as a reference in a template: echo $USER | kapitan refs --write plain:my/user -f - Or update a docker image value as ref ?{plain:images/dev/envoy} : echo 'envoyproxy/envoy:v1.10.0' | kapitan refs --write plain:images/dev/envoy -f - These references will be compiled into their values instead of hashed tags.","title":"plain backend"},{"location":"kap_proposals/kap_5_ref_types_redesign/#base64-backend","text":"The base64 backend type will function as the original ref type. Except that this time, the name is representative of what is actually happening :)","title":"base64 backend"},{"location":"kap_proposals/kap_5_ref_types_redesign/#refs-path","text":"Refs will be stored by default in the ./refs path set by --refs-path replacing the --secrets-path flag.","title":"Refs path"},{"location":"kap_proposals/kap_5_ref_types_redesign/#background","text":"","title":"Background"},{"location":"kap_proposals/kap_5_ref_types_redesign/#kapitan-secrets","text":"Kapitan Secrets allow referring to restricted information (passwords, private keys, etc...) in templates while also securely storing them. On compile, secret tags are updated into hashed tags which validate and instruct Kapitan how to reveal tags into decrypted or encoded information.","title":"Kapitan Secrets"},{"location":"kap_proposals/kap_5_ref_types_redesign/#kapitan-secrets-example","text":"The following command creates a GPG encrypted secret with the contents of file.txt for recipient ramaro@google.com to read: kapitan secrets --write gpg:my/secret1 -f file.txt --recipients ramaro@google.com This secret can be referred to in a jsonnet compoment: { \"type\" : \"app\" , \"name\" : \"test_app\" , \"username\" : \"user_one\" , \"password\" : \"?{gpg:my/secret1}\" } When this compoment is compiled, it looks like (note the hashed tag): type : app name : test_app username : user_one password : ?{gpg:my/secret1:deadbeef} A user with the required permissions can reveal the compiled component: $ kapitan secrets --reveal -f compiled/mytarget/manifests/component.yml type: app name: test_app username: user_one password: secret_content_of_file.txt","title":"Kapitan Secrets example"},{"location":"kap_proposals/kap_5_ref_types_redesign/#secret-backend-comparison","text":"Kapitan today offers multiple secret backends: Type Description Encrypted? Compiles To gpg GnuPG Yes hashed tag gkms Google KMS Yes hashed tag awskms Amazon KMS Yes hashed tag ref base64 No hashed tag However, not all backends are encrypted - this is not consistent! The ref type is not encrypted as its purpose is to allow getting started with the Kapitan Secrets workflow without the need of setting up the encryption backends tooling (gpg, gcloud, boto, etc...)","title":"Secret Backend Comparison"},{"location":"kap_proposals/kap_6_hashicorp_vault/","text":"Hashicorp Vault This feature allows the user to fetch secrets from Hashicorp Vault , with the new secret backend keyword 'vaultkv'. Author: @vaibahvk @daminisatya Specification The following variables need to be exported to the environment(depending on authentication used) where you will run kapitan refs --reveal in order to authenticate to your HashiCorp Vault instance: VAULT_ADDR: URL for vault VAULT_SKIP_VERIFY=true: if set, do not verify presented TLS certificate before communicating with Vault server. Setting this variable is not recommended except during testing VAULT_TOKEN: token for vault or file (~/.vault-tokens) VAULT_ROLE_ID: required by approle VAULT_SECRET_ID: required by approle VAULT_USERNAME: username to login to vault VAULT_PASSWORD: password to login to vault VAULT_CLIENT_KEY: the path to an unencrypted PEM-encoded private key matching the client certificate VAULT_CLIENT_CERT: the path to a PEM-encoded client certificate for TLS authentication to the Vault server VAULT_CACERT: the path to a PEM-encoded CA cert file to use to verify the Vault server TLS certificate VAULT_CAPATH: the path to a directory of PEM-encoded CA cert files to verify the Vault server TLS certificate VAULT_NAMESPACE: specify the Vault Namespace, if you have one Considering a key-value pair like my_key : my_secret ( in our case let\u2019s store hello : batman inside the vault ) in the path secret/foo in a kv-v2(KV version 2) secret engine on the vault server, to use this as a secret either follow: echo \"foo:hello\" > somefile.txt kapitan refs --write vaultkv:path/to/secret_inside_kapitan --file somefile.txt --target dev-sea or in a single line echo \"foo:hello\" | kapitan refs --write vaultkv:path/to/secret_inside_kapitan -t dev-sea -f - The entire string \"foo:hello\" is base64 encoded and stored in the secret_inside_kapitan. Now secret_inside_kapitan contains the following data : Zm9vOmhlbGxvCg== encoding : original type : vaultkv vault_params : auth : token Encoding tells the type of data given to kapitan, if it is original then after decoding base64 we'll get the original secret and if it is base64 then after decoding once we still have a base64 encoded secret and have to decode again. Parameters in the secret file are collected from the inventory of the target we gave from CLI --target dev-sea . If target isn't provided then kapitan will identify the variables from the environment, but providing auth is necessary as a key inside target parameters like the one shown: parameters : kapitan : secrets : vaultkv : auth : userpass engine : kv-v2 mount : team-alpha-secret VAULT_ADDR : http://127.0.0.1:8200 VAULT_NAMESPACE : CICD-alpha VAULT_SKIP_VERIFY : false VAULT_CLIENT_KEY : /path/to/key VAULT_CLIENT_CERT : /path/to/cert Environment variables that can be defined in kapitan inventory are VAULT_ADDR , VAULT_NAMESPACE , VAULT_SKIP_VERIFY , VAULT_CLIENT_CERT , VAULT_CLIENT_KEY , VAULT_CAPATH & VAULT_CACERT . Extra parameters that can be defined in inventory are: auth : specify which authentication method to use like token , userpass , ldap , github & approle mount : specify the mount point of key's path. e.g if path= alpha-secret/foo/bar then mount: alpha-secret (default secret ) engine : secret engine used, either kv-v2 or kv (default kv-v2 ) Environment variables cannot be defined in inventory are VAULT_TOKEN , VAULT_USERNAME , VAULT_PASSWORD , VAULT_ROLE_ID , VAULT_SECRET_ID . This makes the secret_inside_kapitan file accessible throughout the inventory, where we can use the secret whenever necessary like ?{vaultkv:path/to/secret_inside_kapitan} Following is the example file having a secret and pointing to the vault ?{vaultkv:path/to/secret_inside_kapitan} parameters : releases : cod : latest cod : image : alledm/cod:${cod:release} release : ${releases:cod} replicas : ${replicas} args : - --verbose=${verbose} - --password=?{vaultkv:path/to/secret_inside_kapitan} when ?{vaultkv:path/to/secret_inside_kapitan} is compiled, it will look same with an 8 character prefix of sha256 hash added at the end like: kind : Deployment metadata : name : cod namespace : dev-sea spec : replicas : 1 template : metadata : labels : app : cod spec : containers : - args : - --verbose=True - --password=?{vaultkv:path/to/secret_inside_kapitan:57d6f9b7} image : alledm/cod:v2.0.0 name : cod Only the user with the required tokens/permissions can reveal the secrets. Please note that the roles and permissions will be handled at the Vault level. We need not worry about it within Kapitan. Use the following command to reveal the secrets: kapitan refs --reveal -f compile/file/containing/secret Following is the result of the cod-deployment.md file after Kapitan reveal. kind : Deployment metadata : name : cod namespace : dev-sea spec : replicas : 1 template : metadata : labels : app : cod spec : containers : - args : - --verbose=True - --password=batman image : alledm/cod:v2.0.0 name : cod Dependencies hvac is a python client for Hashicorp Vault","title":"Hashicorp Vault"},{"location":"kap_proposals/kap_6_hashicorp_vault/#hashicorp-vault","text":"This feature allows the user to fetch secrets from Hashicorp Vault , with the new secret backend keyword 'vaultkv'. Author: @vaibahvk @daminisatya","title":"Hashicorp Vault"},{"location":"kap_proposals/kap_6_hashicorp_vault/#specification","text":"The following variables need to be exported to the environment(depending on authentication used) where you will run kapitan refs --reveal in order to authenticate to your HashiCorp Vault instance: VAULT_ADDR: URL for vault VAULT_SKIP_VERIFY=true: if set, do not verify presented TLS certificate before communicating with Vault server. Setting this variable is not recommended except during testing VAULT_TOKEN: token for vault or file (~/.vault-tokens) VAULT_ROLE_ID: required by approle VAULT_SECRET_ID: required by approle VAULT_USERNAME: username to login to vault VAULT_PASSWORD: password to login to vault VAULT_CLIENT_KEY: the path to an unencrypted PEM-encoded private key matching the client certificate VAULT_CLIENT_CERT: the path to a PEM-encoded client certificate for TLS authentication to the Vault server VAULT_CACERT: the path to a PEM-encoded CA cert file to use to verify the Vault server TLS certificate VAULT_CAPATH: the path to a directory of PEM-encoded CA cert files to verify the Vault server TLS certificate VAULT_NAMESPACE: specify the Vault Namespace, if you have one Considering a key-value pair like my_key : my_secret ( in our case let\u2019s store hello : batman inside the vault ) in the path secret/foo in a kv-v2(KV version 2) secret engine on the vault server, to use this as a secret either follow: echo \"foo:hello\" > somefile.txt kapitan refs --write vaultkv:path/to/secret_inside_kapitan --file somefile.txt --target dev-sea or in a single line echo \"foo:hello\" | kapitan refs --write vaultkv:path/to/secret_inside_kapitan -t dev-sea -f - The entire string \"foo:hello\" is base64 encoded and stored in the secret_inside_kapitan. Now secret_inside_kapitan contains the following data : Zm9vOmhlbGxvCg== encoding : original type : vaultkv vault_params : auth : token Encoding tells the type of data given to kapitan, if it is original then after decoding base64 we'll get the original secret and if it is base64 then after decoding once we still have a base64 encoded secret and have to decode again. Parameters in the secret file are collected from the inventory of the target we gave from CLI --target dev-sea . If target isn't provided then kapitan will identify the variables from the environment, but providing auth is necessary as a key inside target parameters like the one shown: parameters : kapitan : secrets : vaultkv : auth : userpass engine : kv-v2 mount : team-alpha-secret VAULT_ADDR : http://127.0.0.1:8200 VAULT_NAMESPACE : CICD-alpha VAULT_SKIP_VERIFY : false VAULT_CLIENT_KEY : /path/to/key VAULT_CLIENT_CERT : /path/to/cert Environment variables that can be defined in kapitan inventory are VAULT_ADDR , VAULT_NAMESPACE , VAULT_SKIP_VERIFY , VAULT_CLIENT_CERT , VAULT_CLIENT_KEY , VAULT_CAPATH & VAULT_CACERT . Extra parameters that can be defined in inventory are: auth : specify which authentication method to use like token , userpass , ldap , github & approle mount : specify the mount point of key's path. e.g if path= alpha-secret/foo/bar then mount: alpha-secret (default secret ) engine : secret engine used, either kv-v2 or kv (default kv-v2 ) Environment variables cannot be defined in inventory are VAULT_TOKEN , VAULT_USERNAME , VAULT_PASSWORD , VAULT_ROLE_ID , VAULT_SECRET_ID . This makes the secret_inside_kapitan file accessible throughout the inventory, where we can use the secret whenever necessary like ?{vaultkv:path/to/secret_inside_kapitan} Following is the example file having a secret and pointing to the vault ?{vaultkv:path/to/secret_inside_kapitan} parameters : releases : cod : latest cod : image : alledm/cod:${cod:release} release : ${releases:cod} replicas : ${replicas} args : - --verbose=${verbose} - --password=?{vaultkv:path/to/secret_inside_kapitan} when ?{vaultkv:path/to/secret_inside_kapitan} is compiled, it will look same with an 8 character prefix of sha256 hash added at the end like: kind : Deployment metadata : name : cod namespace : dev-sea spec : replicas : 1 template : metadata : labels : app : cod spec : containers : - args : - --verbose=True - --password=?{vaultkv:path/to/secret_inside_kapitan:57d6f9b7} image : alledm/cod:v2.0.0 name : cod Only the user with the required tokens/permissions can reveal the secrets. Please note that the roles and permissions will be handled at the Vault level. We need not worry about it within Kapitan. Use the following command to reveal the secrets: kapitan refs --reveal -f compile/file/containing/secret Following is the result of the cod-deployment.md file after Kapitan reveal. kind : Deployment metadata : name : cod namespace : dev-sea spec : replicas : 1 template : metadata : labels : app : cod spec : containers : - args : - --verbose=True - --password=batman image : alledm/cod:v2.0.0 name : cod","title":"Specification"},{"location":"kap_proposals/kap_6_hashicorp_vault/#dependencies","text":"hvac is a python client for Hashicorp Vault","title":"Dependencies"},{"location":"kap_proposals/kap_7_remote_inventory/","text":"Remote Inventory Federation This feature would add the ability to Kapitan to fetch parts of the inventory from remote locations (https/git). This would allow users to combine different inventories from different sources and build modular infrastructure reusable across various repos. Author: @alpharoy14 Specification The configuration and declaration of remote inventories would be done in the inventory files. The file specifications are as follows: parameters : kapitan : inventory : - type : <inventory_type> #git\\https source : <source_of_inventory> output_path : <relative_output_path> On executing the $ kapitan compile --fetch command, first the remote inventories will be fetched followed by fetching of external dependencies and finally merge the inventory to compile. Copying inventory files to the output location The output path is the path to save the inventory items into. The path is relative to the inventory/ directory. For example, it could be /classes/ . The contents of the fetched inventory will be recursively copied. The fetched inventory files will be cached in the .dependency_cache directory if --cache is set. eg. $ kapitan compile --fetch --cache Force fetching While fetching, the output path will be recursively checked to see if it contains any file with the same name. If so, kapitan will skip fetching it. To overwrite the files with the newly downloaded inventory items, we can add the --force-fetch flag to the compile command, as shown below. $ kapitan compile --force-fetch URL type The URL type can be either git or http(s). Depending on the URL type, the configuration file may have additional arguments. E.g Git type may also include aditional ref parameter as illustrated below: inventory : - type : git #git\\https source : <source_of_inventory> output_path : <output_path> ref : <commit_hash/branch/tag> Implementation details TODO Dependencies GitPython module (and git executable) for git type requests module for http[s]","title":"Remote Inventory Federation"},{"location":"kap_proposals/kap_7_remote_inventory/#remote-inventory-federation","text":"This feature would add the ability to Kapitan to fetch parts of the inventory from remote locations (https/git). This would allow users to combine different inventories from different sources and build modular infrastructure reusable across various repos. Author: @alpharoy14","title":"Remote Inventory Federation"},{"location":"kap_proposals/kap_7_remote_inventory/#specification","text":"The configuration and declaration of remote inventories would be done in the inventory files. The file specifications are as follows: parameters : kapitan : inventory : - type : <inventory_type> #git\\https source : <source_of_inventory> output_path : <relative_output_path> On executing the $ kapitan compile --fetch command, first the remote inventories will be fetched followed by fetching of external dependencies and finally merge the inventory to compile.","title":"Specification"},{"location":"kap_proposals/kap_7_remote_inventory/#copying-inventory-files-to-the-output-location","text":"The output path is the path to save the inventory items into. The path is relative to the inventory/ directory. For example, it could be /classes/ . The contents of the fetched inventory will be recursively copied. The fetched inventory files will be cached in the .dependency_cache directory if --cache is set. eg. $ kapitan compile --fetch --cache","title":"Copying inventory files to the output location"},{"location":"kap_proposals/kap_7_remote_inventory/#force-fetching","text":"While fetching, the output path will be recursively checked to see if it contains any file with the same name. If so, kapitan will skip fetching it. To overwrite the files with the newly downloaded inventory items, we can add the --force-fetch flag to the compile command, as shown below. $ kapitan compile --force-fetch","title":"Force fetching"},{"location":"kap_proposals/kap_7_remote_inventory/#url-type","text":"The URL type can be either git or http(s). Depending on the URL type, the configuration file may have additional arguments. E.g Git type may also include aditional ref parameter as illustrated below: inventory : - type : git #git\\https source : <source_of_inventory> output_path : <output_path> ref : <commit_hash/branch/tag>","title":"URL type"},{"location":"kap_proposals/kap_7_remote_inventory/#implementation-details","text":"TODO","title":"Implementation details"},{"location":"kap_proposals/kap_7_remote_inventory/#dependencies","text":"GitPython module (and git executable) for git type requests module for http[s]","title":"Dependencies"},{"location":"kap_proposals/kap_8_google_secret_management/","text":"Support for Google Secret Manager This feature will enable users to retrieve secrets from Google Secret Manager API using the gsm keyword. Specification project_id uniquely identifies GCP projects, and it needs to be made accessible to kapitan in one of the following ways: As a part of target parameters : kapitan : secrets : gsm : project_id : Project_Id As a flag kapitan refs --google-project-id = <Project_Id> --write gsm:/path/to/secret_id -f secret_id_file.txt As an environment variable export PROJECT_ID = <Project_Id> Using a secret In GCP, a secret contains one or more secret versions, along with its metadata. The actual contents of a secret are stored in a secret version. Each secret is identified by a name. We call that variable secret_id e.g. my_treasured_secret . The URI of the secret becomes projects/<Project_Id>/secrets/my_treasured_secret The following command will be used to add a secret_id to kapitan. echo \"my_treasured_secret\" | kapitan refs --write gsm:path/to/secret_inside_kapitan -t <target_name> -f - The -t <target_name> is used to get the information about Project_ID. The secret_id is Base64 encoded and stored in path/to/secret_inside_kapitan as data : bXlfdHJlYXN1cmVkX3NlY3JldAo= encoding : original type : gsm gsm_params : project_id : Project_ID referencing a secret Secrets can be refered using ?{gsm:path/to/secret_id:version_id} e.g. parameter : mysql : storage : 10G storage_class : standard image : mysql:latest users : root : password : ?{gsm:path/to/secret_id:version_id} Here, version_id will be an optional argument. By default it will point to latest . Revealing a secret After compilation, the secret reference will be postfixed with 8 characters from the sha256 hash of the retrieved password apiVersion : v1 data : MYSQL_ROOT_PASSWORD : ?{gsm:path/to/secret_id:version_id:deadbeef} kind : Secret metadata : labels : name : example-mysql name : example-mysql namespace : minikube-mysql type : Opaque To reveal the secret, the following command will be used $ kapitan ref --reveal -f compiled/file/containing/secret Dependencies google-cloud-secret-manager note Kapitan will not be responsible for authentication or access management to GCP","title":"Support for [Google Secret Manager](https://cloud.google.com/secret-manager/)"},{"location":"kap_proposals/kap_8_google_secret_management/#support-for-google-secret-manager","text":"This feature will enable users to retrieve secrets from Google Secret Manager API using the gsm keyword.","title":"Support for Google Secret Manager"},{"location":"kap_proposals/kap_8_google_secret_management/#specification","text":"project_id uniquely identifies GCP projects, and it needs to be made accessible to kapitan in one of the following ways: As a part of target parameters : kapitan : secrets : gsm : project_id : Project_Id As a flag kapitan refs --google-project-id = <Project_Id> --write gsm:/path/to/secret_id -f secret_id_file.txt As an environment variable export PROJECT_ID = <Project_Id>","title":"Specification"},{"location":"kap_proposals/kap_8_google_secret_management/#using-a-secret","text":"In GCP, a secret contains one or more secret versions, along with its metadata. The actual contents of a secret are stored in a secret version. Each secret is identified by a name. We call that variable secret_id e.g. my_treasured_secret . The URI of the secret becomes projects/<Project_Id>/secrets/my_treasured_secret The following command will be used to add a secret_id to kapitan. echo \"my_treasured_secret\" | kapitan refs --write gsm:path/to/secret_inside_kapitan -t <target_name> -f - The -t <target_name> is used to get the information about Project_ID. The secret_id is Base64 encoded and stored in path/to/secret_inside_kapitan as data : bXlfdHJlYXN1cmVkX3NlY3JldAo= encoding : original type : gsm gsm_params : project_id : Project_ID","title":"Using a secret"},{"location":"kap_proposals/kap_8_google_secret_management/#referencing-a-secret","text":"Secrets can be refered using ?{gsm:path/to/secret_id:version_id} e.g. parameter : mysql : storage : 10G storage_class : standard image : mysql:latest users : root : password : ?{gsm:path/to/secret_id:version_id} Here, version_id will be an optional argument. By default it will point to latest .","title":"referencing a secret"},{"location":"kap_proposals/kap_8_google_secret_management/#revealing-a-secret","text":"After compilation, the secret reference will be postfixed with 8 characters from the sha256 hash of the retrieved password apiVersion : v1 data : MYSQL_ROOT_PASSWORD : ?{gsm:path/to/secret_id:version_id:deadbeef} kind : Secret metadata : labels : name : example-mysql name : example-mysql namespace : minikube-mysql type : Opaque To reveal the secret, the following command will be used $ kapitan ref --reveal -f compiled/file/containing/secret","title":"Revealing a secret"},{"location":"kap_proposals/kap_8_google_secret_management/#dependencies","text":"google-cloud-secret-manager note Kapitan will not be responsible for authentication or access management to GCP","title":"Dependencies"},{"location":"kap_proposals/kap_8_modularize_kapitan/","text":"Modularize Kapitan Kapitan is packaged in PYPI and as a binary along with all its dependencies. Adding an extra key/security backend means that we need to ship another dependency with that PYPI package, making deploying changes more complicated. This project would modularize kapitan into core dependencies and extra modules. Usage pip3 install --user kapitan # to install only core dependencies Pip3 install --user kapitan [ gkms ] \u200b# gkms is the module Implementation The main module includes the essential kapitan dependencies and reclass dependencies, which will be included in the \u200brequirement.txt\u200b file. The extra module pypi extras will be defined in the s\u200betup.py \u200b file. The extra dependencies are of secret backends like (AWS Key backend, Google KMS Key backend, Vault Key backend etc.) and Helm support.","title":"Modularize Kapitan"},{"location":"kap_proposals/kap_8_modularize_kapitan/#modularize-kapitan","text":"Kapitan is packaged in PYPI and as a binary along with all its dependencies. Adding an extra key/security backend means that we need to ship another dependency with that PYPI package, making deploying changes more complicated. This project would modularize kapitan into core dependencies and extra modules.","title":"Modularize Kapitan"},{"location":"kap_proposals/kap_8_modularize_kapitan/#usage","text":"pip3 install --user kapitan # to install only core dependencies Pip3 install --user kapitan [ gkms ] \u200b# gkms is the module","title":"Usage"},{"location":"kap_proposals/kap_8_modularize_kapitan/#implementation","text":"The main module includes the essential kapitan dependencies and reclass dependencies, which will be included in the \u200brequirement.txt\u200b file. The extra module pypi extras will be defined in the s\u200betup.py \u200b file. The extra dependencies are of secret backends like (AWS Key backend, Google KMS Key backend, Vault Key backend etc.) and Helm support.","title":"Implementation"},{"location":"kap_proposals/kap_9_bring_your_own_helm/","text":"Bring Your Own Helm Proposal The Problem Currently the helm binding can't be run on Mac OSX. Attempts to fix this have been made on several occasions: https://github.com/kapicorp/kapitan/pull/414 https://github.com/kapicorp/kapitan/pull/547 https://github.com/kapicorp/kapitan/pull/568 There are some issues with the current bindings besides the lack of Mac OSX support. The golang runtime (1.14) selected will effect older versions helm templates: https://github.com/helm/helm/issues/7711 . Users can't select the version of helm they'd like to use for templating. Solution Users supply their own helm binary. This allows them to control the version of golang runtime and version of helm they'd like to use. In Kapitan we could rewrite the interface to use subprocess and perform commands. The cli of helm 2 vs helm 3 is slightly different but shouldn't be difficult to codify. This would be great to get rid of cffi and golang which will reduce complexity and build time of the project. Depending on how this goes, this could pave the way for a \"bring your own binary\" input type.","title":"Bring Your Own Helm Proposal"},{"location":"kap_proposals/kap_9_bring_your_own_helm/#bring-your-own-helm-proposal","text":"","title":"Bring Your Own Helm Proposal"},{"location":"kap_proposals/kap_9_bring_your_own_helm/#the-problem","text":"Currently the helm binding can't be run on Mac OSX. Attempts to fix this have been made on several occasions: https://github.com/kapicorp/kapitan/pull/414 https://github.com/kapicorp/kapitan/pull/547 https://github.com/kapicorp/kapitan/pull/568 There are some issues with the current bindings besides the lack of Mac OSX support. The golang runtime (1.14) selected will effect older versions helm templates: https://github.com/helm/helm/issues/7711 . Users can't select the version of helm they'd like to use for templating.","title":"The Problem"},{"location":"kap_proposals/kap_9_bring_your_own_helm/#solution","text":"Users supply their own helm binary. This allows them to control the version of golang runtime and version of helm they'd like to use. In Kapitan we could rewrite the interface to use subprocess and perform commands. The cli of helm 2 vs helm 3 is slightly different but shouldn't be difficult to codify. This would be great to get rid of cffi and golang which will reduce complexity and build time of the project. Depending on how this goes, this could pave the way for a \"bring your own binary\" input type.","title":"Solution"},{"location":"pages/external_dependencies/","text":"External dependencies Kapitan has the functionality to fetch external dependencies from remote locations. Supported dependencies types are: git http helm Usage Kapitan by default will not attempt to download any dependency, and rely on what is already available. Basic fetching You can use the fetch option to explicitly fetch the dependencies: cli dotfile kapitan compile --fetch .kapitan to make it default, then simply use kapitan compile ... compile : fetch : true This will download the dependencies and store them at their respective output_path . Overwrite local changes When fetching a dependency, Kapitan will refuse to overwrite existing files to preserve your local modifications. Use the force-fetch option to force overwrite your local files in the output_path . cli dotfile kapitan compile --force-fetch .kapitan to make it default, then simply use kapitan compile ... compile : force-fetch : true Caching Kapitan also supports caching Use the --cache flag to cache the fetched items in the .dependency_cache directory in the root project directory. ```shell kapitan compile --cache --fetch ``` Defining dependencies git http helm Syntax parameters : kapitan : dependencies : - type : git output_path : path/to/dir source : git_url # mkdocs (1)! subdir : relative/path/from/repo/root (optional) # mkdocs (2)! ref : tag, commit, branch etc. (optional) # mkdocs (3)! submodules : true/false (optional) # mkdocs (4)! Git types can fetch external git repositories through either HTTP/HTTPS or SSH URLs. Optional supports for cloning just a sub-directory Optional support for accessing them in specific commits and branches (refs). Optional support to disable fetching the submodules of a repo. Note This type depends on the git binary installed on your system and available to Kapitan . Example Say we want to fetch the source code from our kapitan repository, specifically, kapicorp/kapitan/kapitan/version.py . Let's create a very simple target file inventory/targets/kapitan-example.yml . parameters : kapitan : vars : target : kapitan-example dependencies : - type : git output_path : source/kapitan source : git@github.com:kapicorp/kapitan.git subdir : kapitan ref : master submodules : true compile : - input_paths : - source/kapitan/version.py input_type : jinja2 # just to copy the file over to target output_path : . Syntax parameters : kapitan : dependencies : - type : http | https # mkdocs (2)! output_path : path/to/file # mkdocs (1)! source : http[s]://<url> # mkdocs (2)! unpack : True | False # mkdocs (3)! output_path must fully specify the file name. For example: http[s] types can fetch external dependencies available at http:// or https:// URL. archive mode: download and unpack Example Single file Archive Say we want to download kapitan README.md file. Since it's on Github, we can access it as https://raw.githubusercontent.com/kapicorp/kapitan/master/README.md . Using the following inventory, we can copy this to our target folder: parameters : kapitan : vars : target : kapitan-example dependencies : - type : https output_path : README.md source : https://raw.githubusercontent.com/kapicorp/kapitan/master/README.md compile : - input_paths : - README.md input_type : jinja2 output_path : . Syntax parameters : kapitan : dependencies : - type : helm output_path : path/to/chart source : http[s]|oci://<helm_chart_repository_url> version : <specific chart version> chart_name : <name of chart> helm_path : <helm binary> Fetches helm charts and any specific subcharts in the requirements.yaml file. helm_path can be used to specify where the helm binary name or path. It defaults to the value of the KAPITAN_HELM_PATH environment var or simply to helm if neither is set. You should specify only if you don't want the default behavior. source can be either the URL to a chart repository, or the URL to a chart on an OCI registry (supported since Helm 3.8.0). Example If we want to download the prometheus helm chart we simply add the dependency to the monitoring target. We want a specific version 11.3.0 so we put that in. parameters : kapitan : vars : target : monitoring dependencies : - type : helm output_path : charts/prometheus source : https://kubernetes-charts.storage.googleapis.com version : 11.3.0 chart_name : prometheus compile : - input_type : helm output_path : . input_paths : - charts/prometheus helm_values : alertmanager : enabled : false helm_params : namespace : monitoring name : prometheus","title":"External dependencies"},{"location":"pages/external_dependencies/#external-dependencies","text":"Kapitan has the functionality to fetch external dependencies from remote locations. Supported dependencies types are: git http helm","title":" External dependencies"},{"location":"pages/external_dependencies/#usage","text":"Kapitan by default will not attempt to download any dependency, and rely on what is already available.","title":"Usage"},{"location":"pages/external_dependencies/#basic-fetching","text":"You can use the fetch option to explicitly fetch the dependencies: cli dotfile kapitan compile --fetch .kapitan to make it default, then simply use kapitan compile ... compile : fetch : true This will download the dependencies and store them at their respective output_path .","title":"Basic fetching"},{"location":"pages/external_dependencies/#overwrite-local-changes","text":"When fetching a dependency, Kapitan will refuse to overwrite existing files to preserve your local modifications. Use the force-fetch option to force overwrite your local files in the output_path . cli dotfile kapitan compile --force-fetch .kapitan to make it default, then simply use kapitan compile ... compile : force-fetch : true","title":"Overwrite local changes"},{"location":"pages/external_dependencies/#caching","text":"Kapitan also supports caching Use the --cache flag to cache the fetched items in the .dependency_cache directory in the root project directory. ```shell kapitan compile --cache --fetch ```","title":"Caching"},{"location":"pages/external_dependencies/#defining-dependencies","text":"git http helm","title":"Defining dependencies"},{"location":"pages/external_dependencies/#syntax","text":"parameters : kapitan : dependencies : - type : git output_path : path/to/dir source : git_url # mkdocs (1)! subdir : relative/path/from/repo/root (optional) # mkdocs (2)! ref : tag, commit, branch etc. (optional) # mkdocs (3)! submodules : true/false (optional) # mkdocs (4)! Git types can fetch external git repositories through either HTTP/HTTPS or SSH URLs. Optional supports for cloning just a sub-directory Optional support for accessing them in specific commits and branches (refs). Optional support to disable fetching the submodules of a repo. Note This type depends on the git binary installed on your system and available to Kapitan .","title":"Syntax"},{"location":"pages/external_dependencies/#example","text":"Say we want to fetch the source code from our kapitan repository, specifically, kapicorp/kapitan/kapitan/version.py . Let's create a very simple target file inventory/targets/kapitan-example.yml . parameters : kapitan : vars : target : kapitan-example dependencies : - type : git output_path : source/kapitan source : git@github.com:kapicorp/kapitan.git subdir : kapitan ref : master submodules : true compile : - input_paths : - source/kapitan/version.py input_type : jinja2 # just to copy the file over to target output_path : .","title":"Example"},{"location":"pages/external_dependencies/#syntax_1","text":"parameters : kapitan : dependencies : - type : http | https # mkdocs (2)! output_path : path/to/file # mkdocs (1)! source : http[s]://<url> # mkdocs (2)! unpack : True | False # mkdocs (3)! output_path must fully specify the file name. For example: http[s] types can fetch external dependencies available at http:// or https:// URL. archive mode: download and unpack","title":"Syntax"},{"location":"pages/external_dependencies/#example_1","text":"Single file Archive Say we want to download kapitan README.md file. Since it's on Github, we can access it as https://raw.githubusercontent.com/kapicorp/kapitan/master/README.md . Using the following inventory, we can copy this to our target folder: parameters : kapitan : vars : target : kapitan-example dependencies : - type : https output_path : README.md source : https://raw.githubusercontent.com/kapicorp/kapitan/master/README.md compile : - input_paths : - README.md input_type : jinja2 output_path : .","title":"Example"},{"location":"pages/external_dependencies/#syntax_2","text":"parameters : kapitan : dependencies : - type : helm output_path : path/to/chart source : http[s]|oci://<helm_chart_repository_url> version : <specific chart version> chart_name : <name of chart> helm_path : <helm binary> Fetches helm charts and any specific subcharts in the requirements.yaml file. helm_path can be used to specify where the helm binary name or path. It defaults to the value of the KAPITAN_HELM_PATH environment var or simply to helm if neither is set. You should specify only if you don't want the default behavior. source can be either the URL to a chart repository, or the URL to a chart on an OCI registry (supported since Helm 3.8.0).","title":"Syntax"},{"location":"pages/external_dependencies/#example_2","text":"If we want to download the prometheus helm chart we simply add the dependency to the monitoring target. We want a specific version 11.3.0 so we put that in. parameters : kapitan : vars : target : monitoring dependencies : - type : helm output_path : charts/prometheus source : https://kubernetes-charts.storage.googleapis.com version : 11.3.0 chart_name : prometheus compile : - input_type : helm output_path : . input_paths : - charts/prometheus helm_values : alertmanager : enabled : false helm_params : namespace : monitoring name : prometheus","title":"Example"},{"location":"pages/kapitan_overview/","text":"Kapitan Overview Kapitan at a glance %%{ init: { securityLevel: 'loose'} }%% graph LR classDef pink fill:#f9f,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; classDef blue fill:#00FFFF,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; TARGET1 --> KAPITAN TARGET2 --> KAPITAN TARGETN --> KAPITAN KAPITAN --> EXTERNAL KAPITAN --> GENERATORS KAPITAN --> HELM KAPITAN --> JINJA KAPITAN --> JSONNET KAPITAN --> KADET EXTERNAL --> OUTPUT GENERATORS --> OUTPUT JINJA --> OUTPUT JSONNET --> OUTPUT KADET --> OUTPUT HELM --> OUTPUT GKMS --> REFERENCES AWSKMS --> REFERENCES VAULT --> REFERENCES OTHER --> REFERENCES PLAIN --> REFERENCES OUTPUT --> TARGETN_OUTPUT OUTPUT --> TARGET1_OUTPUT OUTPUT --> TARGET2_OUTPUT REFERENCES --> KAPITAN TARGET1_OUTPUT --> DOCUMENTATION TARGET1_OUTPUT --> KUBERNETES TARGET1_OUTPUT --> SCRIPTS TARGET1_OUTPUT --> TERRAFORM CLASSES --> TARGET1 CLASSES --> TARGET2 CLASSES --> TARGETN subgraph \"Inventory\" CLASSES[classes] TARGET1([\"target 1\"]):::pink TARGET2([\"target 2\"]) TARGETN([\"target N\"]) end subgraph \"references\" direction TB GKMS[\"GCP KMS\"] AWSKMS[\"AWS KMS\"] VAULT[\"Hashicorp Vault\"] OTHER[\"others\"] PLAIN[\"plain\"] REFERENCES[\"references\"] end KAPITAN((\"<img src='/images/kapitan_logo.png'; width='80'/>\")):::blue click EXTERNAL \"/compile#external\" subgraph \"Input Types\" EXTERNAL[\"external\"] GENERATORS[\"generators\"] HELM[\"helm\"] JINJA[\"jinja\"] JSONNET[\"jsonnet\"] KADET[\"kadet\"] end OUTPUT{{\"compiled output\"}}:::blue subgraph \" \" TARGET1_OUTPUT([target1]):::pink DOCUMENTATION[\"docs\"] KUBERNETES[\"manifests\"] SCRIPTS[\"scripts\"] TERRAFORM[\"terraform\"] end TARGET2_OUTPUT([\"target 2\"]) TARGETN_OUTPUT([\"target N\"]) Essential concepts Inventory The Inventory is a hierarchical database of variables, defined in yaml files, that are passed to the targets during compilation. The Inventory is the heart of Kapitan . Using simple reusable yaml files (classes), you can represent as a SSOT everything that matters in your setup, for instance you can define: kubernetes components definitions terraform resources business concepts documentation and tooling ...anything else you want! After defining it, you can make this data available to the various templating engines Input types offered by Kapitan, allowing you to reuse it. Find more detaled explanation in the inventory section of the documentation. Input types On compilation, Kapitan \"renders\" the Inventory and makes it available to templates that can generate any configuration you want, including Kubernetes manifests , documentation/playbooks, Terraform configuration or even scripts. Generators Generators are simplest way of getting started with Kapitan and require no code at all. Check out our Kapitan Reference repository to get started or our Read our blog post Keep your ship together with Kapitan . The simplest way to get started with Kapitan. Generators are universal templates that are a simplified way to generate configuration files (for instance, Kubernetes manifests) without using any templating at all. Kadet Easily define and reuse complex Python objects that serialize into JSON or YAML Use kadet , our home built Python library, to easily generate json and yaml manifests for your applications. Using kadet is simple as using Python examples/kubernetes/components/nginx-kadet/__init__.py from kapitan.inputs import kadet kubelib = kadet . load_from_search_paths ( \"kubelib\" ) inv = kadet . inventory () name = \"nginx\" labels = kadet . BaseObj . from_dict ({ \"app\" : name }) nginx_container = kubelib . Container ( name = name , image = inv . parameters . nginx . image , ports = [{ \"containerPort\" : 80 }] ) svc_selector = { \"app\" : name } svc_port = kadet . BaseObj () svc_port . root . name = \"http\" svc_port . root . port = 80 svc_port . root . targetPort = 80 def main (): return { \"nginx_deployment\" : kubelib . Deployment ( name = name , labels = labels , containers = [ nginx_container ]), \"nginx_service\" : kubelib . Service ( name = name , labels = labels , ports = [ svc_port ], selector = svc_selector ), } kadet is what generators are being built with. See and example Head over to kapicorp/kadet for more details Find help in #kapitan Jsonnet A powerful DSL for elegant description of JSON data Use the jsonnet input type to compile jsonnet code, and have access to a large amount of available jsonnet libraries like bitnami-labs/kube-libsonnet Find help in #kapitan or #jsonnet examples/kubernetes/components/nginx-jsonnet/main.jsonnet local svc = import \"./service.jsonnet\" ; local deployment = import \"./deployment.jsonnet\" ; { \"app-service\" : svc . nginx_svc , \"app-deployment\" : deployment . nginx_deployment , } Head over to jsonnet to learn more Jinja2 Jinja is a fast, expressive, extensible templating engine Good old Jinja to create text based templates for scripts and documentation. Don't underestimate the power of this very simple approach to create templated scripts and documentation! examples/kubernetes/scripts/setup_cluster.sh #!/bin/bash -eu # Copyright 2019 The Kapitan Authors # SPDX-FileCopyrightText: 2020 The Kapitan Authors <kapitan-admins@googlegroups.com> # # SPDX-License-Identifier: Apache-2.0 { % set i = inventory.parameters % } { % set cluster = i.cluster % } { % if cluster.type == \"gke\" % } gcloud container clusters get-credentials {{ cluster.name }} --zone {{ cluster.zone }} --project {{ i.project }} { % elif cluster.type == \"self-hosted\" % } kubectl config set-credentials $USER --client-certificate = $HOME /credentials/ $USER .crt --client-key = $HOME /credentials/ $USER .key kubectl config set-cluster {{ cluster.id }} --server ={{ cluster.kubernetes.master.api }} --certificate-authority ={{ cluster.kubernetes.master.ca }} --embed-certs ={{ cluster.kubernetes.master.embed }} { % elif cluster.type == \"minikube\" % } { % endif % } Find help in #kapitan Helm The package manager for Kubernetes Kapitan can also be used to manage Helm , giving you access to its enourmous catalogues of Helm charts . examples/kubernetes/inventory/classes/component/nginx-helm.yml external dependencies are used to automatically fetch helm charts in this example. Please use the kapitan compile --fetch flag if the chart has not been downloaded already parameters : namespace : nginx : version : 4.4.0 replicas : 2 name : ${target_name} namespace : ${target_name} kapitan : dependencies : - type : helm output_path : charts/nginx-ingress source : https://kubernetes.github.io/ingress-nginx chart_name : ingress-nginx compile : - output_path : . input_type : helm input_paths : - charts/nginx-ingress helm_values : controller : name : ${nginx:name} helm_params : name : ${nginx:name} namespace : ${nginx:namespace} Find help in #kapitan References Use Kapitan to securely generate and manage secrets with GPG, AWS KMS, gCloud KMS and Vault. Tip Use Tesoro , our Kubernetes Admission Controller , to complete your integration with Kubernetes for secure secret decryption on-the-fly. Credits Jsonnet Jinja2 reclass","title":"Overview"},{"location":"pages/kapitan_overview/#kapitan-overview","text":"","title":" Kapitan Overview"},{"location":"pages/kapitan_overview/#kapitan-at-a-glance","text":"%%{ init: { securityLevel: 'loose'} }%% graph LR classDef pink fill:#f9f,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; classDef blue fill:#00FFFF,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; TARGET1 --> KAPITAN TARGET2 --> KAPITAN TARGETN --> KAPITAN KAPITAN --> EXTERNAL KAPITAN --> GENERATORS KAPITAN --> HELM KAPITAN --> JINJA KAPITAN --> JSONNET KAPITAN --> KADET EXTERNAL --> OUTPUT GENERATORS --> OUTPUT JINJA --> OUTPUT JSONNET --> OUTPUT KADET --> OUTPUT HELM --> OUTPUT GKMS --> REFERENCES AWSKMS --> REFERENCES VAULT --> REFERENCES OTHER --> REFERENCES PLAIN --> REFERENCES OUTPUT --> TARGETN_OUTPUT OUTPUT --> TARGET1_OUTPUT OUTPUT --> TARGET2_OUTPUT REFERENCES --> KAPITAN TARGET1_OUTPUT --> DOCUMENTATION TARGET1_OUTPUT --> KUBERNETES TARGET1_OUTPUT --> SCRIPTS TARGET1_OUTPUT --> TERRAFORM CLASSES --> TARGET1 CLASSES --> TARGET2 CLASSES --> TARGETN subgraph \"Inventory\" CLASSES[classes] TARGET1([\"target 1\"]):::pink TARGET2([\"target 2\"]) TARGETN([\"target N\"]) end subgraph \"references\" direction TB GKMS[\"GCP KMS\"] AWSKMS[\"AWS KMS\"] VAULT[\"Hashicorp Vault\"] OTHER[\"others\"] PLAIN[\"plain\"] REFERENCES[\"references\"] end KAPITAN((\"<img src='/images/kapitan_logo.png'; width='80'/>\")):::blue click EXTERNAL \"/compile#external\" subgraph \"Input Types\" EXTERNAL[\"external\"] GENERATORS[\"generators\"] HELM[\"helm\"] JINJA[\"jinja\"] JSONNET[\"jsonnet\"] KADET[\"kadet\"] end OUTPUT{{\"compiled output\"}}:::blue subgraph \" \" TARGET1_OUTPUT([target1]):::pink DOCUMENTATION[\"docs\"] KUBERNETES[\"manifests\"] SCRIPTS[\"scripts\"] TERRAFORM[\"terraform\"] end TARGET2_OUTPUT([\"target 2\"]) TARGETN_OUTPUT([\"target N\"])","title":"Kapitan at a glance"},{"location":"pages/kapitan_overview/#essential-concepts","text":"","title":"Essential concepts"},{"location":"pages/kapitan_overview/#inventory","text":"The Inventory is a hierarchical database of variables, defined in yaml files, that are passed to the targets during compilation. The Inventory is the heart of Kapitan . Using simple reusable yaml files (classes), you can represent as a SSOT everything that matters in your setup, for instance you can define: kubernetes components definitions terraform resources business concepts documentation and tooling ...anything else you want! After defining it, you can make this data available to the various templating engines Input types offered by Kapitan, allowing you to reuse it. Find more detaled explanation in the inventory section of the documentation.","title":"Inventory"},{"location":"pages/kapitan_overview/#input-types","text":"On compilation, Kapitan \"renders\" the Inventory and makes it available to templates that can generate any configuration you want, including Kubernetes manifests , documentation/playbooks, Terraform configuration or even scripts.","title":"Input types"},{"location":"pages/kapitan_overview/#generators","text":"Generators are simplest way of getting started with Kapitan and require no code at all. Check out our Kapitan Reference repository to get started or our Read our blog post Keep your ship together with Kapitan . The simplest way to get started with Kapitan. Generators are universal templates that are a simplified way to generate configuration files (for instance, Kubernetes manifests) without using any templating at all.","title":"Generators"},{"location":"pages/kapitan_overview/#kadet","text":"Easily define and reuse complex Python objects that serialize into JSON or YAML Use kadet , our home built Python library, to easily generate json and yaml manifests for your applications. Using kadet is simple as using Python examples/kubernetes/components/nginx-kadet/__init__.py from kapitan.inputs import kadet kubelib = kadet . load_from_search_paths ( \"kubelib\" ) inv = kadet . inventory () name = \"nginx\" labels = kadet . BaseObj . from_dict ({ \"app\" : name }) nginx_container = kubelib . Container ( name = name , image = inv . parameters . nginx . image , ports = [{ \"containerPort\" : 80 }] ) svc_selector = { \"app\" : name } svc_port = kadet . BaseObj () svc_port . root . name = \"http\" svc_port . root . port = 80 svc_port . root . targetPort = 80 def main (): return { \"nginx_deployment\" : kubelib . Deployment ( name = name , labels = labels , containers = [ nginx_container ]), \"nginx_service\" : kubelib . Service ( name = name , labels = labels , ports = [ svc_port ], selector = svc_selector ), } kadet is what generators are being built with. See and example Head over to kapicorp/kadet for more details Find help in #kapitan","title":"Kadet"},{"location":"pages/kapitan_overview/#jsonnet","text":"A powerful DSL for elegant description of JSON data Use the jsonnet input type to compile jsonnet code, and have access to a large amount of available jsonnet libraries like bitnami-labs/kube-libsonnet Find help in #kapitan or #jsonnet examples/kubernetes/components/nginx-jsonnet/main.jsonnet local svc = import \"./service.jsonnet\" ; local deployment = import \"./deployment.jsonnet\" ; { \"app-service\" : svc . nginx_svc , \"app-deployment\" : deployment . nginx_deployment , } Head over to jsonnet to learn more","title":"Jsonnet"},{"location":"pages/kapitan_overview/#jinja2","text":"Jinja is a fast, expressive, extensible templating engine Good old Jinja to create text based templates for scripts and documentation. Don't underestimate the power of this very simple approach to create templated scripts and documentation! examples/kubernetes/scripts/setup_cluster.sh #!/bin/bash -eu # Copyright 2019 The Kapitan Authors # SPDX-FileCopyrightText: 2020 The Kapitan Authors <kapitan-admins@googlegroups.com> # # SPDX-License-Identifier: Apache-2.0 { % set i = inventory.parameters % } { % set cluster = i.cluster % } { % if cluster.type == \"gke\" % } gcloud container clusters get-credentials {{ cluster.name }} --zone {{ cluster.zone }} --project {{ i.project }} { % elif cluster.type == \"self-hosted\" % } kubectl config set-credentials $USER --client-certificate = $HOME /credentials/ $USER .crt --client-key = $HOME /credentials/ $USER .key kubectl config set-cluster {{ cluster.id }} --server ={{ cluster.kubernetes.master.api }} --certificate-authority ={{ cluster.kubernetes.master.ca }} --embed-certs ={{ cluster.kubernetes.master.embed }} { % elif cluster.type == \"minikube\" % } { % endif % } Find help in #kapitan","title":"Jinja2"},{"location":"pages/kapitan_overview/#helm","text":"The package manager for Kubernetes Kapitan can also be used to manage Helm , giving you access to its enourmous catalogues of Helm charts . examples/kubernetes/inventory/classes/component/nginx-helm.yml external dependencies are used to automatically fetch helm charts in this example. Please use the kapitan compile --fetch flag if the chart has not been downloaded already parameters : namespace : nginx : version : 4.4.0 replicas : 2 name : ${target_name} namespace : ${target_name} kapitan : dependencies : - type : helm output_path : charts/nginx-ingress source : https://kubernetes.github.io/ingress-nginx chart_name : ingress-nginx compile : - output_path : . input_type : helm input_paths : - charts/nginx-ingress helm_values : controller : name : ${nginx:name} helm_params : name : ${nginx:name} namespace : ${nginx:namespace} Find help in #kapitan","title":" Helm"},{"location":"pages/kapitan_overview/#references","text":"Use Kapitan to securely generate and manage secrets with GPG, AWS KMS, gCloud KMS and Vault. Tip Use Tesoro , our Kubernetes Admission Controller , to complete your integration with Kubernetes for secure secret decryption on-the-fly.","title":"References"},{"location":"pages/kapitan_overview/#credits","text":"Jsonnet Jinja2 reclass","title":"Credits"},{"location":"pages/remote_repositories/","text":"Remote Inventories Kapitan is capable of recursively fetching inventory items stored in remote locations and copy it to the specified output path. This feature can be used by specifying those inventory items in classes or targets under parameters.kapitan.inventory . Supported types are: git type http type Class items can be specified before they are locally available as long as they are fetched in the same run. Example of this is given below. Git type Git types can fetch external inventories available via HTTP/HTTPS or SSH URLs. This is useful for fetching repositories or their sub-directories, as well as accessing them in specific commits and branches (refs). Note : git types require git binary on your system. Definition parameters : kapitan : inventory : - type : git output_path : path/to/dir source : git_url subdir : relative/path/from/repo/root (optional) ref : tag, commit, branch etc. (optional) Example Lets say we want to fetch a class from our kapitan repository, specifically kapicorp/kapitan/tree/master/examples/docker/inventory/classes/dockerfiles.yml . Lets create a simple target file docker.yml Note external dependencies are used to fetch dependency items in this example. targets/docker.yml classes : - dockerfiles parameters : kapitan : vars : target : docker inventory : - type : git source : https://github.com/kapicorp/kapitan subdir : examples/docker/inventory/classes/ output_path : classes/ dependencies : - type : git source : https://github.com/kapicorp/kapitan subdir : examples/docker/components output_path : components/ - type : git source : https://github.com/kapicorp/kapitan subdir : examples/docker/templates output_path : templates/ dockerfiles : - name : web image : amazoncorretto:11 - name : worker image : amazoncorretto:8 kapitan compile --fetch click to expand output [ WARNING ] Reclass class not found: 'dockerfiles' . Skipped! [ WARNING ] Reclass class not found: 'dockerfiles' . Skipped! Inventory https://github.com/kapicorp/kapitan: fetching now Inventory https://github.com/kapicorp/kapitan: successfully fetched Inventory https://github.com/kapicorp/kapitan: saved to inventory/classes Dependency https://github.com/kapicorp/kapitan: saved to components Dependency https://github.com/kapicorp/kapitan: saved to templates Compiled docker ( 0 .11s ) http type http[s] types can fetch external inventories available at http:// or https:// URL. Definition parameters : kapitan : inventory : - type : http | https output_path : full/path/to/file.yml source : http[s]://<url> unpack : True | False # False by default Example targets/mysql-generator-fetch.yml classes : - common - kapitan.generators.kubernetes parameters : kapitan : inventory : - type : https source : https://raw.githubusercontent.com/kapicorp/kapitan-reference/master/inventory/classes/kapitan/generators/kubernetes.yml output_path : classes/kapitan/generators/kubernetes.yml components : mysql : image : mysql kapitan compile --fetch click to expand output ./kapitan compile -t mysql-generator-fetch --fetch Inventory https://raw.githubusercontent.com/kapicorp/kapitan-reference/master/inventory/classes/kapitan/generators/kubernetes.yml: fetching now Inventory https://raw.githubusercontent.com/kapicorp/kapitan-reference/master/inventory/classes/kapitan/generators/kubernetes.yml: successfully fetched Inventory https://raw.githubusercontent.com/kapicorp/kapitan-reference/master/inventory/classes/kapitan/generators/kubernetes.yml: saved to inventory/classes/kapitan/generators/kubernetes.yml ... cut ... Compiled mysql-generator-fetch ( 0 .06s )","title":"Remote repositories"},{"location":"pages/remote_repositories/#remote-inventories","text":"Kapitan is capable of recursively fetching inventory items stored in remote locations and copy it to the specified output path. This feature can be used by specifying those inventory items in classes or targets under parameters.kapitan.inventory . Supported types are: git type http type Class items can be specified before they are locally available as long as they are fetched in the same run. Example of this is given below.","title":" Remote Inventories"},{"location":"pages/remote_repositories/#git-type","text":"Git types can fetch external inventories available via HTTP/HTTPS or SSH URLs. This is useful for fetching repositories or their sub-directories, as well as accessing them in specific commits and branches (refs). Note : git types require git binary on your system.","title":"Git type"},{"location":"pages/remote_repositories/#definition","text":"parameters : kapitan : inventory : - type : git output_path : path/to/dir source : git_url subdir : relative/path/from/repo/root (optional) ref : tag, commit, branch etc. (optional)","title":"Definition"},{"location":"pages/remote_repositories/#example","text":"Lets say we want to fetch a class from our kapitan repository, specifically kapicorp/kapitan/tree/master/examples/docker/inventory/classes/dockerfiles.yml . Lets create a simple target file docker.yml Note external dependencies are used to fetch dependency items in this example. targets/docker.yml classes : - dockerfiles parameters : kapitan : vars : target : docker inventory : - type : git source : https://github.com/kapicorp/kapitan subdir : examples/docker/inventory/classes/ output_path : classes/ dependencies : - type : git source : https://github.com/kapicorp/kapitan subdir : examples/docker/components output_path : components/ - type : git source : https://github.com/kapicorp/kapitan subdir : examples/docker/templates output_path : templates/ dockerfiles : - name : web image : amazoncorretto:11 - name : worker image : amazoncorretto:8 kapitan compile --fetch click to expand output [ WARNING ] Reclass class not found: 'dockerfiles' . Skipped! [ WARNING ] Reclass class not found: 'dockerfiles' . Skipped! Inventory https://github.com/kapicorp/kapitan: fetching now Inventory https://github.com/kapicorp/kapitan: successfully fetched Inventory https://github.com/kapicorp/kapitan: saved to inventory/classes Dependency https://github.com/kapicorp/kapitan: saved to components Dependency https://github.com/kapicorp/kapitan: saved to templates Compiled docker ( 0 .11s )","title":"Example"},{"location":"pages/remote_repositories/#http-type","text":"http[s] types can fetch external inventories available at http:// or https:// URL.","title":"http type"},{"location":"pages/remote_repositories/#definition_1","text":"parameters : kapitan : inventory : - type : http | https output_path : full/path/to/file.yml source : http[s]://<url> unpack : True | False # False by default","title":"Definition"},{"location":"pages/remote_repositories/#example_1","text":"targets/mysql-generator-fetch.yml classes : - common - kapitan.generators.kubernetes parameters : kapitan : inventory : - type : https source : https://raw.githubusercontent.com/kapicorp/kapitan-reference/master/inventory/classes/kapitan/generators/kubernetes.yml output_path : classes/kapitan/generators/kubernetes.yml components : mysql : image : mysql kapitan compile --fetch click to expand output ./kapitan compile -t mysql-generator-fetch --fetch Inventory https://raw.githubusercontent.com/kapicorp/kapitan-reference/master/inventory/classes/kapitan/generators/kubernetes.yml: fetching now Inventory https://raw.githubusercontent.com/kapicorp/kapitan-reference/master/inventory/classes/kapitan/generators/kubernetes.yml: successfully fetched Inventory https://raw.githubusercontent.com/kapicorp/kapitan-reference/master/inventory/classes/kapitan/generators/kubernetes.yml: saved to inventory/classes/kapitan/generators/kubernetes.yml ... cut ... Compiled mysql-generator-fetch ( 0 .06s )","title":"Example"},{"location":"pages/blog/2022-12-04/","text":"5 Years of Kapitan Last October we quietly celebrated 5 years of Kapitan . In 5 years, we've been able to witness a steady and relentless of Kapitan, which has however never caught the full attention of the majority of the community. The main issue has always been around an embarassing lack of documentation , and we've worked hard to improve on that, with more updates due soon. Let this first blog post from a revamped website be a promise to our community of a better effort in explaining what sets Kapitan apart, and makes it the only tool of its kind. And let's start with a simple question: Why do you even need Kapitan ? Credits In reality Kapitan's heatbeat started about 9 months earlier at DeepMind Health, created by Ricardo Amaro with the help of some of my amazing team: in no particular order Adrian Chifor , Paul S and Luis Buriola . It was then kindly released to the community by Google/DeepMind and is has so been improved thanks to more than 50 contributors . Why do I need Kapitan ? Kapitan is a hard sell, but a rewarding one. For these main reasons: Kapitan solves problems that some don\u2019t know/think to have. Some people by now have probably accepted the Status Quo and think that some suffering is part of their job descriptions. Objectively, Kapitan requires an investment of effort to learn how to use a new tool, and this adds friction. All I can say it is very rewarding once you get to use it, so stick with me while I try to explain the problems that Kapitan is solving The problems It would be reductive to list the problems that Kapitan solves, because sometimes we ourselves are stunned by what Kapitan is being used for, so I will start with some common relatable ones, and perhaps that will give you the right framing to understand how to use it with your setup. In its most basic explanation, Kapitan solves the problem of avoiding duplication of configuration data : by consolidating it in one place (the Inventory ), and making it accessible by all the tools and languages it integrates with (see Input Types ). This configuration data is then used by Kapitan (templates) to configure and operate a number of completely distinct and unaware tools which would normally not be able to share their configurations. Without Kapitan Let's consider the case where you want to define a new bucket, with a given bucket_name . Without Kapitan you would probably need to: Write a PR on your Terraform repository to create the new bucket. Which name should I use? Make sure to write it down! CTRL-C Write a PR for your values.yaml file to configure your Helm chart: <CTRL-V> Write somewhere some documentation to write down the bucket name and why it exists. Another <CTRL-V> Another PR to change some **kustomize** configuration for another service to tell it to use the new bucket <CTRL-V> Days after, time to upload something to that bucket: gsutil cp my_file wait_what_was_the_bucket_name_again .. Better check the documentation: CTRL-C + <CTRL-V> With Kapitan When using Kapitan, your changes are likely to be contained within one PR, from which you can have a full view of everything that is happening. What happens is explained in this flow %%{ init: { securityLevel: 'loose'} }%% graph LR classDef pink fill:#f9f,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; classDef blue fill:#00FFFF,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; classDef bold color:#000,font-weight: bold; DATA --> KAPITAN BUCKET --> DATA KAPITAN --> KUBERNETES KAPITAN --> TERRAFORM KAPITAN --> DOCUMENTATION KAPITAN --> SCRIPT KAPITAN --> HELM KUBERNETES --> BUCKET_K8S TERRAFORM --> BUCKET_TF DOCUMENTATION --> BUCKET_DOC SCRIPT --> BUCKET_SCRIPT HELM --> BUCKET_HELM DATA[(\"All your data\")] BUCKET(\"bucket_name\") KAPITAN((\"<img src='/images/kapitan_logo.png'; width='150'/>\")):::blue subgraph \" \" KUBERNETES([\"Kubernetes\"]):::pink BUCKET_K8S(\".. a ConfigMap uses bucket_name\"):::bold end subgraph \" \" TERRAFORM([\"Terraform\"]):::pink BUCKET_TF(\"..creates the bucket bucket_name\"):::bold end subgraph \" \" DOCUMENTATION([\"Documentation\"]):::pink BUCKET_DOC(\"..references a link to bucket_name\"):::bold end subgraph \" \" SCRIPT([\"Canned Script\"]):::pink BUCKET_SCRIPT(\"..knows how to upload files to bucket_name\"):::bold end subgraph \" \" HELM([\"Helm\"]):::pink BUCKET_HELM(\"..configures a chart to use the bucket_name\"):::bold end Thanks to its flexiblility, you can use Kapitan to generate all sorts of configurations: Kubernetes and Terraform resources, ArgoCD pipelines, Docker Compose files, random configs, scripts, documentations and anything else you find relevant. The trick is obviously on how to drive these changes, but it is not as complicated as it sounds. We'll get there soon enough! Let's see now another example of things that are so established in the way to do things that become elusivly impossible to see. As a way to highlight the potential issues with this way of doing things, let's ask some questions on your current setup. We pick on Kubernetes this time. Kubernetes I\u2019ll start with Kubernetes , such a popular and brilliant solution to problems most people should not be concerned with (jokes apart, I adore Kubernetes). To most, Kubernetes is that type of solution that quickly turns into a problem of its own right. So.. how do you deploy to Kubernetes right now? Helm comes to mind first, right? Kapitan + Helm : BFF In spite of Kapitan being initially considered (even by ourselves) as an alternative to Helm , we\u2019ve actually enjoyed the benefits of integrating with this amazing tool and the ecosystem it gives us access to. So yes, good news: you can use Helm right from within Kapitan !. Well, let\u2019s put that to a test. How do you manage your Helm charts? I\u2019ll attempt to break these questions down into categories. Code Organization DRY Maintenance Operations Documentation Secrets management Everything else Where do you keep your Helm charts? In a single repository? How many repositories? Alongside the code you develop? What about the official ones that you didn't create yourself? How many values.yaml files do you have? How much consistency is there between them? any snowflakes ? If you change something, like with the bucket_name example above: how many places do you need to go and update? And how many times do you get it wrong? Don't you feel all your charts look the same? Yet how many times do you need to deviate from the one you thought captured everything? What if you need to make a change to all your charts at once: how do you deal with it? What about configuration files, how do you deal with templating those? How do you deal with \u201cofficial\u201d charts, do they always cover what you want to do? How do you deal with modifications that you need to apply to your own version of a an official chart? What if you need to make a change that affects ALL your charts? Or if the change is for all the charts for a set of microservices? How many times you find yourself seting parameters on the command line of Helm and other tools? How many times did you connect to the wrong context in Kubernetes How many of your colleagues have the same clean context setup as you have? How many things are there that you wish you were tracking? How do I connect to the production database? Which user is it again? How easy is it for you to create a new environment from scratch? Are you sure? When was the last time you tried? How easy is it to keep your configuration up to date? Does your documentation need to be \u201cunderstood\u201d or can be just executed on? How many conditionals like this do you have in your documentation? NOTE: Cluster X in project Y has an older version of Q and requires you to do Z instead N because of A, B and C! Would you be able to follow those instructions at 3am on a Sunday morning? How do you handle secrets in your repository? Do you know how to create your secrets from scratch? Do you remember that token you created 4 months ago? How did you do that? How long would it take you? Is the process of creating them \u201csecure\u201d? Or does it leave you with random certificates and tokens unencrypted on your \u201cDownloads\u201d folder? The above concerns: do they also apply to other things you manage? Terraform? Pipelines? Random other systems you interact with? I\u2019ll stop here because I do not want to lose you, and neither do I want to discourage you. But if you look around it\u2019s true, you do have a very complicated setup. And Kapitan can help you streamline it for you. In fact, Kapitan can leave you with a consistent and uniform way to manage all these concerns at once. My job here is done: you have awakened and you won't look at your setup in the same way. Keep tuned and learn about how Kapitan can change the way you do things.","title":"5 years of Kapitan"},{"location":"pages/blog/2022-12-04/#5-years-of-kapitan","text":"Last October we quietly celebrated 5 years of Kapitan . In 5 years, we've been able to witness a steady and relentless of Kapitan, which has however never caught the full attention of the majority of the community. The main issue has always been around an embarassing lack of documentation , and we've worked hard to improve on that, with more updates due soon. Let this first blog post from a revamped website be a promise to our community of a better effort in explaining what sets Kapitan apart, and makes it the only tool of its kind. And let's start with a simple question: Why do you even need Kapitan ? Credits In reality Kapitan's heatbeat started about 9 months earlier at DeepMind Health, created by Ricardo Amaro with the help of some of my amazing team: in no particular order Adrian Chifor , Paul S and Luis Buriola . It was then kindly released to the community by Google/DeepMind and is has so been improved thanks to more than 50 contributors .","title":" 5 Years of Kapitan"},{"location":"pages/blog/2022-12-04/#why-do-i-need-kapitan","text":"Kapitan is a hard sell, but a rewarding one. For these main reasons: Kapitan solves problems that some don\u2019t know/think to have. Some people by now have probably accepted the Status Quo and think that some suffering is part of their job descriptions. Objectively, Kapitan requires an investment of effort to learn how to use a new tool, and this adds friction. All I can say it is very rewarding once you get to use it, so stick with me while I try to explain the problems that Kapitan is solving","title":"Why do I need Kapitan?"},{"location":"pages/blog/2022-12-04/#the-problems","text":"It would be reductive to list the problems that Kapitan solves, because sometimes we ourselves are stunned by what Kapitan is being used for, so I will start with some common relatable ones, and perhaps that will give you the right framing to understand how to use it with your setup. In its most basic explanation, Kapitan solves the problem of avoiding duplication of configuration data : by consolidating it in one place (the Inventory ), and making it accessible by all the tools and languages it integrates with (see Input Types ). This configuration data is then used by Kapitan (templates) to configure and operate a number of completely distinct and unaware tools which would normally not be able to share their configurations.","title":"The problems"},{"location":"pages/blog/2022-12-04/#without-kapitan","text":"Let's consider the case where you want to define a new bucket, with a given bucket_name . Without Kapitan you would probably need to: Write a PR on your Terraform repository to create the new bucket. Which name should I use? Make sure to write it down! CTRL-C Write a PR for your values.yaml file to configure your Helm chart: <CTRL-V> Write somewhere some documentation to write down the bucket name and why it exists. Another <CTRL-V> Another PR to change some **kustomize** configuration for another service to tell it to use the new bucket <CTRL-V> Days after, time to upload something to that bucket: gsutil cp my_file wait_what_was_the_bucket_name_again .. Better check the documentation: CTRL-C + <CTRL-V>","title":"Without Kapitan"},{"location":"pages/blog/2022-12-04/#with-kapitan","text":"When using Kapitan, your changes are likely to be contained within one PR, from which you can have a full view of everything that is happening. What happens is explained in this flow %%{ init: { securityLevel: 'loose'} }%% graph LR classDef pink fill:#f9f,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; classDef blue fill:#00FFFF,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; classDef bold color:#000,font-weight: bold; DATA --> KAPITAN BUCKET --> DATA KAPITAN --> KUBERNETES KAPITAN --> TERRAFORM KAPITAN --> DOCUMENTATION KAPITAN --> SCRIPT KAPITAN --> HELM KUBERNETES --> BUCKET_K8S TERRAFORM --> BUCKET_TF DOCUMENTATION --> BUCKET_DOC SCRIPT --> BUCKET_SCRIPT HELM --> BUCKET_HELM DATA[(\"All your data\")] BUCKET(\"bucket_name\") KAPITAN((\"<img src='/images/kapitan_logo.png'; width='150'/>\")):::blue subgraph \" \" KUBERNETES([\"Kubernetes\"]):::pink BUCKET_K8S(\".. a ConfigMap uses bucket_name\"):::bold end subgraph \" \" TERRAFORM([\"Terraform\"]):::pink BUCKET_TF(\"..creates the bucket bucket_name\"):::bold end subgraph \" \" DOCUMENTATION([\"Documentation\"]):::pink BUCKET_DOC(\"..references a link to bucket_name\"):::bold end subgraph \" \" SCRIPT([\"Canned Script\"]):::pink BUCKET_SCRIPT(\"..knows how to upload files to bucket_name\"):::bold end subgraph \" \" HELM([\"Helm\"]):::pink BUCKET_HELM(\"..configures a chart to use the bucket_name\"):::bold end Thanks to its flexiblility, you can use Kapitan to generate all sorts of configurations: Kubernetes and Terraform resources, ArgoCD pipelines, Docker Compose files, random configs, scripts, documentations and anything else you find relevant. The trick is obviously on how to drive these changes, but it is not as complicated as it sounds. We'll get there soon enough! Let's see now another example of things that are so established in the way to do things that become elusivly impossible to see. As a way to highlight the potential issues with this way of doing things, let's ask some questions on your current setup. We pick on Kubernetes this time.","title":"With Kapitan"},{"location":"pages/blog/2022-12-04/#kubernetes","text":"I\u2019ll start with Kubernetes , such a popular and brilliant solution to problems most people should not be concerned with (jokes apart, I adore Kubernetes). To most, Kubernetes is that type of solution that quickly turns into a problem of its own right. So.. how do you deploy to Kubernetes right now? Helm comes to mind first, right? Kapitan + Helm : BFF In spite of Kapitan being initially considered (even by ourselves) as an alternative to Helm , we\u2019ve actually enjoyed the benefits of integrating with this amazing tool and the ecosystem it gives us access to. So yes, good news: you can use Helm right from within Kapitan !. Well, let\u2019s put that to a test. How do you manage your Helm charts? I\u2019ll attempt to break these questions down into categories. Code Organization DRY Maintenance Operations Documentation Secrets management Everything else Where do you keep your Helm charts? In a single repository? How many repositories? Alongside the code you develop? What about the official ones that you didn't create yourself? How many values.yaml files do you have? How much consistency is there between them? any snowflakes ? If you change something, like with the bucket_name example above: how many places do you need to go and update? And how many times do you get it wrong? Don't you feel all your charts look the same? Yet how many times do you need to deviate from the one you thought captured everything? What if you need to make a change to all your charts at once: how do you deal with it? What about configuration files, how do you deal with templating those? How do you deal with \u201cofficial\u201d charts, do they always cover what you want to do? How do you deal with modifications that you need to apply to your own version of a an official chart? What if you need to make a change that affects ALL your charts? Or if the change is for all the charts for a set of microservices? How many times you find yourself seting parameters on the command line of Helm and other tools? How many times did you connect to the wrong context in Kubernetes How many of your colleagues have the same clean context setup as you have? How many things are there that you wish you were tracking? How do I connect to the production database? Which user is it again? How easy is it for you to create a new environment from scratch? Are you sure? When was the last time you tried? How easy is it to keep your configuration up to date? Does your documentation need to be \u201cunderstood\u201d or can be just executed on? How many conditionals like this do you have in your documentation? NOTE: Cluster X in project Y has an older version of Q and requires you to do Z instead N because of A, B and C! Would you be able to follow those instructions at 3am on a Sunday morning? How do you handle secrets in your repository? Do you know how to create your secrets from scratch? Do you remember that token you created 4 months ago? How did you do that? How long would it take you? Is the process of creating them \u201csecure\u201d? Or does it leave you with random certificates and tokens unencrypted on your \u201cDownloads\u201d folder? The above concerns: do they also apply to other things you manage? Terraform? Pipelines? Random other systems you interact with? I\u2019ll stop here because I do not want to lose you, and neither do I want to discourage you. But if you look around it\u2019s true, you do have a very complicated setup. And Kapitan can help you streamline it for you. In fact, Kapitan can leave you with a consistent and uniform way to manage all these concerns at once. My job here is done: you have awakened and you won't look at your setup in the same way. Keep tuned and learn about how Kapitan can change the way you do things.","title":"Kubernetes"},{"location":"pages/blog/2023-01-16/","text":"New Kapitan release v0.31.0 The Kapicorp team is happy to to announce a new release of Kapitan . This release is yet another great bundle of features and improvements over the past year, the majority of which have been contributions from our community! Head over our release page on GitHub for a full list of features and contributors. If you missed it, have a look at our latest blog post here 5 years of Kapitan Please help us by visiting our Sponsor Kapitan page.","title":"New Kapitan release"},{"location":"pages/blog/2023-01-16/#new-kapitan-release-v0310","text":"The Kapicorp team is happy to to announce a new release of Kapitan . This release is yet another great bundle of features and improvements over the past year, the majority of which have been contributions from our community! Head over our release page on GitHub for a full list of features and contributors. If you missed it, have a look at our latest blog post here 5 years of Kapitan Please help us by visiting our Sponsor Kapitan page.","title":" New Kapitan release  v0.31.0"},{"location":"pages/blog/2023-06-01/","text":"New Kapitan release v0.32.0 The Kapicorp team is happy to to announce a new release of Kapitan . This release contains loads of improvements for the past 6 months, the majority of which have been contributions from our community! Head over our release page on GitHub for a full list of features and contributors. Please help us by visiting our Sponsor Kapitan page.","title":":kapitan-logo: New **Kapitan** release  v0.32.0"},{"location":"pages/blog/2023-06-01/#new-kapitan-release-v0320","text":"The Kapicorp team is happy to to announce a new release of Kapitan . This release contains loads of improvements for the past 6 months, the majority of which have been contributions from our community! Head over our release page on GitHub for a full list of features and contributors. Please help us by visiting our Sponsor Kapitan page.","title":" New Kapitan release  v0.32.0"},{"location":"pages/commands/kapitan_compile/","text":"CLI Reference | kapitan compile kapitan compile Merges inventory and inputs and produces generated files in the output folder ( /compiled by default) Compile all targets kapitan compile click to expand output Compiled mysql-generator-fetch (0.18s) Compiled vault (0.25s) Compiled pritunl (0.22s) Compiled gke-pvm-killer (0.05s) Compiled examples (0.30s) Compiled mysql (0.08s) Compiled postgres-proxy (0.06s) Compiled echo-server (0.06s) Compiled global (0.03s) Compiled guestbook-argocd (0.08s) Compiled tutorial (0.13s) Compiled kapicorp-project-123 (0.03s) Compiled kapicorp-demo-march (0.03s) Compiled kapicorp-terraform-admin (0.03s) Compiled sock-shop (0.32s) Compiled tesoro (0.09s) Compiled dev-sockshop (0.32s) Compiled prod-sockshop (0.38s) Compiled argocd (2.29s) Selective compilation Using target names Compiles one or more targets selected by name using --targets or -t kapitan compile -t mysql tesoro click to expand output Compiled mysql ( 0 .06s ) Compiled tesoro ( 0 .09s ) Using labels Compiles one or more targets selected matching labels with --labels or -l Info This works if you have labelled your targets using the following syntax: parameters : ... kapitan : ... labels : customer : acme see Labels for more details $ kapitan compile -l customer = acme Compiled acme-project ( 0 .14s ) Compiled acme-pipelines ( 0 .10s ) Fetch on compile Use the --fetch flag to fetch Remote Inventories and the External Dependencies . kapitan compile --fetch This will download the dependencies according to their configurations By default, kapitan does not overwrite an existing item with the same name as that of the fetched inventory items. Use the --force-fetch flag to force fetch (update cache with freshly fetched items) and overwrite inventory items of the same name in the output_path . kapitan compile --force-fetch Use the --cache flag to cache the fetched items in the .dependency_cache directory in the root project directory. kapitan compile --cache --fetch Embed references By default, Kapitan references are stored encrypted (for backends that support encription) in the configuration repository under the /refs directory. For instance, a reference tag ?{gpg:targets/minikube-mysql/mysql/password:ec3d54de} would point to a phisical file on disk under /refs like: refs/targets/minikube-mysql/mysql/password data: hQEMA8uOJKdm07XTAQgAp5i [[ CUT ]] BwqYc3g7PI09HCJZdU = encoding: base64 recipients: - fingerprint: D9234C61F58BEB3ED8552A57E28DC07A3CBFAE7C type: gpg The --embed-refs flags tells Kapitan to embed these references on compile, alongside the generated output. By doing so, compiled output is self-contained and can be revealed by Tesoro or other tools. kapitan compile --embed-refs See how the compiled output for this specific target changes to embed the actul encrypted content, (marked by ?{gpg: :embedded} to indicate it is a gpg reference) rather than just holding a reference to it (like in this case ?{gpg:targets/minikube-mysql/mysql/password:ec3d54de} which points to ). click to expand output diff --git a/examples/kubernetes/compiled/minikube-mysql/manifests/mysql_app.yml b/examples/kubernetes/compiled/minikube-mysql/manifests/mysql_app.yml [[ CUT ]] apiVersion: v1 data: - MYSQL_ROOT_PASSWORD: ? { gpg:targets/minikube-mysql/mysql/password:ec3d54de } - MYSQL_ROOT_PASSWORD_SHA256: ? { gpg:targets/minikube-mysql/mysql/password_sha256:122d2732 } + MYSQL_ROOT_PASSWORD: ? { gpg:eyJkYXRhIjogImhR [[ CUT ]] gInR5cGUiOiAiZ3BnIn0 = :embedded } + MYSQL_ROOT_PASSWORD_SHA256: ? { gpg:eyJkYXRhI [[ CUT ]] eXBlIjogImdwZyJ9:embedded } help kapitan compile --help click to expand output ```shell usage: kapitan compile [-h] [--search-paths JPATH [JPATH ...]] [--jinja2-filters FPATH] [--verbose] [--prune] [--quiet] [--output-path PATH] [--fetch] [--force-fetch] [--force] [--validate] [--parallelism INT] [--indent INT] [--refs-path REFS_PATH] [--reveal] [--embed-refs] [--inventory-path INVENTORY_PATH] [--cache] [--cache-paths PATH [PATH ...]] [--ignore-version-check] [--use-go-jsonnet] [--compose-node-name] [--schemas-path SCHEMAS_PATH] [--yaml-multiline-string-style STYLE] [--yaml-dump-null-as-empty] [--targets TARGET [TARGET ...] | --labels [key=value ...]] optional arguments: -h, --help show this help message and exit --search-paths JPATH [JPATH ...], -J JPATH [JPATH ...] set search paths, default is [\".\"] --jinja2-filters FPATH, -J2F FPATH load custom jinja2 filters from any file, default is to put them inside lib/jinja2_filters.py --verbose, -v set verbose mode --prune prune jsonnet output --quiet set quiet mode, only critical output --output-path PATH set output path, default is \".\" --fetch fetch remote inventories and/or external dependencies --force-fetch overwrite existing inventory and/or dependency item --force overwrite existing inventory and/or dependency item --validate validate compile output against schemas as specified in inventory --parallelism INT, -p INT Number of concurrent compile processes, default is 4 --indent INT, -i INT Indentation spaces for YAML/JSON, default is 2 --refs-path REFS_PATH set refs path, default is \"./refs\" --reveal reveal refs (warning: this will potentially write sensitive data) --embed-refs embed ref contents --inventory-path INVENTORY_PATH set inventory path, default is \"./inventory\" --cache, -c enable compilation caching to .kapitan_cache and dependency caching to .dependency_cache, default is False --cache-paths PATH [PATH ...] cache additional paths to .kapitan_cache, default is [] --ignore-version-check ignore the version from .kapitan --use-go-jsonnet use go-jsonnet --compose-node-name Create same subfolder structure from inventory/targets inside compiled folder --schemas-path SCHEMAS_PATH set schema cache path, default is \"./schemas\" --yaml-multiline-string-style STYLE, -L STYLE set multiline string style to STYLE, default is 'double-quotes' --yaml-dump-null-as-empty dumps all none-type entries as empty, default is dumping as 'null' --targets TARGET [TARGET ...], -t TARGET [TARGET ...] targets to compile, default is all --labels [key=value ...], -l [key=value ...] compile targets matching the labels, default is all ```","title":"compile"},{"location":"pages/commands/kapitan_compile/#cli-reference-kapitan-compile","text":"","title":" CLI Reference | kapitan compile"},{"location":"pages/commands/kapitan_compile/#kapitan-compile","text":"Merges inventory and inputs and produces generated files in the output folder ( /compiled by default)","title":"kapitan compile"},{"location":"pages/commands/kapitan_compile/#compile-all-targets","text":"kapitan compile click to expand output Compiled mysql-generator-fetch (0.18s) Compiled vault (0.25s) Compiled pritunl (0.22s) Compiled gke-pvm-killer (0.05s) Compiled examples (0.30s) Compiled mysql (0.08s) Compiled postgres-proxy (0.06s) Compiled echo-server (0.06s) Compiled global (0.03s) Compiled guestbook-argocd (0.08s) Compiled tutorial (0.13s) Compiled kapicorp-project-123 (0.03s) Compiled kapicorp-demo-march (0.03s) Compiled kapicorp-terraform-admin (0.03s) Compiled sock-shop (0.32s) Compiled tesoro (0.09s) Compiled dev-sockshop (0.32s) Compiled prod-sockshop (0.38s) Compiled argocd (2.29s)","title":"Compile all targets"},{"location":"pages/commands/kapitan_compile/#selective-compilation","text":"","title":"Selective compilation"},{"location":"pages/commands/kapitan_compile/#using-target-names","text":"Compiles one or more targets selected by name using --targets or -t kapitan compile -t mysql tesoro click to expand output Compiled mysql ( 0 .06s ) Compiled tesoro ( 0 .09s )","title":"Using target names"},{"location":"pages/commands/kapitan_compile/#using-labels","text":"Compiles one or more targets selected matching labels with --labels or -l Info This works if you have labelled your targets using the following syntax: parameters : ... kapitan : ... labels : customer : acme see Labels for more details $ kapitan compile -l customer = acme Compiled acme-project ( 0 .14s ) Compiled acme-pipelines ( 0 .10s )","title":"Using labels"},{"location":"pages/commands/kapitan_compile/#fetch-on-compile","text":"Use the --fetch flag to fetch Remote Inventories and the External Dependencies . kapitan compile --fetch This will download the dependencies according to their configurations By default, kapitan does not overwrite an existing item with the same name as that of the fetched inventory items. Use the --force-fetch flag to force fetch (update cache with freshly fetched items) and overwrite inventory items of the same name in the output_path . kapitan compile --force-fetch Use the --cache flag to cache the fetched items in the .dependency_cache directory in the root project directory. kapitan compile --cache --fetch","title":"Fetch on compile"},{"location":"pages/commands/kapitan_compile/#embed-references","text":"By default, Kapitan references are stored encrypted (for backends that support encription) in the configuration repository under the /refs directory. For instance, a reference tag ?{gpg:targets/minikube-mysql/mysql/password:ec3d54de} would point to a phisical file on disk under /refs like: refs/targets/minikube-mysql/mysql/password data: hQEMA8uOJKdm07XTAQgAp5i [[ CUT ]] BwqYc3g7PI09HCJZdU = encoding: base64 recipients: - fingerprint: D9234C61F58BEB3ED8552A57E28DC07A3CBFAE7C type: gpg The --embed-refs flags tells Kapitan to embed these references on compile, alongside the generated output. By doing so, compiled output is self-contained and can be revealed by Tesoro or other tools. kapitan compile --embed-refs See how the compiled output for this specific target changes to embed the actul encrypted content, (marked by ?{gpg: :embedded} to indicate it is a gpg reference) rather than just holding a reference to it (like in this case ?{gpg:targets/minikube-mysql/mysql/password:ec3d54de} which points to ). click to expand output diff --git a/examples/kubernetes/compiled/minikube-mysql/manifests/mysql_app.yml b/examples/kubernetes/compiled/minikube-mysql/manifests/mysql_app.yml [[ CUT ]] apiVersion: v1 data: - MYSQL_ROOT_PASSWORD: ? { gpg:targets/minikube-mysql/mysql/password:ec3d54de } - MYSQL_ROOT_PASSWORD_SHA256: ? { gpg:targets/minikube-mysql/mysql/password_sha256:122d2732 } + MYSQL_ROOT_PASSWORD: ? { gpg:eyJkYXRhIjogImhR [[ CUT ]] gInR5cGUiOiAiZ3BnIn0 = :embedded } + MYSQL_ROOT_PASSWORD_SHA256: ? { gpg:eyJkYXRhI [[ CUT ]] eXBlIjogImdwZyJ9:embedded }","title":"Embed references"},{"location":"pages/commands/kapitan_compile/#help","text":"kapitan compile --help click to expand output ```shell usage: kapitan compile [-h] [--search-paths JPATH [JPATH ...]] [--jinja2-filters FPATH] [--verbose] [--prune] [--quiet] [--output-path PATH] [--fetch] [--force-fetch] [--force] [--validate] [--parallelism INT] [--indent INT] [--refs-path REFS_PATH] [--reveal] [--embed-refs] [--inventory-path INVENTORY_PATH] [--cache] [--cache-paths PATH [PATH ...]] [--ignore-version-check] [--use-go-jsonnet] [--compose-node-name] [--schemas-path SCHEMAS_PATH] [--yaml-multiline-string-style STYLE] [--yaml-dump-null-as-empty] [--targets TARGET [TARGET ...] | --labels [key=value ...]] optional arguments: -h, --help show this help message and exit --search-paths JPATH [JPATH ...], -J JPATH [JPATH ...] set search paths, default is [\".\"] --jinja2-filters FPATH, -J2F FPATH load custom jinja2 filters from any file, default is to put them inside lib/jinja2_filters.py --verbose, -v set verbose mode --prune prune jsonnet output --quiet set quiet mode, only critical output --output-path PATH set output path, default is \".\" --fetch fetch remote inventories and/or external dependencies --force-fetch overwrite existing inventory and/or dependency item --force overwrite existing inventory and/or dependency item --validate validate compile output against schemas as specified in inventory --parallelism INT, -p INT Number of concurrent compile processes, default is 4 --indent INT, -i INT Indentation spaces for YAML/JSON, default is 2 --refs-path REFS_PATH set refs path, default is \"./refs\" --reveal reveal refs (warning: this will potentially write sensitive data) --embed-refs embed ref contents --inventory-path INVENTORY_PATH set inventory path, default is \"./inventory\" --cache, -c enable compilation caching to .kapitan_cache and dependency caching to .dependency_cache, default is False --cache-paths PATH [PATH ...] cache additional paths to .kapitan_cache, default is [] --ignore-version-check ignore the version from .kapitan --use-go-jsonnet use go-jsonnet --compose-node-name Create same subfolder structure from inventory/targets inside compiled folder --schemas-path SCHEMAS_PATH set schema cache path, default is \"./schemas\" --yaml-multiline-string-style STYLE, -L STYLE set multiline string style to STYLE, default is 'double-quotes' --yaml-dump-null-as-empty dumps all none-type entries as empty, default is dumping as 'null' --targets TARGET [TARGET ...], -t TARGET [TARGET ...] targets to compile, default is all --labels [key=value ...], -l [key=value ...] compile targets matching the labels, default is all ```","title":"help"},{"location":"pages/commands/kapitan_dotfile/","text":"CLI Reference | .kapitan config file .kapitan Kapitan allows you to coveniently override defaults by specifying a local .kapitan file in the root of your repository (relative to the kapitan configuration): This comes handy to make sure Kapitan runs consistently for your specific setup. Info Any Kapitan command can be overridden in the .kapitan dotfile, but here are some of the most common examples. version To enforce the Kapitan version used for compilation (for consistency and safety), you can add version to .kapitan : version : 0.30.0 ... This constrain can be relaxed to allow minor versions to be also accepted: version : 0.30 # Allows any 0.30.x release to run ... compile You can also permanently define all command line flags in the .kapitan config file. For example: ... compile : indent : 4 parallelism : 8 would be equivalent to running: kapitan compile --indent 4 --parallelism 8 inventory In some cases, you might want to store the inventory under a different directory. You can configure the inventory section of the Kapitan dotfile to make sure it's persisted across all Kapitan runs. ... inventory : inventory-path : ./some_path which would be equivalent to always running: kapitan inventory --inventory-path = ./some_path","title":"kapitan dotfile"},{"location":"pages/commands/kapitan_dotfile/#cli-reference-kapitan-config-file","text":"","title":" CLI Reference | .kapitan config file"},{"location":"pages/commands/kapitan_dotfile/#kapitan","text":"Kapitan allows you to coveniently override defaults by specifying a local .kapitan file in the root of your repository (relative to the kapitan configuration): This comes handy to make sure Kapitan runs consistently for your specific setup. Info Any Kapitan command can be overridden in the .kapitan dotfile, but here are some of the most common examples.","title":".kapitan"},{"location":"pages/commands/kapitan_dotfile/#version","text":"To enforce the Kapitan version used for compilation (for consistency and safety), you can add version to .kapitan : version : 0.30.0 ... This constrain can be relaxed to allow minor versions to be also accepted: version : 0.30 # Allows any 0.30.x release to run ...","title":"version"},{"location":"pages/commands/kapitan_dotfile/#compile","text":"You can also permanently define all command line flags in the .kapitan config file. For example: ... compile : indent : 4 parallelism : 8 would be equivalent to running: kapitan compile --indent 4 --parallelism 8","title":"compile"},{"location":"pages/commands/kapitan_dotfile/#inventory","text":"In some cases, you might want to store the inventory under a different directory. You can configure the inventory section of the Kapitan dotfile to make sure it's persisted across all Kapitan runs. ... inventory : inventory-path : ./some_path which would be equivalent to always running: kapitan inventory --inventory-path = ./some_path","title":"inventory"},{"location":"pages/commands/kapitan_inventory/","text":"CLI Reference | kapitan inventory kapitan inventory Renders the resulting inventory values for a specific target. For example, rendering the inventory for the mysql target: kapitan inventory -t mysql click to expand output __reclass__ : environment : base name : mysql node : mysql timestamp : Wed Nov 23 23:19:28 2022 uri : yaml_fs:///src/inventory/targets/examples/mysql.yml applications : [] classes : - kapitan.kube - kapitan.generators.kubernetes - kapitan.generators.argocd - kapitan.generators.terraform - kapitan.generators.rabbitmq - kapitan.common - common - components.mysql environment : base exports : {} parameters : _reclass_ : environment : base name : full : mysql short : mysql components : mysql : config_maps : config : data : mysql.cnf : value : ignore-db-dir=lost+found mytemplate.cnf : template : components/mysql/mytemplate.cnf.j2 values : mysql : client : port : 3306 socket : /var/run/mysqld/mysqld.sock mysqld : bind-address : 127.0.0.1 max_allowed_packet : 64M thread_concurrency : 8 mount : /etc/mysql/conf.d/ env : MYSQL_DATABASE : '' MYSQL_PASSWORD : secretKeyRef : key : mysql-password MYSQL_ROOT_PASSWORD : secretKeyRef : key : mysql-root-password MYSQL_USER : '' image : mysql:5.7.28 ports : mysql : service_port : 3306 secrets : secrets : data : mysql-password : value : ?{plain:targets/mysql/mysql-password||randomstr|base64} mysql-root-password : value : ?{plain:targets/mysql/mysql-root-password||randomstr:32|base64} versioned : true type : statefulset volume_claims : datadir : spec : accessModes : - ReadWriteOnce resources : requests : storage : 10Gi storageClassName : standard volume_mounts : datadir : mountPath : /var/lib/mysql docs : - templates/docs/README.md generators : manifest : default_config : annotations : manifests.kapicorp.com/generated : 'true' service_account : create : false type : deployment kapitan : compile : - input_paths : - components/generators/kubernetes input_type : kadet output_path : manifests output_type : yml - input_params : function : generate_docs template_path : templates/docs/service_component.md.j2 input_paths : - components/generators/kubernetes input_type : kadet output_path : docs output_type : plain - input_params : function : generate_pre_deploy input_paths : - components/generators/kubernetes input_type : kadet output_path : pre-deploy output_type : yml - input_paths : - components/generators/argocd input_type : kadet output_path : argocd output_type : yml - input_params : generator_root : resources.tf input_paths : - components/generators/terraform input_type : kadet output_path : terraform output_type : json - ignore_missing : true input_paths : - resources/state/mysql/.terraform.lock.hcl input_type : copy output_path : terraform/ - input_paths : - components/generators/rabbitmq input_type : kadet output_path : rabbitmq output_type : yml - input_paths : - templates/docs/README.md input_type : jinja2 output_path : docs - input_paths : [] input_type : jinja2 output_path : scripts - input_paths : [] input_type : jsonnet output_path : manifests output_type : yml dependencies : - output_path : lib/kube.libsonnet source : https://raw.githubusercontent.com/bitnami-labs/kube-libsonnet/master/kube.libsonnet type : https - output_path : lib/kube-platforms.libsonnet source : https://raw.githubusercontent.com/bitnami-labs/kube-libsonnet/master/kube-platforms.libsonnet type : https - output_path : components/generators/kubernetes ref : master source : https://github.com/kapicorp/kapitan-reference.git subdir : components/generators/kubernetes type : git - output_path : components/generators/terraform ref : master source : https://github.com/kapicorp/kapitan-reference.git subdir : components/generators/terraform type : git vars : target : mysql manifests : [] mysql : settings : client : port : 3306 socket : /var/run/mysqld/mysqld.sock mysqld : bind-address : 127.0.0.1 max_allowed_packet : 64M thread_concurrency : 8 namespace : mysql scripts : [] target_name : mysql","title":"inventory"},{"location":"pages/commands/kapitan_inventory/#cli-reference-kapitan-inventory","text":"","title":" CLI Reference | kapitan inventory"},{"location":"pages/commands/kapitan_inventory/#kapitan-inventory","text":"Renders the resulting inventory values for a specific target. For example, rendering the inventory for the mysql target: kapitan inventory -t mysql click to expand output __reclass__ : environment : base name : mysql node : mysql timestamp : Wed Nov 23 23:19:28 2022 uri : yaml_fs:///src/inventory/targets/examples/mysql.yml applications : [] classes : - kapitan.kube - kapitan.generators.kubernetes - kapitan.generators.argocd - kapitan.generators.terraform - kapitan.generators.rabbitmq - kapitan.common - common - components.mysql environment : base exports : {} parameters : _reclass_ : environment : base name : full : mysql short : mysql components : mysql : config_maps : config : data : mysql.cnf : value : ignore-db-dir=lost+found mytemplate.cnf : template : components/mysql/mytemplate.cnf.j2 values : mysql : client : port : 3306 socket : /var/run/mysqld/mysqld.sock mysqld : bind-address : 127.0.0.1 max_allowed_packet : 64M thread_concurrency : 8 mount : /etc/mysql/conf.d/ env : MYSQL_DATABASE : '' MYSQL_PASSWORD : secretKeyRef : key : mysql-password MYSQL_ROOT_PASSWORD : secretKeyRef : key : mysql-root-password MYSQL_USER : '' image : mysql:5.7.28 ports : mysql : service_port : 3306 secrets : secrets : data : mysql-password : value : ?{plain:targets/mysql/mysql-password||randomstr|base64} mysql-root-password : value : ?{plain:targets/mysql/mysql-root-password||randomstr:32|base64} versioned : true type : statefulset volume_claims : datadir : spec : accessModes : - ReadWriteOnce resources : requests : storage : 10Gi storageClassName : standard volume_mounts : datadir : mountPath : /var/lib/mysql docs : - templates/docs/README.md generators : manifest : default_config : annotations : manifests.kapicorp.com/generated : 'true' service_account : create : false type : deployment kapitan : compile : - input_paths : - components/generators/kubernetes input_type : kadet output_path : manifests output_type : yml - input_params : function : generate_docs template_path : templates/docs/service_component.md.j2 input_paths : - components/generators/kubernetes input_type : kadet output_path : docs output_type : plain - input_params : function : generate_pre_deploy input_paths : - components/generators/kubernetes input_type : kadet output_path : pre-deploy output_type : yml - input_paths : - components/generators/argocd input_type : kadet output_path : argocd output_type : yml - input_params : generator_root : resources.tf input_paths : - components/generators/terraform input_type : kadet output_path : terraform output_type : json - ignore_missing : true input_paths : - resources/state/mysql/.terraform.lock.hcl input_type : copy output_path : terraform/ - input_paths : - components/generators/rabbitmq input_type : kadet output_path : rabbitmq output_type : yml - input_paths : - templates/docs/README.md input_type : jinja2 output_path : docs - input_paths : [] input_type : jinja2 output_path : scripts - input_paths : [] input_type : jsonnet output_path : manifests output_type : yml dependencies : - output_path : lib/kube.libsonnet source : https://raw.githubusercontent.com/bitnami-labs/kube-libsonnet/master/kube.libsonnet type : https - output_path : lib/kube-platforms.libsonnet source : https://raw.githubusercontent.com/bitnami-labs/kube-libsonnet/master/kube-platforms.libsonnet type : https - output_path : components/generators/kubernetes ref : master source : https://github.com/kapicorp/kapitan-reference.git subdir : components/generators/kubernetes type : git - output_path : components/generators/terraform ref : master source : https://github.com/kapicorp/kapitan-reference.git subdir : components/generators/terraform type : git vars : target : mysql manifests : [] mysql : settings : client : port : 3306 socket : /var/run/mysqld/mysqld.sock mysqld : bind-address : 127.0.0.1 max_allowed_packet : 64M thread_concurrency : 8 namespace : mysql scripts : [] target_name : mysql","title":"kapitan inventory"},{"location":"pages/commands/kapitan_lint/","text":"CLI Reference | kapitan lint kapitan lint Perform a checkup on your inventory or refs. ./kapitan lint click to expand output Running yamllint on all inventory files... .yamllint not found. Using default values File ./inventory/classes/components/echo-server.yml has the following issues: 95 :29: forbidden implicit octal value \"0550\" ( octal-values ) File ./inventory/classes/terraform/gcp/services.yml has the following issues: 15 :11: duplication of key \"enable_compute_service\" in mapping ( key-duplicates ) Total yamllint issues found: 2 Checking for orphan classes in inventory... No usage found for the following 6 classes: { 'components.argoproj.cd.argocd-server-oidc' , 'components.helm.cert-manager-helm' , 'components.rabbitmq-operator.rabbitmq-configuration' , 'components.rabbitmq-operator.rabbitmq-operator' , 'features.gkms-demo' , 'projects.localhost.kubernetes.katacoda' }","title":"lint"},{"location":"pages/commands/kapitan_lint/#cli-reference-kapitan-lint","text":"","title":" CLI Reference | kapitan lint"},{"location":"pages/commands/kapitan_lint/#kapitan-lint","text":"Perform a checkup on your inventory or refs. ./kapitan lint click to expand output Running yamllint on all inventory files... .yamllint not found. Using default values File ./inventory/classes/components/echo-server.yml has the following issues: 95 :29: forbidden implicit octal value \"0550\" ( octal-values ) File ./inventory/classes/terraform/gcp/services.yml has the following issues: 15 :11: duplication of key \"enable_compute_service\" in mapping ( key-duplicates ) Total yamllint issues found: 2 Checking for orphan classes in inventory... No usage found for the following 6 classes: { 'components.argoproj.cd.argocd-server-oidc' , 'components.helm.cert-manager-helm' , 'components.rabbitmq-operator.rabbitmq-configuration' , 'components.rabbitmq-operator.rabbitmq-operator' , 'features.gkms-demo' , 'projects.localhost.kubernetes.katacoda' }","title":"kapitan lint"},{"location":"pages/commands/kapitan_searchvar/","text":"CLI Reference | kapitan searchvar kapitan searchvar Shows all inventory files where a variable is declared: ./kapitan searchvar parameters.components.*.image click to expand output ./inventory/classes/components/vault.yml ${ vault : image } ./inventory/classes/components/logstash.yml eu.gcr.io/antha-images/logstash:7.5.1 ./inventory/classes/components/gke-pvm-killer.yml estafette/estafette-gke-preemptible-killer:1.2.5 ./inventory/classes/components/mysql.yml mysql:5.7.28 ./inventory/classes/components/postgres-proxy.yml gcr.io/cloudsql-docker/gce-proxy:1.16 ./inventory/classes/components/echo-server.yml jmalloc/echo-server ./inventory/classes/components/trivy.yml ${ trivy : image } ./inventory/classes/components/filebeat.yml ${ filebeat : image } : ${ filebeat : version } ./inventory/classes/components/pritunl/pritunl-mongo.yml docker.io/bitnami/mongodb:4.2.6-debian-10-r23 ./inventory/classes/components/pritunl/pritunl.yml alledm/pritunl ./inventory/classes/components/weaveworks/user-db.yml weaveworksdemos/user-db:0.3.0 ./inventory/classes/components/weaveworks/catalogue.yml weaveworksdemos/catalogue:0.3.5 ./inventory/classes/components/weaveworks/user.yml weaveworksdemos/user:0.4.7 ./inventory/classes/components/weaveworks/session-db.yml redis:alpine ./inventory/classes/components/weaveworks/catalogue-db.yml weaveworksdemos/catalogue-db:0.3.0 ./inventory/classes/components/weaveworks/carts-db.yml mongo ./inventory/classes/components/weaveworks/orders-db.yml mongo ./inventory/classes/components/weaveworks/orders.yml weaveworksdemos/orders:0.4.7 ./inventory/classes/components/weaveworks/shipping.yml weaveworksdemos/shipping:0.4.8 ./inventory/classes/components/weaveworks/queue-master.yml weaveworksdemos/queue-master:0.3.1 ./inventory/classes/components/weaveworks/rabbitmq.yml rabbitmq:3.6.8-management ./inventory/classes/components/weaveworks/payment.yml weaveworksdemos/payment:0.4.3 ./inventory/classes/components/weaveworks/front-end.yml weaveworksdemos/front-end:0.3.12 ./inventory/classes/components/weaveworks/carts.yml weaveworksdemos/carts:0.4.8 ./inventory/classes/components/kapicorp/tesoro.yml kapicorp/tesoro","title":"searchvar"},{"location":"pages/commands/kapitan_searchvar/#cli-reference-kapitan-searchvar","text":"","title":" CLI Reference | kapitan searchvar"},{"location":"pages/commands/kapitan_searchvar/#kapitan-searchvar","text":"Shows all inventory files where a variable is declared: ./kapitan searchvar parameters.components.*.image click to expand output ./inventory/classes/components/vault.yml ${ vault : image } ./inventory/classes/components/logstash.yml eu.gcr.io/antha-images/logstash:7.5.1 ./inventory/classes/components/gke-pvm-killer.yml estafette/estafette-gke-preemptible-killer:1.2.5 ./inventory/classes/components/mysql.yml mysql:5.7.28 ./inventory/classes/components/postgres-proxy.yml gcr.io/cloudsql-docker/gce-proxy:1.16 ./inventory/classes/components/echo-server.yml jmalloc/echo-server ./inventory/classes/components/trivy.yml ${ trivy : image } ./inventory/classes/components/filebeat.yml ${ filebeat : image } : ${ filebeat : version } ./inventory/classes/components/pritunl/pritunl-mongo.yml docker.io/bitnami/mongodb:4.2.6-debian-10-r23 ./inventory/classes/components/pritunl/pritunl.yml alledm/pritunl ./inventory/classes/components/weaveworks/user-db.yml weaveworksdemos/user-db:0.3.0 ./inventory/classes/components/weaveworks/catalogue.yml weaveworksdemos/catalogue:0.3.5 ./inventory/classes/components/weaveworks/user.yml weaveworksdemos/user:0.4.7 ./inventory/classes/components/weaveworks/session-db.yml redis:alpine ./inventory/classes/components/weaveworks/catalogue-db.yml weaveworksdemos/catalogue-db:0.3.0 ./inventory/classes/components/weaveworks/carts-db.yml mongo ./inventory/classes/components/weaveworks/orders-db.yml mongo ./inventory/classes/components/weaveworks/orders.yml weaveworksdemos/orders:0.4.7 ./inventory/classes/components/weaveworks/shipping.yml weaveworksdemos/shipping:0.4.8 ./inventory/classes/components/weaveworks/queue-master.yml weaveworksdemos/queue-master:0.3.1 ./inventory/classes/components/weaveworks/rabbitmq.yml rabbitmq:3.6.8-management ./inventory/classes/components/weaveworks/payment.yml weaveworksdemos/payment:0.4.3 ./inventory/classes/components/weaveworks/front-end.yml weaveworksdemos/front-end:0.3.12 ./inventory/classes/components/weaveworks/carts.yml weaveworksdemos/carts:0.4.8 ./inventory/classes/components/kapicorp/tesoro.yml kapicorp/tesoro","title":"kapitan searchvar"},{"location":"pages/commands/kapitan_validate/","text":"CLI Reference | kapitan validate kapitan validate Validates the schema of compiled output. Validate options are specified in the inventory under parameters.kapitan.validate . Supported types are: Usage standalone manual with kapitan compile automatic with .kapitan dotfile kapitan validate click to expand output created schema-cache-path at ./schemas Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_secret.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_jsonnet.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_simple.yml kapitan compile --validate click to expand output Rendered inventory ( 0 .27s ) Compiled labels ( 0 .23s ) Compiled removal ( 0 .00s ) Compiled busybox ( 0 .24s ) Compiled minikube-nginx-jsonnet ( 0 .49s ) Compiled minikube-nginx-kadet ( 0 .25s ) Compiled minikube-mysql ( 0 .59s ) Compiled minikube-es ( 1 .17s ) Compiled all-glob ( 1 .55s ) Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_secret.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_jsonnet.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_simple.yml You can leverage the .kapitan dotfile to make sure validate runs every time you run compile. example .kapitan ... compile : validate : true The validate command will now be implied for every compile run kapitan compile click to expand output Rendered inventory ( 0 .27s ) Compiled labels ( 0 .23s ) Compiled removal ( 0 .00s ) Compiled busybox ( 0 .24s ) Compiled minikube-nginx-jsonnet ( 0 .49s ) Compiled minikube-nginx-kadet ( 0 .25s ) Compiled minikube-mysql ( 0 .59s ) Compiled minikube-es ( 1 .17s ) Compiled all-glob ( 1 .55s ) Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_secret.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_jsonnet.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_simple.yml Kubernetes Setup Kubernetes has different resource kinds, for instance: service deployment statefulset Kapitan has built in support for validation of Kubernetes kinds, and automatically integrates with https://kubernetesjsonschema.dev . See github.com/instrumenta/kubernetes-json-schema for more informations. Info Kapitan will automatically download the schemas for Kubernetes Manifests directly from https://kubernetesjsonschema.dev By default, the schemas are cached into ./schemas/ , which can be modified with the --schemas-path option. override permanently schema-path Remember to use the .kapitan dotfile configuration to override permanently the schema-path location. $ cat .kapitan # other options abbreviated for clarity validate: schemas-path: custom/schemas/cache/path Example Refer to the mysql example. kubernetes/inventory/classes/component/mysql.yml validate : - type : kubernetes # mkdocs (1)! output_paths : # mkdocs (2)! - manifests/mysql_secret.yml kind : secret # temporarily replaced with 'deployment' during test # mkdocs (3)! version : 1.14.0 # optional, defaults to 1.14.0 # mkdocs (4)! - type : kubernetes output_paths : - manifests/mysql_service_jsonnet.yml - manifests/mysql_service_simple.yml kind : service version : 1.14.0 type | currently only Kubernetes is supported output_paths | list of files to validate kind | a Kubernetes resource kind version | a Kubernetes API version, defaults to 1.14.0","title":"validate"},{"location":"pages/commands/kapitan_validate/#cli-reference-kapitan-validate","text":"","title":" CLI Reference | kapitan validate"},{"location":"pages/commands/kapitan_validate/#kapitan-validate","text":"Validates the schema of compiled output. Validate options are specified in the inventory under parameters.kapitan.validate . Supported types are:","title":"kapitan validate"},{"location":"pages/commands/kapitan_validate/#usage","text":"standalone manual with kapitan compile automatic with .kapitan dotfile kapitan validate click to expand output created schema-cache-path at ./schemas Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_secret.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_jsonnet.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_simple.yml kapitan compile --validate click to expand output Rendered inventory ( 0 .27s ) Compiled labels ( 0 .23s ) Compiled removal ( 0 .00s ) Compiled busybox ( 0 .24s ) Compiled minikube-nginx-jsonnet ( 0 .49s ) Compiled minikube-nginx-kadet ( 0 .25s ) Compiled minikube-mysql ( 0 .59s ) Compiled minikube-es ( 1 .17s ) Compiled all-glob ( 1 .55s ) Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_secret.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_jsonnet.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_simple.yml You can leverage the .kapitan dotfile to make sure validate runs every time you run compile. example .kapitan ... compile : validate : true The validate command will now be implied for every compile run kapitan compile click to expand output Rendered inventory ( 0 .27s ) Compiled labels ( 0 .23s ) Compiled removal ( 0 .00s ) Compiled busybox ( 0 .24s ) Compiled minikube-nginx-jsonnet ( 0 .49s ) Compiled minikube-nginx-kadet ( 0 .25s ) Compiled minikube-mysql ( 0 .59s ) Compiled minikube-es ( 1 .17s ) Compiled all-glob ( 1 .55s ) Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_secret.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_jsonnet.yml Validation: manifest validation successful for ./compiled/minikube-mysql/manifests/mysql_service_simple.yml","title":"Usage"},{"location":"pages/commands/kapitan_validate/#kubernetes-setup","text":"Kubernetes has different resource kinds, for instance: service deployment statefulset Kapitan has built in support for validation of Kubernetes kinds, and automatically integrates with https://kubernetesjsonschema.dev . See github.com/instrumenta/kubernetes-json-schema for more informations. Info Kapitan will automatically download the schemas for Kubernetes Manifests directly from https://kubernetesjsonschema.dev By default, the schemas are cached into ./schemas/ , which can be modified with the --schemas-path option. override permanently schema-path Remember to use the .kapitan dotfile configuration to override permanently the schema-path location. $ cat .kapitan # other options abbreviated for clarity validate: schemas-path: custom/schemas/cache/path","title":"Kubernetes Setup"},{"location":"pages/commands/kapitan_validate/#example","text":"Refer to the mysql example. kubernetes/inventory/classes/component/mysql.yml validate : - type : kubernetes # mkdocs (1)! output_paths : # mkdocs (2)! - manifests/mysql_secret.yml kind : secret # temporarily replaced with 'deployment' during test # mkdocs (3)! version : 1.14.0 # optional, defaults to 1.14.0 # mkdocs (4)! - type : kubernetes output_paths : - manifests/mysql_service_jsonnet.yml - manifests/mysql_service_simple.yml kind : service version : 1.14.0 type | currently only Kubernetes is supported output_paths | list of files to validate kind | a Kubernetes resource kind version | a Kubernetes API version, defaults to 1.14.0","title":"Example"},{"location":"pages/contribute/code/","tags":["community"],"text":"Kapitan code Many of our features come from contributions from external collaborators. Please help us improve Kapitan by extending it with your ideas, or help us squash bugs you discover. It's simple, just send us a PR with your improvements! Submitting code We would like ask you to fork Kapitan project and create a Pull Request targeting master branch. All submissions, including submissions by project members, require review. Setup We highly recommend that you create a dedicated Python environment for Kapitan. There are multiple solutions: pyenv virtualenv venv Once you've done it, please install all Kapitan's dependencies: python3 -m venv env source env/bin/activate pip3 install black # required for `make test_formatting` pip3 install -r requirements.txt Because we are using a pinned version of reclass which is added as a submodule into Kapitan's repository, you need to pull it separately by executing the command below: git submodule update --init Troubleshoot Check if gcc is installed: brew install gcc@5 Testing Run make test to run all tests. If you modify anything in the examples/ folder make sure you replicate the compiled result of that in tests/test_kubernetes_compiled . If you add new features, run make test_coverage && make test_formatting to make sure the test coverage remains at current or better levels and that code formatting is applied. If you would like to evaluate your changes by running your version of Kapitan, you can do that by running bin/kapitan from this repository or even setting an alias to it. python3 -m unittest tests/test_vault_transit.py Code Style To make sure you adhere to the Style Guide for Python (PEP8) Python Black is used to apply the formatting so make sure you have it installed with pip3 install black . Apply via Git hook Run pip3 install pre-commit to install precommit framework. In the Kapitan root directory, run pre-commit install Git add/commit any changed files you want. Apply manually Run make format_codestyle before submitting. Release process Create a branch named release-v<NUMBER> . Use v0.*.*-rc.* if you want pre-release versions to be uploaded. Update CHANGELOG.md with the release changes. Once reviewed and merged, Github Actions will auto-release. The merge has to happen with a merge commit not with squash/rebase so that the commit message still mentions kapicorp/release-v* inside. Packaging extra resources in python package To package any extra resources/files in the pip package, make sure you modify both MANIFEST.in . Leave a comment","title":"Kapitan Code"},{"location":"pages/contribute/code/#kapitan-code","text":"Many of our features come from contributions from external collaborators. Please help us improve Kapitan by extending it with your ideas, or help us squash bugs you discover. It's simple, just send us a PR with your improvements!","title":" Kapitan code"},{"location":"pages/contribute/code/#submitting-code","text":"We would like ask you to fork Kapitan project and create a Pull Request targeting master branch. All submissions, including submissions by project members, require review.","title":"Submitting code"},{"location":"pages/contribute/code/#setup","text":"We highly recommend that you create a dedicated Python environment for Kapitan. There are multiple solutions: pyenv virtualenv venv Once you've done it, please install all Kapitan's dependencies: python3 -m venv env source env/bin/activate pip3 install black # required for `make test_formatting` pip3 install -r requirements.txt Because we are using a pinned version of reclass which is added as a submodule into Kapitan's repository, you need to pull it separately by executing the command below: git submodule update --init","title":"Setup"},{"location":"pages/contribute/code/#troubleshoot","text":"Check if gcc is installed: brew install gcc@5","title":"Troubleshoot"},{"location":"pages/contribute/code/#testing","text":"Run make test to run all tests. If you modify anything in the examples/ folder make sure you replicate the compiled result of that in tests/test_kubernetes_compiled . If you add new features, run make test_coverage && make test_formatting to make sure the test coverage remains at current or better levels and that code formatting is applied. If you would like to evaluate your changes by running your version of Kapitan, you can do that by running bin/kapitan from this repository or even setting an alias to it. python3 -m unittest tests/test_vault_transit.py","title":"Testing"},{"location":"pages/contribute/code/#code-style","text":"To make sure you adhere to the Style Guide for Python (PEP8) Python Black is used to apply the formatting so make sure you have it installed with pip3 install black .","title":"Code Style"},{"location":"pages/contribute/code/#apply-via-git-hook","text":"Run pip3 install pre-commit to install precommit framework. In the Kapitan root directory, run pre-commit install Git add/commit any changed files you want.","title":"Apply via Git hook"},{"location":"pages/contribute/code/#apply-manually","text":"Run make format_codestyle before submitting.","title":"Apply manually"},{"location":"pages/contribute/code/#release-process","text":"Create a branch named release-v<NUMBER> . Use v0.*.*-rc.* if you want pre-release versions to be uploaded. Update CHANGELOG.md with the release changes. Once reviewed and merged, Github Actions will auto-release. The merge has to happen with a merge commit not with squash/rebase so that the commit message still mentions kapicorp/release-v* inside.","title":"Release process"},{"location":"pages/contribute/code/#packaging-extra-resources-in-python-package","text":"To package any extra resources/files in the pip package, make sure you modify both MANIFEST.in .","title":"Packaging extra resources in python package"},{"location":"pages/contribute/code/#leave-a-comment","text":"","title":"Leave a comment"},{"location":"pages/contribute/documentation/","tags":["community"],"text":"Documentation Our documentation usully prevents new users from adopting Kapitan . Help us improve by contributing with fixes and keeping it up-to-date. Articles Write articles on Kapitan and share your way of working. Inspire others, and reach out to have your article published / endorsed by us. This Website Find something odd? Let us know or change it yourself: you can edit pages of this website on Github by clicking the pencil icon at the top right of this page! Update documentation We use mkdocs to generate our gh-pages from .md files under docs/ folder. Updating our gh-pages is therefore a two-step process. Update the markdown Submit a PR for our master branch that updates the .md file(s). Test how the changes would look like when deployed to gh-pages by serving it on localhost: make local_serve_documentation Submit a PR Once the above PR has been merged, use mkdocs gh-deploy command to push the commit that updates the site content to your own gh-pages branch. Make sure that you already have this gh-pages branch in your fork that is up-to-date with our gh-pages branch such that the two branches share the commit history (otherwise Github would not allow PRs to be created). # locally, on master branch (which has your updated docs) COMMIT_MSG=\"your commit message to replace\" make mkdocs_gh_deploy After it's pushed, create a PR that targets our gh-pages branch from your gh-pages branch.","title":"Documentation"},{"location":"pages/contribute/documentation/#documentation","text":"Our documentation usully prevents new users from adopting Kapitan . Help us improve by contributing with fixes and keeping it up-to-date.","title":" Documentation"},{"location":"pages/contribute/documentation/#articles","text":"Write articles on Kapitan and share your way of working. Inspire others, and reach out to have your article published / endorsed by us.","title":"Articles"},{"location":"pages/contribute/documentation/#this-website","text":"Find something odd? Let us know or change it yourself: you can edit pages of this website on Github by clicking the pencil icon at the top right of this page!","title":"This Website"},{"location":"pages/contribute/documentation/#update-documentation","text":"We use mkdocs to generate our gh-pages from .md files under docs/ folder. Updating our gh-pages is therefore a two-step process.","title":"Update documentation"},{"location":"pages/contribute/documentation/#update-the-markdown","text":"Submit a PR for our master branch that updates the .md file(s). Test how the changes would look like when deployed to gh-pages by serving it on localhost: make local_serve_documentation","title":"Update the markdown"},{"location":"pages/contribute/documentation/#submit-a-pr","text":"Once the above PR has been merged, use mkdocs gh-deploy command to push the commit that updates the site content to your own gh-pages branch. Make sure that you already have this gh-pages branch in your fork that is up-to-date with our gh-pages branch such that the two branches share the commit history (otherwise Github would not allow PRs to be created). # locally, on master branch (which has your updated docs) COMMIT_MSG=\"your commit message to replace\" make mkdocs_gh_deploy After it's pushed, create a PR that targets our gh-pages branch from your gh-pages branch.","title":"Submit a PR"},{"location":"pages/contribute/sponsor/","tags":["community"],"text":"Sponsor Kapitan Do you want to help the project? Great! There are many ways to do it We accept donations throught GitHubs Sponsors . Alternatively reach out for other ways to support us. Companies and individuals sponsoring us on a regular base will be recognised and called out on our website","title":"Sponsor Us"},{"location":"pages/contribute/sponsor/#sponsor-kapitan","text":"Do you want to help the project? Great! There are many ways to do it We accept donations throught GitHubs Sponsors . Alternatively reach out for other ways to support us. Companies and individuals sponsoring us on a regular base will be recognised and called out on our website","title":" Sponsor Kapitan"},{"location":"pages/contribute/talk/","text":"Talk about Kapitan Our project needs your support to get noticed! Please let everyone know that you are using Kapitan Help us grow: give us a star Join us on kubernetes.slack.com #kapitan ( Get invited ) Tweet about us on Twitter . Remember to add @kapitandev to your tweets Share our website https://kapitan.dev Write tutorials and blog posts and join the many who have done it already! Get published on the Kapitan Blog Share what Kapitan does for you and for your company Inspire your colleagues and network on LinkedIn","title":"Talk about Kapitan"},{"location":"pages/contribute/talk/#talk-about-kapitan","text":"Our project needs your support to get noticed! Please let everyone know that you are using Kapitan Help us grow: give us a star Join us on kubernetes.slack.com #kapitan ( Get invited ) Tweet about us on Twitter . Remember to add @kapitandev to your tweets Share our website https://kapitan.dev Write tutorials and blog posts and join the many who have done it already! Get published on the Kapitan Blog Share what Kapitan does for you and for your company Inspire your colleagues and network on LinkedIn","title":" Talk about Kapitan"},{"location":"pages/examples/kubernetes/","tags":["kubernetes"],"text":"Kubernetes examples Here, we walk through how kapitan could be used to help create kubernetes manifests, whose values are customized for each target according to the inventory structure. The example folder can be found in our repository on Github at https://github.com/kapicorp/kapitan/tree/master/examples/kubernetes . Directory structure The following tree shows what this directory looks like (only showing tree level 1): \u251c\u2500\u2500 components \u251c\u2500\u2500 docs \u251c\u2500\u2500 inventory \u251c\u2500\u2500 lib \u251c\u2500\u2500 scripts \u251c\u2500\u2500 refs \u2514\u2500\u2500 templates We will describe the role of each folder in the following sections. inventory This folder contains the inventory values used to render the templates for each target. The structure of this folder is as follows: . \u251c\u2500\u2500 classes \u2502 \u251c\u2500\u2500 cluster \u2502 \u2502 \u251c\u2500\u2500 common.yml \u2502 \u2502 \u2514\u2500\u2500 minikube.yml \u2502 \u251c\u2500\u2500 common.yml \u2502 \u2514\u2500\u2500 component \u2502 \u251c\u2500\u2500 elasticsearch.yml \u2502 \u251c\u2500\u2500 mysql.yml \u2502 \u251c\u2500\u2500 namespace.yml \u2502 \u2514\u2500\u2500 nginx.yml \u2514\u2500\u2500 targets \u251c\u2500\u2500 minikube-es.yml \u251c\u2500\u2500 minikube-mysql.yml \u2514\u2500\u2500 minikube-nginx.yml The required sub-folder is targets : during compile, kapitan searches for the yaml files under targets in order to identify the targets. In this example, there are three targets: minikube-es minikube-mysql minikube-nginx Therefore, when you run kapitan compile , under the compiled folder that kapitan generates, you will see three folders named after these targets. classes is a folder that contains yaml files used as the \"base class\" in the hierarchical inventory database. The values defined here are inherited by the target files. For more explanation on how this works, look at the inventory documentation . Notice how the classes are nicely divided up into components and clusters, such as nginx and mysql, in order to clearly define what components each target should contain and to make the classes reusable. For example, take a look at targets/nginx.yml : classes : - common - cluster.minikube - component.namespace - component.nginx parameters : target_name : minikube-nginx namespace : ${target_name} This target inherits values from four files under classes folder: common.yml cluster/minikube.yml component/namespace.yml component/nginx.yml Note: that some of these classes themselves may inherit from other classes. And the way classes are defined makes it easy to identify what components and clusters this target should contain and belong to! Let's take a close look now at component/namespace.yml : parameters : namespace : ${target_name} kapitan : compile : - output_path : pre-deploy input_type : jsonnet output_type : yaml input_paths : - components/namespace/main.jsonnet As we see, this file declares a kapitan.compile item whose input path (i.e. the template file) is components/namespace/main.jsonnet which, when rendered, will generate yaml file(s) under compiled/minikube-nginx/pre-deploy . Don't confuse the components folder with inventory/classes/components folder: the former contains the actual templates, while the latter contains inventory classes. components This folder contains the template files as discussed above, typically jsonnet and kadet files. The tree of this directory looks as follows: . \u251c\u2500\u2500 elasticsearch \u2502 \u251c\u2500\u2500 elasticsearch.container.jsonnet \u2502 \u251c\u2500\u2500 elasticsearch.statefulset.jsonnet \u2502 \u2514\u2500\u2500 main.jsonnet \u251c\u2500\u2500 mysql \u2502 \u251c\u2500\u2500 main.jsonnet \u2502 \u251c\u2500\u2500 secret.jsonnet \u2502 \u251c\u2500\u2500 service.jsonnet \u2502 \u2514\u2500\u2500 statefulset.jsonnet \u251c\u2500\u2500 namespace \u2502 \u2514\u2500\u2500 main.jsonnet \u2514\u2500\u2500 nginx \u2514\u2500\u2500 __init__.py Notice how the directory structure corresponds to that of inventory/classes/components in order to make it easy to identify which templates are used for which components. As mentioned above, we know that the target minikube-nginx inherits from component.namespace . Let's take a look at components/namespace/main.jsonnet : local kube = impor t \"lib/kube.libjsonnet\" ; local kap = impor t \"lib/kapitan.libjsonnet\" ; local i n ve nt ory = kap.i n ve nt ory(); local p = i n ve nt ory.parame ters ; { \"00_namespace\" : kube.Namespace(p. na mespace) , \"10_serviceaccount\" : kube.ServiceAccou nt ( \"default\" ) } The first two lines import libjsonnet files under lib folder: this is the folder that contains helper files used inside templates. For example, kapitan.libjsonnet allows you to access inventory values inside jsonnet templates, and kube.libjsonnet defines functions to generate popular kubernetes manifests. The actual object defined in components/namespace/main.jsonnet looks like this: { \"00_namespace\" : kube.Namespace(p. na mespace) , \"10_serviceaccount\" : kube.ServiceAccou nt ( \"default\" ) } We have \"00_namespace\" and \"10_serviceaccount\" as the keys. These will become files under compiled/minikube-nginx/pre-deploy , since pre-deploy is the input_paths declared in the inventory. For instance, 00_namespace.yml would look like this: apiVersion : v1 kind : Namespace metadata : annotations : {} labels : name : minikube-nginx name : minikube-nginx namespace : minikube-nginx spec : {} templates, docs, scripts These folders contain jinja2 template files. For example, component.elasticsearch contains: kapitan : compile : # other items abbreviated for clarity - output_path : scripts input_type : jinja2 input_paths : - scripts - output_path : . input_type : jinja2 input_paths : - docs/elasticsearch/README.md Since component.elasticsearch is inherited by the target minikube-es , this generates files under compiled/minikube-es/scripts and compiled/minikube-es/README.md . References This folder contains references created manually by the user, or automatically by kapitan. Refer to references management for how it works. In this example, the configuration, such as the recipients, is declared in inventory/classes/common.yml : parameters : kapitan : vars : target : ${target_name} namespace : ${target_name} secrets : gpg : recipients : - name : example@kapitan.dev fingerprint : D9234C61F58BEB3ED8552A57E28DC07A3CBFAE7C The references to the secrets are declared in inventory/classes/component/mysql , which is inherited by the target minikube-mysql . After running kapitan compile , some of the generated manifests contain the references to secrets. For example, have a look at compiled/minikube-mysql/manifests/mysql_secret.yml : apiVersion : v1 data : MYSQL_ROOT_PASSWORD : ?{gpg:targets/minikube-mysql/mysql/password:ec3d54de} MYSQL_ROOT_PASSWORD_SHA256 : ?{gpg:targets/minikube-mysql/mysql/password_sha256:122d2732} kind : Secret metadata : annotations : {} labels : name : example-mysql name : example-mysql namespace : minikube-mysql type : Opaque MYSQL_ROOT_PASSWORD refers to the secret stored in refs/targets/minikube-mysql/mysql/password and so on. You may reveal the secrets by running kapitan refs --reveal -f mysql_secret.yml and use the manifest by piping the output to kubectl!","title":"Kubernetes"},{"location":"pages/examples/kubernetes/#kubernetes-examples","text":"Here, we walk through how kapitan could be used to help create kubernetes manifests, whose values are customized for each target according to the inventory structure. The example folder can be found in our repository on Github at https://github.com/kapicorp/kapitan/tree/master/examples/kubernetes .","title":" Kubernetes examples"},{"location":"pages/examples/kubernetes/#directory-structure","text":"The following tree shows what this directory looks like (only showing tree level 1): \u251c\u2500\u2500 components \u251c\u2500\u2500 docs \u251c\u2500\u2500 inventory \u251c\u2500\u2500 lib \u251c\u2500\u2500 scripts \u251c\u2500\u2500 refs \u2514\u2500\u2500 templates We will describe the role of each folder in the following sections.","title":"Directory structure"},{"location":"pages/examples/kubernetes/#inventory","text":"This folder contains the inventory values used to render the templates for each target. The structure of this folder is as follows: . \u251c\u2500\u2500 classes \u2502 \u251c\u2500\u2500 cluster \u2502 \u2502 \u251c\u2500\u2500 common.yml \u2502 \u2502 \u2514\u2500\u2500 minikube.yml \u2502 \u251c\u2500\u2500 common.yml \u2502 \u2514\u2500\u2500 component \u2502 \u251c\u2500\u2500 elasticsearch.yml \u2502 \u251c\u2500\u2500 mysql.yml \u2502 \u251c\u2500\u2500 namespace.yml \u2502 \u2514\u2500\u2500 nginx.yml \u2514\u2500\u2500 targets \u251c\u2500\u2500 minikube-es.yml \u251c\u2500\u2500 minikube-mysql.yml \u2514\u2500\u2500 minikube-nginx.yml The required sub-folder is targets : during compile, kapitan searches for the yaml files under targets in order to identify the targets. In this example, there are three targets: minikube-es minikube-mysql minikube-nginx Therefore, when you run kapitan compile , under the compiled folder that kapitan generates, you will see three folders named after these targets. classes is a folder that contains yaml files used as the \"base class\" in the hierarchical inventory database. The values defined here are inherited by the target files. For more explanation on how this works, look at the inventory documentation . Notice how the classes are nicely divided up into components and clusters, such as nginx and mysql, in order to clearly define what components each target should contain and to make the classes reusable. For example, take a look at targets/nginx.yml : classes : - common - cluster.minikube - component.namespace - component.nginx parameters : target_name : minikube-nginx namespace : ${target_name} This target inherits values from four files under classes folder: common.yml cluster/minikube.yml component/namespace.yml component/nginx.yml Note: that some of these classes themselves may inherit from other classes. And the way classes are defined makes it easy to identify what components and clusters this target should contain and belong to! Let's take a close look now at component/namespace.yml : parameters : namespace : ${target_name} kapitan : compile : - output_path : pre-deploy input_type : jsonnet output_type : yaml input_paths : - components/namespace/main.jsonnet As we see, this file declares a kapitan.compile item whose input path (i.e. the template file) is components/namespace/main.jsonnet which, when rendered, will generate yaml file(s) under compiled/minikube-nginx/pre-deploy . Don't confuse the components folder with inventory/classes/components folder: the former contains the actual templates, while the latter contains inventory classes.","title":"inventory"},{"location":"pages/examples/kubernetes/#components","text":"This folder contains the template files as discussed above, typically jsonnet and kadet files. The tree of this directory looks as follows: . \u251c\u2500\u2500 elasticsearch \u2502 \u251c\u2500\u2500 elasticsearch.container.jsonnet \u2502 \u251c\u2500\u2500 elasticsearch.statefulset.jsonnet \u2502 \u2514\u2500\u2500 main.jsonnet \u251c\u2500\u2500 mysql \u2502 \u251c\u2500\u2500 main.jsonnet \u2502 \u251c\u2500\u2500 secret.jsonnet \u2502 \u251c\u2500\u2500 service.jsonnet \u2502 \u2514\u2500\u2500 statefulset.jsonnet \u251c\u2500\u2500 namespace \u2502 \u2514\u2500\u2500 main.jsonnet \u2514\u2500\u2500 nginx \u2514\u2500\u2500 __init__.py Notice how the directory structure corresponds to that of inventory/classes/components in order to make it easy to identify which templates are used for which components. As mentioned above, we know that the target minikube-nginx inherits from component.namespace . Let's take a look at components/namespace/main.jsonnet : local kube = impor t \"lib/kube.libjsonnet\" ; local kap = impor t \"lib/kapitan.libjsonnet\" ; local i n ve nt ory = kap.i n ve nt ory(); local p = i n ve nt ory.parame ters ; { \"00_namespace\" : kube.Namespace(p. na mespace) , \"10_serviceaccount\" : kube.ServiceAccou nt ( \"default\" ) } The first two lines import libjsonnet files under lib folder: this is the folder that contains helper files used inside templates. For example, kapitan.libjsonnet allows you to access inventory values inside jsonnet templates, and kube.libjsonnet defines functions to generate popular kubernetes manifests. The actual object defined in components/namespace/main.jsonnet looks like this: { \"00_namespace\" : kube.Namespace(p. na mespace) , \"10_serviceaccount\" : kube.ServiceAccou nt ( \"default\" ) } We have \"00_namespace\" and \"10_serviceaccount\" as the keys. These will become files under compiled/minikube-nginx/pre-deploy , since pre-deploy is the input_paths declared in the inventory. For instance, 00_namespace.yml would look like this: apiVersion : v1 kind : Namespace metadata : annotations : {} labels : name : minikube-nginx name : minikube-nginx namespace : minikube-nginx spec : {}","title":"components"},{"location":"pages/examples/kubernetes/#templates-docs-scripts","text":"These folders contain jinja2 template files. For example, component.elasticsearch contains: kapitan : compile : # other items abbreviated for clarity - output_path : scripts input_type : jinja2 input_paths : - scripts - output_path : . input_type : jinja2 input_paths : - docs/elasticsearch/README.md Since component.elasticsearch is inherited by the target minikube-es , this generates files under compiled/minikube-es/scripts and compiled/minikube-es/README.md .","title":"templates, docs, scripts"},{"location":"pages/examples/kubernetes/#references","text":"This folder contains references created manually by the user, or automatically by kapitan. Refer to references management for how it works. In this example, the configuration, such as the recipients, is declared in inventory/classes/common.yml : parameters : kapitan : vars : target : ${target_name} namespace : ${target_name} secrets : gpg : recipients : - name : example@kapitan.dev fingerprint : D9234C61F58BEB3ED8552A57E28DC07A3CBFAE7C The references to the secrets are declared in inventory/classes/component/mysql , which is inherited by the target minikube-mysql . After running kapitan compile , some of the generated manifests contain the references to secrets. For example, have a look at compiled/minikube-mysql/manifests/mysql_secret.yml : apiVersion : v1 data : MYSQL_ROOT_PASSWORD : ?{gpg:targets/minikube-mysql/mysql/password:ec3d54de} MYSQL_ROOT_PASSWORD_SHA256 : ?{gpg:targets/minikube-mysql/mysql/password_sha256:122d2732} kind : Secret metadata : annotations : {} labels : name : example-mysql name : example-mysql namespace : minikube-mysql type : Opaque MYSQL_ROOT_PASSWORD refers to the secret stored in refs/targets/minikube-mysql/mysql/password and so on. You may reveal the secrets by running kapitan refs --reveal -f mysql_secret.yml and use the manifest by piping the output to kubectl!","title":"References"},{"location":"pages/examples/terraform/","tags":["terraform"],"text":"Terraform example We will be looking at how to use Kapitan to compile terraform files with Jsonnet as the input type. It's possible to use other input types, however, Jsonnet is recommended. For example, we could use the Kadet input to generate terraform files but this would require templates to be written in YAML then rendered into JSON. It is possible to allow Kadet to consume JSON as an input. This enables you to integrate your organizations pre-existing terraform JSON file's as templates. Jsonnet is the most straightforward input type as you will see due to its functional nature. The only appropriate output type is JSON since this is the format that Terraform consumes. Directory structure There are several examples available in examples/terraform . This will be our working directory for this documentation. The directory structure is as follows: \u251c\u2500\u2500 inventory \u2514\u2500\u2500 templates It is possible to further extend this locally to include a lib directory where a terraform.libjsonnet file can be stored for use. This is generally dependent on the project scope and organizational patterns. We will describe in more detail the role of each of these folders in the following sections. inventory This folder contains the inventory files used to render the templates for each target. The structure of this folder is as follows: . \u251c\u2500\u2500 classes \u2502 \u251c\u2500\u2500 env \u2502 \u2502 \u251c\u2500\u2500 develop.yml \u2502 \u2502 \u251c\u2500\u2500 prod.yml \u2502 \u2502 \u2514\u2500\u2500 sandbox.yml \u2502 \u251c\u2500\u2500 provider \u2502 \u2502 \u2514\u2500\u2500 gcp.yml \u2502 \u2514\u2500\u2500 type \u2502 \u2514\u2500\u2500 terraform.yml \u251c\u2500\u2500 reclass-config.yml \u2514\u2500\u2500 targets \u251c\u2500\u2500 develop \u2502 \u2514\u2500\u2500 project1.yml \u251c\u2500\u2500 prod \u2502 \u2514\u2500\u2500 project2.yml \u2514\u2500\u2500 sandbox \u2514\u2500\u2500 project3.yml The targets directory enables us to define various projects. We can specify each project as an environment such as dev , staging and production with each having unique parameters. The following is an example targets file. type.terraform is what defines the entry point into the main Jsonnet template file. The parameters in the file inventory/targets/develop/project1.yml will then be utilized to set the environmental specific provider/resource configuration. We define the default region and zone for terraform's provider configuration. The default DNS TTL for the DNS resource is also configured for the development environment. classes : - type.terraform parameters : name : project1 region : europe-west2 zone : europe-west2-a dns_default_ttl : 300 In the following example, we use a reclass configuration file to specify further parameters that we would like to merge into our project files. Thus we define nodes, which are stored in targets and environmental mandatory parameters stored in classes/env/ . The reclass config is shown below: storage_type : yaml_fs pretty_print : true output : yaml inventory_base_uri : . nodes_uri : targets classes_uri : classes compose_node_name : false class_mappings : - develop/* env.develop - prod/* env.prod - sandbox/* env.sandbox The following class provider.gcp will be found in all files in this path since it is a common configuration for the cloud authentication module. classes : - provider.gcp Further classes that group parameters together can be included. To assist in further refining the configuration. components We tend to use components as a method to organize Jsonnet files. This is not mandatory since it is possible to configure Kapitan to look for input files wherever you would like. You can have these in any path just ensure you define that path in inventory/classes/type/terraform.yml . The templates folder is where the Jsonnet is located in this instance as shown below: . \u251c\u2500\u2500 cloudbuild.jsonnet \u251c\u2500\u2500 dns.jsonnet \u251c\u2500\u2500 iam.jsonnet \u251c\u2500\u2500 iam_service_account.jsonnet \u251c\u2500\u2500 kms.jsonnet \u251c\u2500\u2500 kubernetes.jsonnet \u251c\u2500\u2500 logging.jsonnet \u251c\u2500\u2500 main.jsonnet \u251c\u2500\u2500 monitoring.jsonnet \u251c\u2500\u2500 org_iam.jsonnet \u251c\u2500\u2500 output.jsonnet \u251c\u2500\u2500 provider.jsonnet \u251c\u2500\u2500 pubsub.jsonnet \u251c\u2500\u2500 README.md.j2 \u2514\u2500\u2500 storage.jsonnet The main thing to understand about terraform components is that they are strictly handled by Jsonnet for simplicity. The rendering logic is as follows: { \"output.tf\": output, \"provider.tf\": provider, [if name_in_resoures(\"cloudbuild\") then \"cloudbuild.tf\"]: cloudbuild, [if name_in_resoures(\"container\") then \"kubernetes.tf\"]: kubernetes, [if name_in_resoures(\"dns\") then \"dns.tf\"]: dns, [if name_in_resoures(\"iam\") && \"serviceaccounts\" in p.resources.iam then \"iam_service_account.tf\"]: iam_service_account, ... [if name_in_resoures(\"pubsub\") then \"pubsub.tf\"]: pubsub, [if name_in_resoures(\"storage\") then \"storage.tf\"]: storage, } Each Jsonnet file defines a resource and then it is imported. Jsonnet then filters through all the inventory parameters to find specific keys that have been defined. Let's take for example the cloud build resource: local cloudbuild = import \"cloudbuild.jsonnet\"; ... { \"output.tf\": output, \"provider.tf\": provider, [if name_in_resoures(\"cloudbuild\") then \"cloudbuild.tf\"]: cloudbuild, ... } Assuming that one of the configuration files for a specific environment has the parameter key cloudbuild set. These parameters will then be interpreted by the cloudbuild.jsonnet template. A file named cloudbuild.tf.json will then be compiled using the parameters associated with the cloudbuild parameter key. It is important to understand that once you have a deeper understanding of Kapitan's capabilities, you can organize these files to a style and logic suitable for your organization. templates, docs, scripts Jinja2 is used to generate documentation that sources information from kapitan's inventory. This enables the ability to have dynamic documentation based on your infrastructure configuration changes. In templates/terraform you will find README.md.j2 . This is used to generate a README.md template to be utilized by terraform's output module. The following is what generates the documentation: data: { template_file: { readme: { template: kap.jinja2_template(\"templates/terraform/README.md.j2\", inv), }, }, }, output: { \"README.md\": { value: \"${data.template_file.readme.rendered}\", sensitive: true, }, }, The function kap.jinja2_template() (imported from kapitan.libjsonnet ) is used to convert and interpreter the README.md.j2 file into a raw string using the inventory for evaluation logic. Based on the various parameters jinja2 decides which sections of the readme should be included. When terraform runs it will use the output module to generate your desired README.md using information from terraform's state. Scripts are located in the scripts directory. They are compiled using jinja2 as the templating language. An example is as follows: export TF_DATA_DIR = $( realpath -m ${ DIR } /../../../.TF_DATA_DIR/ {{ inventory.parameters.name }} ) # Folder for TF initialization (preferable outside of compiled) export OUTPUT_DIR = $( realpath -m ${ DIR } /../../../output/ {{ inventory.parameters.name }} ) # Folder for storing output files (preferable outside of compiled) It is good practice to utilize this method to improve integration with various CLI based tools. Scripts help to ensure terraform and kapitan can function with your CI/CD systems. It generally depends on your organizational workflows. References Although there are no particular references in this instance. It is possible to utilize Kapitan references as defined in referemce management . Collaboration In some situations you may find teams that are used to writing terraform in HCL. In such situations it may be difficult to adopt Kapitan into the companies workflows. We can however use terraform modules to simplify the integration process. This means teams which are used to writing in HCL will not need to completely adopt Jsonnet. Modules can be imported into projects by defining them under the modules parameter key as shown in inventory/targets/sandbox . This means teams will only have to worry about coordinating parameter inputs for different projects. Jsonnet provides the ability to specify conventions and validation of input parameters. This provides peace of mind to infrastructure administrators around the tools usage.","title":"Terraform"},{"location":"pages/examples/terraform/#terraform-example","text":"We will be looking at how to use Kapitan to compile terraform files with Jsonnet as the input type. It's possible to use other input types, however, Jsonnet is recommended. For example, we could use the Kadet input to generate terraform files but this would require templates to be written in YAML then rendered into JSON. It is possible to allow Kadet to consume JSON as an input. This enables you to integrate your organizations pre-existing terraform JSON file's as templates. Jsonnet is the most straightforward input type as you will see due to its functional nature. The only appropriate output type is JSON since this is the format that Terraform consumes.","title":" Terraform example"},{"location":"pages/examples/terraform/#directory-structure","text":"There are several examples available in examples/terraform . This will be our working directory for this documentation. The directory structure is as follows: \u251c\u2500\u2500 inventory \u2514\u2500\u2500 templates It is possible to further extend this locally to include a lib directory where a terraform.libjsonnet file can be stored for use. This is generally dependent on the project scope and organizational patterns. We will describe in more detail the role of each of these folders in the following sections.","title":"Directory structure"},{"location":"pages/examples/terraform/#inventory","text":"This folder contains the inventory files used to render the templates for each target. The structure of this folder is as follows: . \u251c\u2500\u2500 classes \u2502 \u251c\u2500\u2500 env \u2502 \u2502 \u251c\u2500\u2500 develop.yml \u2502 \u2502 \u251c\u2500\u2500 prod.yml \u2502 \u2502 \u2514\u2500\u2500 sandbox.yml \u2502 \u251c\u2500\u2500 provider \u2502 \u2502 \u2514\u2500\u2500 gcp.yml \u2502 \u2514\u2500\u2500 type \u2502 \u2514\u2500\u2500 terraform.yml \u251c\u2500\u2500 reclass-config.yml \u2514\u2500\u2500 targets \u251c\u2500\u2500 develop \u2502 \u2514\u2500\u2500 project1.yml \u251c\u2500\u2500 prod \u2502 \u2514\u2500\u2500 project2.yml \u2514\u2500\u2500 sandbox \u2514\u2500\u2500 project3.yml The targets directory enables us to define various projects. We can specify each project as an environment such as dev , staging and production with each having unique parameters. The following is an example targets file. type.terraform is what defines the entry point into the main Jsonnet template file. The parameters in the file inventory/targets/develop/project1.yml will then be utilized to set the environmental specific provider/resource configuration. We define the default region and zone for terraform's provider configuration. The default DNS TTL for the DNS resource is also configured for the development environment. classes : - type.terraform parameters : name : project1 region : europe-west2 zone : europe-west2-a dns_default_ttl : 300 In the following example, we use a reclass configuration file to specify further parameters that we would like to merge into our project files. Thus we define nodes, which are stored in targets and environmental mandatory parameters stored in classes/env/ . The reclass config is shown below: storage_type : yaml_fs pretty_print : true output : yaml inventory_base_uri : . nodes_uri : targets classes_uri : classes compose_node_name : false class_mappings : - develop/* env.develop - prod/* env.prod - sandbox/* env.sandbox The following class provider.gcp will be found in all files in this path since it is a common configuration for the cloud authentication module. classes : - provider.gcp Further classes that group parameters together can be included. To assist in further refining the configuration.","title":"inventory"},{"location":"pages/examples/terraform/#components","text":"We tend to use components as a method to organize Jsonnet files. This is not mandatory since it is possible to configure Kapitan to look for input files wherever you would like. You can have these in any path just ensure you define that path in inventory/classes/type/terraform.yml . The templates folder is where the Jsonnet is located in this instance as shown below: . \u251c\u2500\u2500 cloudbuild.jsonnet \u251c\u2500\u2500 dns.jsonnet \u251c\u2500\u2500 iam.jsonnet \u251c\u2500\u2500 iam_service_account.jsonnet \u251c\u2500\u2500 kms.jsonnet \u251c\u2500\u2500 kubernetes.jsonnet \u251c\u2500\u2500 logging.jsonnet \u251c\u2500\u2500 main.jsonnet \u251c\u2500\u2500 monitoring.jsonnet \u251c\u2500\u2500 org_iam.jsonnet \u251c\u2500\u2500 output.jsonnet \u251c\u2500\u2500 provider.jsonnet \u251c\u2500\u2500 pubsub.jsonnet \u251c\u2500\u2500 README.md.j2 \u2514\u2500\u2500 storage.jsonnet The main thing to understand about terraform components is that they are strictly handled by Jsonnet for simplicity. The rendering logic is as follows: { \"output.tf\": output, \"provider.tf\": provider, [if name_in_resoures(\"cloudbuild\") then \"cloudbuild.tf\"]: cloudbuild, [if name_in_resoures(\"container\") then \"kubernetes.tf\"]: kubernetes, [if name_in_resoures(\"dns\") then \"dns.tf\"]: dns, [if name_in_resoures(\"iam\") && \"serviceaccounts\" in p.resources.iam then \"iam_service_account.tf\"]: iam_service_account, ... [if name_in_resoures(\"pubsub\") then \"pubsub.tf\"]: pubsub, [if name_in_resoures(\"storage\") then \"storage.tf\"]: storage, } Each Jsonnet file defines a resource and then it is imported. Jsonnet then filters through all the inventory parameters to find specific keys that have been defined. Let's take for example the cloud build resource: local cloudbuild = import \"cloudbuild.jsonnet\"; ... { \"output.tf\": output, \"provider.tf\": provider, [if name_in_resoures(\"cloudbuild\") then \"cloudbuild.tf\"]: cloudbuild, ... } Assuming that one of the configuration files for a specific environment has the parameter key cloudbuild set. These parameters will then be interpreted by the cloudbuild.jsonnet template. A file named cloudbuild.tf.json will then be compiled using the parameters associated with the cloudbuild parameter key. It is important to understand that once you have a deeper understanding of Kapitan's capabilities, you can organize these files to a style and logic suitable for your organization.","title":"components"},{"location":"pages/examples/terraform/#templates-docs-scripts","text":"Jinja2 is used to generate documentation that sources information from kapitan's inventory. This enables the ability to have dynamic documentation based on your infrastructure configuration changes. In templates/terraform you will find README.md.j2 . This is used to generate a README.md template to be utilized by terraform's output module. The following is what generates the documentation: data: { template_file: { readme: { template: kap.jinja2_template(\"templates/terraform/README.md.j2\", inv), }, }, }, output: { \"README.md\": { value: \"${data.template_file.readme.rendered}\", sensitive: true, }, }, The function kap.jinja2_template() (imported from kapitan.libjsonnet ) is used to convert and interpreter the README.md.j2 file into a raw string using the inventory for evaluation logic. Based on the various parameters jinja2 decides which sections of the readme should be included. When terraform runs it will use the output module to generate your desired README.md using information from terraform's state. Scripts are located in the scripts directory. They are compiled using jinja2 as the templating language. An example is as follows: export TF_DATA_DIR = $( realpath -m ${ DIR } /../../../.TF_DATA_DIR/ {{ inventory.parameters.name }} ) # Folder for TF initialization (preferable outside of compiled) export OUTPUT_DIR = $( realpath -m ${ DIR } /../../../output/ {{ inventory.parameters.name }} ) # Folder for storing output files (preferable outside of compiled) It is good practice to utilize this method to improve integration with various CLI based tools. Scripts help to ensure terraform and kapitan can function with your CI/CD systems. It generally depends on your organizational workflows.","title":"templates, docs, scripts"},{"location":"pages/examples/terraform/#references","text":"Although there are no particular references in this instance. It is possible to utilize Kapitan references as defined in referemce management .","title":"References"},{"location":"pages/examples/terraform/#collaboration","text":"In some situations you may find teams that are used to writing terraform in HCL. In such situations it may be difficult to adopt Kapitan into the companies workflows. We can however use terraform modules to simplify the integration process. This means teams which are used to writing in HCL will not need to completely adopt Jsonnet. Modules can be imported into projects by defining them under the modules parameter key as shown in inventory/targets/sandbox . This means teams will only have to worry about coordinating parameter inputs for different projects. Jsonnet provides the ability to specify conventions and validation of input parameters. This provides peace of mind to infrastructure administrators around the tools usage.","title":"Collaboration"},{"location":"pages/input_types/copy/","text":"Copy This input type simply copies the input templates to the output directory without any rendering/processing. For Copy, input_paths can be either a file or a directory: in case of a directory, all the templates in the directory will be copied and outputted to output_path . Supported output types : N/A (no need to specify output_type ) Example kapitan : compile : - input_type : copy ignore_missing : true # Do not error if path is missing. Defaults to False input_paths : - resources/state/${target_name}/.terraform.lock.hcl output_path : terraform/","title":"Copy"},{"location":"pages/input_types/copy/#copy","text":"This input type simply copies the input templates to the output directory without any rendering/processing. For Copy, input_paths can be either a file or a directory: in case of a directory, all the templates in the directory will be copied and outputted to output_path . Supported output types : N/A (no need to specify output_type ) Example kapitan : compile : - input_type : copy ignore_missing : true # Do not error if path is missing. Defaults to False input_paths : - resources/state/${target_name}/.terraform.lock.hcl output_path : terraform/","title":" Copy"},{"location":"pages/input_types/external/","text":"External This input type executes an external script or binary. This can be used to manipulate already compiled files or execute binaries outside of kapitan that generate or manipulate files. For example, ytt is a useful yaml templating tool. It is not built into the kapitan binary, however, with the external input type, we could specify the ytt binary to be executed with specific arguments and environment variables. In this example, we're removing a label from a k8s manifests in a directory ingresses and placing it into the compiled target directory. parameters : target_name : k8s-manifests kapitan : vars : target : ${target_name} compile : - input_type : external input_paths : - /usr/local/bin/ytt # path to ytt on system output_path : . args : - -f - ingresses/ # directory with ingresses - -f - ytt/remove.yaml # custom ytt script - \">\" - \\${compiled_target_dir}/ingresses/ingresses.yaml # final merged result Supported output types : N/A (no need to specify output_type ) Additionally, the input type supports field env_vars , which can be used to set environment variables for the external command. By default, the external command doesn't inherit any environment variables from Kapitan's environment. However, if environment variables $PATH or $HOME aren't set in env_vars , they will be propagated from Kapitan's environment to the external command's environment. Finally, Kapitan will substitute ${compiled_target_dir} in both the command's arguments and the environment variables. This variable needs to be escaped in the configuration to ensure that reclass won't interpret it as a reclass reference.","title":"External"},{"location":"pages/input_types/external/#external","text":"This input type executes an external script or binary. This can be used to manipulate already compiled files or execute binaries outside of kapitan that generate or manipulate files. For example, ytt is a useful yaml templating tool. It is not built into the kapitan binary, however, with the external input type, we could specify the ytt binary to be executed with specific arguments and environment variables. In this example, we're removing a label from a k8s manifests in a directory ingresses and placing it into the compiled target directory. parameters : target_name : k8s-manifests kapitan : vars : target : ${target_name} compile : - input_type : external input_paths : - /usr/local/bin/ytt # path to ytt on system output_path : . args : - -f - ingresses/ # directory with ingresses - -f - ytt/remove.yaml # custom ytt script - \">\" - \\${compiled_target_dir}/ingresses/ingresses.yaml # final merged result Supported output types : N/A (no need to specify output_type ) Additionally, the input type supports field env_vars , which can be used to set environment variables for the external command. By default, the external command doesn't inherit any environment variables from Kapitan's environment. However, if environment variables $PATH or $HOME aren't set in env_vars , they will be propagated from Kapitan's environment to the external command's environment. Finally, Kapitan will substitute ${compiled_target_dir} in both the command's arguments and the environment variables. This variable needs to be escaped in the configuration to ensure that reclass won't interpret it as a reclass reference.","title":" External"},{"location":"pages/input_types/helm/","text":"Input Type | Helm This is a Python binding to helm template command for users with helm charts. This does not require the helm executable, and the templates are rendered without the Tiller server. Unlike other input types, Helm input types support the following additional parameters under kapitan.compile : parameters : kapitan : compile : - output_path : <output_path> input_type : helm input_paths : - <chart_path> helm_values : <object_with_values_to_override> helm_values_files : - <values_file_path> helm_path : <helm binary> helm_params : name : <chart_release_name> namespace : <substitutes_.Release.Namespace> output_file : <string> validate : true \u2026 helm_values is an object containing values specified that will override the default values in the input chart. This has exactly the same effect as specifying --values custom_values.yml for helm template command where custom_values.yml structure mirrors that of helm_values . helm_values_files is an array containing the paths to helm values files used as input for the chart. This has exactly the same effect as specifying --file my_custom_values.yml for the helm template command where my_custom_values.yml is a helm values file. If the same keys exist in helm_values and in multiple specified helm_values_files , the last indexed file in the helm_values_files will take precedence followed by the preceding helm_values_files and at the bottom the helm_values defined in teh compile block. There is an example in the tests. The monitoring-dev (kapitan/tests/test_resources/inventory/targets/monitoring-dev.yml) and monitoring-prd (kapitan/tests/test_resources/inventory/targets/monitoring-prd.yml) targets both use the monitoring (tests/test_resources/inventory/classes/component/monitoring.yml) component. This component has helm chart input and takes a common.yml helm_values file which is \"shared\" by any target that uses the component and it also takes a dynamically defined file based on a kapitan variable defined in the target. helm_path can be use to provide the helm binary name or path. helm_path defaults to the value of KAPITAN_HELM_PATH env var if it is set, else it defaults to helm helm_params correspond to the flags for helm template . Most flags that helm supports can be used here by replacing '-' by '_' in the flag name. Flags without argument must have a boolean value, all other flags require a string value. Special flags: name : equivalent of helm template [NAME] parameter. Ignored if name_template is also specified. If neither name_template nor name are specified, the --generate-name flag is used to generate a name. output_file : name of the single file used to output all the generated resources. This is equivalent to call helm template without specifing output dir. If not specified, each resource is generated into a distinct file. include_crds and skip_tests : These flags are enabled by default and should be set to false to be removed. debug : prints the helm debug output in kapitan debug log. namespace : note that due to the restriction on helm template command, specifying the namespace does not automatically add metadata.namespace property to the resources. Therefore, users are encouraged to explicitly specify it in all resources: metadata : namespace : {{ .Release.Namespace }} # or any other custom values See the helm doc for further detail. Example Let's use nginx-ingress helm chart as the input. Using kapitan dependency manager , this chart can be fetched via a URL as listed in https://helm.nginx.com/stable/index.yaml . On a side note, https://helm.nginx.com/stable/ is the chart repository URL which you would helm repo add , and this repository should contain index.yaml that lists out all the available charts and their URLs. By locating this index.yaml file, you can locate all the charts available in the repository. We can use version 0.3.3 found at https://helm.nginx.com/stable/nginx-ingress-0.3.3.tgz . We can create a simple target file as inventory/targets/nginx-from-chart.yml whose content is as follows: parameters : kapitan : vars : target : nginx-from-chart dependencies : - type : https source : https://helm.nginx.com/stable/nginx-ingress-0.3.3.tgz unpack : True output_path : components/charts compile : - output_path : . input_type : helm input_paths : - components/charts/nginx-ingress helm_values : controller : name : my-controller image : repository : custom_repo helm_params : name : my-first-release-name namespace : my-first-namespace To compile this target, run: $ kapitan compile --fetch Dependency https://helm.nginx.com/stable/nginx-ingress-0.3.3.tgz : fetching now Dependency https://helm.nginx.com/stable/nginx-ingress-0.3.3.tgz : successfully fetched Dependency https://helm.nginx.com/stable/nginx-ingress-0.3.3.tgz : extracted to components/charts Compiled nginx-from-chart ( 0 .07s ) The chart is fetched before compile, which creates components/charts/nginx-ingress folder that is used as the input_paths for the helm input type. To confirm if the helm_values actually has overridden the default values, we can try: $ grep \"my-controller\" compiled/nginx-from-chart/nginx-ingress/templates/controller-deployment.yaml name: my-controller app: my-controller app: my-controller Building the binding from source Run cd kapitan/inputs/helm ./build.sh This requires Go 1.14. Helm subcharts There is an external dependency manager of type helm which enables you to specify helm charts to download, including subcharts.","title":"Helm"},{"location":"pages/input_types/helm/#input-type-helm","text":"This is a Python binding to helm template command for users with helm charts. This does not require the helm executable, and the templates are rendered without the Tiller server. Unlike other input types, Helm input types support the following additional parameters under kapitan.compile : parameters : kapitan : compile : - output_path : <output_path> input_type : helm input_paths : - <chart_path> helm_values : <object_with_values_to_override> helm_values_files : - <values_file_path> helm_path : <helm binary> helm_params : name : <chart_release_name> namespace : <substitutes_.Release.Namespace> output_file : <string> validate : true \u2026 helm_values is an object containing values specified that will override the default values in the input chart. This has exactly the same effect as specifying --values custom_values.yml for helm template command where custom_values.yml structure mirrors that of helm_values . helm_values_files is an array containing the paths to helm values files used as input for the chart. This has exactly the same effect as specifying --file my_custom_values.yml for the helm template command where my_custom_values.yml is a helm values file. If the same keys exist in helm_values and in multiple specified helm_values_files , the last indexed file in the helm_values_files will take precedence followed by the preceding helm_values_files and at the bottom the helm_values defined in teh compile block. There is an example in the tests. The monitoring-dev (kapitan/tests/test_resources/inventory/targets/monitoring-dev.yml) and monitoring-prd (kapitan/tests/test_resources/inventory/targets/monitoring-prd.yml) targets both use the monitoring (tests/test_resources/inventory/classes/component/monitoring.yml) component. This component has helm chart input and takes a common.yml helm_values file which is \"shared\" by any target that uses the component and it also takes a dynamically defined file based on a kapitan variable defined in the target. helm_path can be use to provide the helm binary name or path. helm_path defaults to the value of KAPITAN_HELM_PATH env var if it is set, else it defaults to helm helm_params correspond to the flags for helm template . Most flags that helm supports can be used here by replacing '-' by '_' in the flag name. Flags without argument must have a boolean value, all other flags require a string value. Special flags: name : equivalent of helm template [NAME] parameter. Ignored if name_template is also specified. If neither name_template nor name are specified, the --generate-name flag is used to generate a name. output_file : name of the single file used to output all the generated resources. This is equivalent to call helm template without specifing output dir. If not specified, each resource is generated into a distinct file. include_crds and skip_tests : These flags are enabled by default and should be set to false to be removed. debug : prints the helm debug output in kapitan debug log. namespace : note that due to the restriction on helm template command, specifying the namespace does not automatically add metadata.namespace property to the resources. Therefore, users are encouraged to explicitly specify it in all resources: metadata : namespace : {{ .Release.Namespace }} # or any other custom values See the helm doc for further detail.","title":" Input Type | Helm"},{"location":"pages/input_types/helm/#example","text":"Let's use nginx-ingress helm chart as the input. Using kapitan dependency manager , this chart can be fetched via a URL as listed in https://helm.nginx.com/stable/index.yaml . On a side note, https://helm.nginx.com/stable/ is the chart repository URL which you would helm repo add , and this repository should contain index.yaml that lists out all the available charts and their URLs. By locating this index.yaml file, you can locate all the charts available in the repository. We can use version 0.3.3 found at https://helm.nginx.com/stable/nginx-ingress-0.3.3.tgz . We can create a simple target file as inventory/targets/nginx-from-chart.yml whose content is as follows: parameters : kapitan : vars : target : nginx-from-chart dependencies : - type : https source : https://helm.nginx.com/stable/nginx-ingress-0.3.3.tgz unpack : True output_path : components/charts compile : - output_path : . input_type : helm input_paths : - components/charts/nginx-ingress helm_values : controller : name : my-controller image : repository : custom_repo helm_params : name : my-first-release-name namespace : my-first-namespace To compile this target, run: $ kapitan compile --fetch Dependency https://helm.nginx.com/stable/nginx-ingress-0.3.3.tgz : fetching now Dependency https://helm.nginx.com/stable/nginx-ingress-0.3.3.tgz : successfully fetched Dependency https://helm.nginx.com/stable/nginx-ingress-0.3.3.tgz : extracted to components/charts Compiled nginx-from-chart ( 0 .07s ) The chart is fetched before compile, which creates components/charts/nginx-ingress folder that is used as the input_paths for the helm input type. To confirm if the helm_values actually has overridden the default values, we can try: $ grep \"my-controller\" compiled/nginx-from-chart/nginx-ingress/templates/controller-deployment.yaml name: my-controller app: my-controller app: my-controller","title":"Example"},{"location":"pages/input_types/helm/#building-the-binding-from-source","text":"Run cd kapitan/inputs/helm ./build.sh This requires Go 1.14.","title":"Building the binding from source"},{"location":"pages/input_types/helm/#helm-subcharts","text":"There is an external dependency manager of type helm which enables you to specify helm charts to download, including subcharts.","title":"Helm subcharts"},{"location":"pages/input_types/introduction/","text":"Introduction Note: make sure to read up on inventory before moving on. Phases of the compile command Now that we have a basic understanding of Kapitan inventory , we can talk about the kapitan compile command. The command has five distinct phases : graph LR classDef pink fill:#f9f,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; classDef blue fill:#00FFFF,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; INVENTORY[\"Inventory\"]:::pink COMPILE[\"Compile\"]:::pink FINISH[\"Finish\"]:::pink COPY[\"Copy\"]:::pink subgraph \"fetch\" F{\"fetch?\"} FETCH[\"fetch dependencies\"] end subgraph \"validate\" V{\"validate?\"} VALIDATE[\"Validate\"] end subgraph \"reveal\" REVEAL[\"Reveal\"] R{\"reveal?\"} end INVENTORY --> F F --> |yes| FETCH FETCH --> COMPILE F ==> |no| COMPILE COMPILE ==> R R ==> |no| COPY R --> |yes| REVEAL REVEAL --> COPY COPY --> V V --> |yes| VALIDATE V ==> |no| FINISH VALIDATE --> FINISH Step Flag Description Configuration Inventory Kapitan uses reclass to render a final version of the inventory. Fetch --fetch Kapitan fetches external dependencies parameters.kapitan.dependencies Compile Kapitan compiles the input types for each target parameters.kapitan.compile Reveal --reveal Kapitan reveals the secrets directly in the compiled output parameters.kapitan.secrets Copy Kapitan moves the output files from the tmp directory to /compiled Validate --validate Kapitan validates the schema of compiled output. parameters.kapitan.validate Finish Kapitan has completed all tasks Supported input types Input types can be specified in the inventory under kapitan.compile in the following format: jinja2 jsonnet kadet helm copy parameters : kapitan : compile : - output_path : <output_path_in_target_dir> input_type : jinja2 input_params : # (1)! input_paths : - directory/ - file - globbed/path/* a dict passed to the template Please see Jinja parameters : kapitan : compile : - output_path : <output_path_in_target_dir> input_type : jsonnet prune : false # (1)! input_paths : - directory/ - file - globbed/path/* output_type : [ ` yaml` | `json` ] (Default: global --prune) parameters : kapitan : compile : - output_path : <output_path_in_target_dir> input_type : kadet prune : false # (1)! input_paths : - directory/ - file - globbed/path/* output_type : [ ` yaml` | `json` ] (Default: global --prune) Please see Kadet parameters : kapitan : compile : - output_path : <output_path_in_target_dir> input_type : helm prune : false # (1)! input_paths : - directory/ - file - globbed/path/* output_type : <output_type_specific_to_input_type> (Default: global --prune) parameters : kapitan : compile : - output_path : <output_path_in_target_dir> input_type : copy prune : false # (1)! input_paths : - directory/ - file - globbed/path/* output_type : <output_type_specific_to_input_type> (Default: global --prune)","title":"Introduction"},{"location":"pages/input_types/introduction/#introduction","text":"Note: make sure to read up on inventory before moving on.","title":"Introduction"},{"location":"pages/input_types/introduction/#phases-of-the-compile-command","text":"Now that we have a basic understanding of Kapitan inventory , we can talk about the kapitan compile command. The command has five distinct phases : graph LR classDef pink fill:#f9f,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; classDef blue fill:#00FFFF,stroke:#333,stroke-width:4px,color:#000,font-weight: bold; INVENTORY[\"Inventory\"]:::pink COMPILE[\"Compile\"]:::pink FINISH[\"Finish\"]:::pink COPY[\"Copy\"]:::pink subgraph \"fetch\" F{\"fetch?\"} FETCH[\"fetch dependencies\"] end subgraph \"validate\" V{\"validate?\"} VALIDATE[\"Validate\"] end subgraph \"reveal\" REVEAL[\"Reveal\"] R{\"reveal?\"} end INVENTORY --> F F --> |yes| FETCH FETCH --> COMPILE F ==> |no| COMPILE COMPILE ==> R R ==> |no| COPY R --> |yes| REVEAL REVEAL --> COPY COPY --> V V --> |yes| VALIDATE V ==> |no| FINISH VALIDATE --> FINISH Step Flag Description Configuration Inventory Kapitan uses reclass to render a final version of the inventory. Fetch --fetch Kapitan fetches external dependencies parameters.kapitan.dependencies Compile Kapitan compiles the input types for each target parameters.kapitan.compile Reveal --reveal Kapitan reveals the secrets directly in the compiled output parameters.kapitan.secrets Copy Kapitan moves the output files from the tmp directory to /compiled Validate --validate Kapitan validates the schema of compiled output. parameters.kapitan.validate Finish Kapitan has completed all tasks","title":"Phases of the compile command"},{"location":"pages/input_types/introduction/#supported-input-types","text":"Input types can be specified in the inventory under kapitan.compile in the following format: jinja2 jsonnet kadet helm copy parameters : kapitan : compile : - output_path : <output_path_in_target_dir> input_type : jinja2 input_params : # (1)! input_paths : - directory/ - file - globbed/path/* a dict passed to the template Please see Jinja parameters : kapitan : compile : - output_path : <output_path_in_target_dir> input_type : jsonnet prune : false # (1)! input_paths : - directory/ - file - globbed/path/* output_type : [ ` yaml` | `json` ] (Default: global --prune) parameters : kapitan : compile : - output_path : <output_path_in_target_dir> input_type : kadet prune : false # (1)! input_paths : - directory/ - file - globbed/path/* output_type : [ ` yaml` | `json` ] (Default: global --prune) Please see Kadet parameters : kapitan : compile : - output_path : <output_path_in_target_dir> input_type : helm prune : false # (1)! input_paths : - directory/ - file - globbed/path/* output_type : <output_type_specific_to_input_type> (Default: global --prune) parameters : kapitan : compile : - output_path : <output_path_in_target_dir> input_type : copy prune : false # (1)! input_paths : - directory/ - file - globbed/path/* output_type : <output_type_specific_to_input_type> (Default: global --prune)","title":"Supported input types"},{"location":"pages/input_types/jinja/","text":"Input Type | Jinja2 This input type is probably the most simple input type to use: it is very versatile and is commonly used to create scripts and documentation files. It renders jinja2 templates. Example configuration Here's some configuration from the nginx example examples/kubernetes/inventory/classes/component/nginx-common.yml templates : #(1)! - docs/nginx/README.md - components/nginx-deploy.sh kapitan : compile : - output_path : . #(2)! input_type : jinja2 input_paths : ${templates} #(3)! We define a list with all the templates we want to compile with this input type Then input type will render the files a the root of the target compiled folder e.g. compiled/${target_name} We pass the list as input_paths Notice how make use of variable interpolation to use the convenience of a list to add all the files we want to compile. You can now simply add to that list from any other place in the inventory that calls that class. input_paths can either be a file, or a directory: in case of a directory, all the templates in the directory will be rendered. input_params (optional) can be used to pass extra parameters, helpful when needing to use a similar template for multiple components in the same target. Documentation We usually store documentation templates under the templates/docs directory. examples/kubernetes/docs/nginx/README.md { % set i = inventory.parameters % } # Welcome to the README! Target *{{ i.target_name }}* is running : * {{ i.nginx.replicas }} replicas of *nginx* running nginx image {{ i.nginx.image }} * on cluster {{ i.cluster.name }} Compiled result # Welcome to the README! Target *minikube-nginx-jsonnet* is running: * 1 replicas of *nginx* running nginx image nginx:1:15.8 * on cluster minikube Scripts When we use Jinja to render scripts, we tend to call them \"canned scripts\" to indicate that these scripts have everything needed to run without extra parameters. We usually store script templates under the templates/scripts directory. examples/kubernetes/components/nginx-deploy.sh #!/bin/bash -e DIR = $( dirname ${ BASH_SOURCE [0] } ) { % set i = inventory.parameters % } #(1)! KUBECTL = \"kubectl -n {{i.namespace}}\" #(2)! # Create namespace before anything else ${ KUBECTL } apply -f ${ DIR } /pre-deploy/namespace.yml for SECTION in manifests do echo \"## run kubectl apply for ${ SECTION } \" ${ KUBECTL } apply -f ${ DIR } / ${ SECTION } / | column -t done We import the inventory as a Jinja variable We use to set the namespace explicitly Compiled result #!/bin/bash -e DIR = $( dirname ${ BASH_SOURCE [0] } ) #(1)! KUBECTL = \"kubectl -n minikube-nginx-jsonnet\" #(2)! # Create namespace before anything else ${ KUBECTL } apply -f ${ DIR } /pre-deploy/namespace.yml for SECTION in manifests do echo \"## run kubectl apply for ${ SECTION } \" ${ KUBECTL } apply -f ${ DIR } / ${ SECTION } / | column -t done The script is now a \"canned script\" and ready to be used for this specif target. You can see that the namespace has been replaced with the target's one. Accessing the inventory Templates will be provided at runtime with 3 variables: inventory : To access the inventory for that specific target. inventory_global : To access the inventory of all targets. input_params : To access the optional dictionary provided to the input type. Use of inventory_global inventory_global can be used to generate a \" global \" README.md that contains a link to all generated targets. | *Target* | |------------------------------------------------------------------------| {% for target in inventory_global | sort () %} {% set p = inventory_global [ target ] .parameters %} |[ {{ target }} ](../ {{ target }} /docs/README.md) | {% endfor %} Compiled result | *Target* | |------------------------------------------------------------------------| | [ argocd ]( ../argocd/docs/README.md ) | | [ dev-sockshop ]( ../dev-sockshop/docs/README.md ) | | [ echo-server ]( ../echo-server/docs/README.md ) | | [ examples ]( ../examples/docs/README.md ) | | [ gke-pvm-killer ]( ../gke-pvm-killer/docs/README.md ) | | [ global ]( ../global/docs/README.md ) | | [ guestbook-argocd ]( ../guestbook-argocd/docs/README.md ) | | [ kapicorp-demo-march ]( ../kapicorp-demo-march/docs/README.md ) | | [ kapicorp-project-123 ]( ../kapicorp-project-123/docs/README.md ) | | [ kapicorp-terraform-admin ]( ../kapicorp-terraform-admin/docs/README.md ) | | [ mysql ]( ../mysql/docs/README.md ) | | [ postgres-proxy ]( ../postgres-proxy/docs/README.md ) | | [ pritunl ]( ../pritunl/docs/README.md ) | | [ prod-sockshop ]( ../prod-sockshop/docs/README.md ) | | [ sock-shop ]( ../sock-shop/docs/README.md ) | | [ tesoro ]( ../tesoro/docs/README.md ) | | [ tutorial ]( ../tutorial/docs/README.md ) | | [ vault ]( ../vault/docs/README.md ) | Jinja2 custom filters We support the following custom filters for use in Jinja2 templates: Encoding Time Regexp fileglob bool ternary shuffle reveal_maybe sha256 yaml toml b64encode b64decode SHA256 hashing of text {{ text | sha256 }} Dump text as YAML {{ text | yaml }} Dump text as TOML {{ text | toml }} base64 encode text {{ text | b64encode }} base64 decode text {{ text | b64decode }} to_datetime strftime return datetime object for string {{ \"2019-03-07 13:37:00\" | to_datetime }} return current date string for format {{ \"%a, %d %b %Y %H:%M\" | strftime }} regex_replace regex_escape regex_search regex_findall perform a re.sub returning a string {{ hello world | regex_replace(pattern=\"world\", replacement=\"kapitan\")}} escape all regular expressions special characters from string {{ \"+s[a-z].*\" | regex_escape}} perform re.search and return the list of matches or a backref {{ hello world | regex_search(\"world.*\")}} perform re.findall and return the list of matches as array {{ hello world | regex_findall(\"world.*\")}} return list of matched regular files for glob {{ ./path/file* | fileglob }} return the bool for value {{ yes | bool }} value ? true_val : false_val {{ condition | ternary(\"yes\", \"no\")}} randomly shuffle elements of a list {{ [1, 2, 3, 4, 5] | shuffle }} reveal ref/secret tag only if compile --reveal flag is set {{ \"?{base64:my_ref}\" | reveal_maybe}} Tip You can also provide path to your custom filter modules in CLI. By default, you can put your filters in lib/jinja2_filters.py and they will automatically get loaded.","title":"Jinja"},{"location":"pages/input_types/jinja/#input-type-jinja2","text":"This input type is probably the most simple input type to use: it is very versatile and is commonly used to create scripts and documentation files. It renders jinja2 templates.","title":" Input Type | Jinja2"},{"location":"pages/input_types/jinja/#example-configuration","text":"Here's some configuration from the nginx example examples/kubernetes/inventory/classes/component/nginx-common.yml templates : #(1)! - docs/nginx/README.md - components/nginx-deploy.sh kapitan : compile : - output_path : . #(2)! input_type : jinja2 input_paths : ${templates} #(3)! We define a list with all the templates we want to compile with this input type Then input type will render the files a the root of the target compiled folder e.g. compiled/${target_name} We pass the list as input_paths Notice how make use of variable interpolation to use the convenience of a list to add all the files we want to compile. You can now simply add to that list from any other place in the inventory that calls that class. input_paths can either be a file, or a directory: in case of a directory, all the templates in the directory will be rendered. input_params (optional) can be used to pass extra parameters, helpful when needing to use a similar template for multiple components in the same target.","title":"Example configuration"},{"location":"pages/input_types/jinja/#documentation","text":"We usually store documentation templates under the templates/docs directory. examples/kubernetes/docs/nginx/README.md { % set i = inventory.parameters % } # Welcome to the README! Target *{{ i.target_name }}* is running : * {{ i.nginx.replicas }} replicas of *nginx* running nginx image {{ i.nginx.image }} * on cluster {{ i.cluster.name }} Compiled result # Welcome to the README! Target *minikube-nginx-jsonnet* is running: * 1 replicas of *nginx* running nginx image nginx:1:15.8 * on cluster minikube","title":"Documentation"},{"location":"pages/input_types/jinja/#scripts","text":"When we use Jinja to render scripts, we tend to call them \"canned scripts\" to indicate that these scripts have everything needed to run without extra parameters. We usually store script templates under the templates/scripts directory. examples/kubernetes/components/nginx-deploy.sh #!/bin/bash -e DIR = $( dirname ${ BASH_SOURCE [0] } ) { % set i = inventory.parameters % } #(1)! KUBECTL = \"kubectl -n {{i.namespace}}\" #(2)! # Create namespace before anything else ${ KUBECTL } apply -f ${ DIR } /pre-deploy/namespace.yml for SECTION in manifests do echo \"## run kubectl apply for ${ SECTION } \" ${ KUBECTL } apply -f ${ DIR } / ${ SECTION } / | column -t done We import the inventory as a Jinja variable We use to set the namespace explicitly Compiled result #!/bin/bash -e DIR = $( dirname ${ BASH_SOURCE [0] } ) #(1)! KUBECTL = \"kubectl -n minikube-nginx-jsonnet\" #(2)! # Create namespace before anything else ${ KUBECTL } apply -f ${ DIR } /pre-deploy/namespace.yml for SECTION in manifests do echo \"## run kubectl apply for ${ SECTION } \" ${ KUBECTL } apply -f ${ DIR } / ${ SECTION } / | column -t done The script is now a \"canned script\" and ready to be used for this specif target. You can see that the namespace has been replaced with the target's one.","title":"Scripts"},{"location":"pages/input_types/jinja/#accessing-the-inventory","text":"Templates will be provided at runtime with 3 variables: inventory : To access the inventory for that specific target. inventory_global : To access the inventory of all targets. input_params : To access the optional dictionary provided to the input type. Use of inventory_global inventory_global can be used to generate a \" global \" README.md that contains a link to all generated targets. | *Target* | |------------------------------------------------------------------------| {% for target in inventory_global | sort () %} {% set p = inventory_global [ target ] .parameters %} |[ {{ target }} ](../ {{ target }} /docs/README.md) | {% endfor %} Compiled result | *Target* | |------------------------------------------------------------------------| | [ argocd ]( ../argocd/docs/README.md ) | | [ dev-sockshop ]( ../dev-sockshop/docs/README.md ) | | [ echo-server ]( ../echo-server/docs/README.md ) | | [ examples ]( ../examples/docs/README.md ) | | [ gke-pvm-killer ]( ../gke-pvm-killer/docs/README.md ) | | [ global ]( ../global/docs/README.md ) | | [ guestbook-argocd ]( ../guestbook-argocd/docs/README.md ) | | [ kapicorp-demo-march ]( ../kapicorp-demo-march/docs/README.md ) | | [ kapicorp-project-123 ]( ../kapicorp-project-123/docs/README.md ) | | [ kapicorp-terraform-admin ]( ../kapicorp-terraform-admin/docs/README.md ) | | [ mysql ]( ../mysql/docs/README.md ) | | [ postgres-proxy ]( ../postgres-proxy/docs/README.md ) | | [ pritunl ]( ../pritunl/docs/README.md ) | | [ prod-sockshop ]( ../prod-sockshop/docs/README.md ) | | [ sock-shop ]( ../sock-shop/docs/README.md ) | | [ tesoro ]( ../tesoro/docs/README.md ) | | [ tutorial ]( ../tutorial/docs/README.md ) | | [ vault ]( ../vault/docs/README.md ) |","title":"Accessing the inventory"},{"location":"pages/input_types/jinja/#jinja2-custom-filters","text":"We support the following custom filters for use in Jinja2 templates: Encoding Time Regexp fileglob bool ternary shuffle reveal_maybe sha256 yaml toml b64encode b64decode SHA256 hashing of text {{ text | sha256 }} Dump text as YAML {{ text | yaml }} Dump text as TOML {{ text | toml }} base64 encode text {{ text | b64encode }} base64 decode text {{ text | b64decode }} to_datetime strftime return datetime object for string {{ \"2019-03-07 13:37:00\" | to_datetime }} return current date string for format {{ \"%a, %d %b %Y %H:%M\" | strftime }} regex_replace regex_escape regex_search regex_findall perform a re.sub returning a string {{ hello world | regex_replace(pattern=\"world\", replacement=\"kapitan\")}} escape all regular expressions special characters from string {{ \"+s[a-z].*\" | regex_escape}} perform re.search and return the list of matches or a backref {{ hello world | regex_search(\"world.*\")}} perform re.findall and return the list of matches as array {{ hello world | regex_findall(\"world.*\")}} return list of matched regular files for glob {{ ./path/file* | fileglob }} return the bool for value {{ yes | bool }} value ? true_val : false_val {{ condition | ternary(\"yes\", \"no\")}} randomly shuffle elements of a list {{ [1, 2, 3, 4, 5] | shuffle }} reveal ref/secret tag only if compile --reveal flag is set {{ \"?{base64:my_ref}\" | reveal_maybe}} Tip You can also provide path to your custom filter modules in CLI. By default, you can put your filters in lib/jinja2_filters.py and they will automatically get loaded.","title":"Jinja2 custom filters"},{"location":"pages/input_types/jsonnet/","text":"Input Type | Jsonnet Jsonnet is a superset of json format that includes features such as conditionals, variables and imports. Refer to jsonnet docs to understand how it works. Note: unlike jinja2 templates, one jsonnet template can output multiple files (one per object declared in the file). Accessing the inventory Typical jsonnet files would start as follows: local kap = import \"lib/kapitan.libjsonnet\" ; #(1)! local inv = kap . inventory (); #(2)! local p = inv . parameters ; #(3)! { \"data_java_opts\" : p . elasticsearch . roles . data . java_opts , #(4)! } Import the Kapitan inventory library. Assign the content of the full inventory for this specific target to the inv variable. Assign the content of the inventory.parameters to a variable p for convenience. Use the p variable fo access a specific intentory value Note: The dictionary keys of the jsonnet object are used as filenames for the generated output files. If your jsonnet is not a dictionary, but is a valid json(net) object, then the output filename will be the same as the input filename. E.g. 'my_string' is inside templates/input_file.jsonnet so the generated output file will be named input_file.json for example and will contain \"my_string\" . Jinja2 templating Kapitan allows you to compile a Jinja template from within Jsonnet: local kap = impor t \"lib/kapitan.libjsonnet\" ; { \"jon_snow\" : kap.ji n ja 2 _ te mpla te ( \"templates/got.j2\" , { is_dead : false } ) , } Callback functions In addition, importing kapitan.libjsonnet makes available the following native_callback functions gluing reclass to jsonnet (amongst others): inventory jinja2_template yaml file I/O sha256_string gzip_b64 jsonschema returns a dictionary with the inventory for target renders the jinja2 file with context specified yaml_load yaml_load_stream yaml_dump yaml_dump_stream returns a json string of the specified yaml file returns a list of json strings of the specified yaml file returns a string yaml from a json string returns a string yaml stream from a json string file_read file_exists dir_files_list dir_files_read reads the file specified returns informative object if a file exists returns a list of file in a dir returns an object with keys - file_name and values - file contents returns sha256 of string returns base64 encoded gzip of obj validates obj with schema, returns object with 'valid' and 'reason' keys Jsonschema validation Given the follow example inventory: mysql : storage : 10G storage_class : standard image : mysql:latest The yaml inventory structure can be validated with the new jsonschema() function: local schema = { t ype : \"object\" , proper t ies : { s t orage : { t ype : \"string\" , pa ttern : \"^[0-9]+[MGT]{1}$\" }, image : { t ype : \"string\" }, } } ; // run jsonschema validation local valida t io n = kap.jso ns chema(i n v.parame ters .mysql , schema); // assert valid, otherwise error with validation.reason asser t valida t io n .valid : valida t io n .reaso n ; If validation.valid is not true, it will then fail compilation and display validation.reason . Fails validation because storage has an invalid pattern ( 10Z ) Jsonnet error: failed to compile /code/components/mysql/main.jsonnet: RUNTIME ERROR: '10Z' does not match '^[0-9]+[MGT]{1}$' Failed validating 'pattern' in schema [ 'properties' ][ 'storage' ] : { 'pattern' : '^[0-9]+[MGT]{1}$' , 'type' : 'string' } On instance [ 'storage' ] : '10Z' /code/mysql/main.jsonnet: ( 19 :1 ) - ( 43 :2 ) Compile error: failed to compile target: minikube-mysql","title":"Jsonnet"},{"location":"pages/input_types/jsonnet/#input-type-jsonnet","text":"Jsonnet is a superset of json format that includes features such as conditionals, variables and imports. Refer to jsonnet docs to understand how it works. Note: unlike jinja2 templates, one jsonnet template can output multiple files (one per object declared in the file).","title":" Input Type | Jsonnet"},{"location":"pages/input_types/jsonnet/#accessing-the-inventory","text":"Typical jsonnet files would start as follows: local kap = import \"lib/kapitan.libjsonnet\" ; #(1)! local inv = kap . inventory (); #(2)! local p = inv . parameters ; #(3)! { \"data_java_opts\" : p . elasticsearch . roles . data . java_opts , #(4)! } Import the Kapitan inventory library. Assign the content of the full inventory for this specific target to the inv variable. Assign the content of the inventory.parameters to a variable p for convenience. Use the p variable fo access a specific intentory value Note: The dictionary keys of the jsonnet object are used as filenames for the generated output files. If your jsonnet is not a dictionary, but is a valid json(net) object, then the output filename will be the same as the input filename. E.g. 'my_string' is inside templates/input_file.jsonnet so the generated output file will be named input_file.json for example and will contain \"my_string\" .","title":"Accessing the inventory"},{"location":"pages/input_types/jsonnet/#jinja2-templating","text":"Kapitan allows you to compile a Jinja template from within Jsonnet: local kap = impor t \"lib/kapitan.libjsonnet\" ; { \"jon_snow\" : kap.ji n ja 2 _ te mpla te ( \"templates/got.j2\" , { is_dead : false } ) , }","title":"Jinja2 templating"},{"location":"pages/input_types/jsonnet/#callback-functions","text":"In addition, importing kapitan.libjsonnet makes available the following native_callback functions gluing reclass to jsonnet (amongst others): inventory jinja2_template yaml file I/O sha256_string gzip_b64 jsonschema returns a dictionary with the inventory for target renders the jinja2 file with context specified yaml_load yaml_load_stream yaml_dump yaml_dump_stream returns a json string of the specified yaml file returns a list of json strings of the specified yaml file returns a string yaml from a json string returns a string yaml stream from a json string file_read file_exists dir_files_list dir_files_read reads the file specified returns informative object if a file exists returns a list of file in a dir returns an object with keys - file_name and values - file contents returns sha256 of string returns base64 encoded gzip of obj validates obj with schema, returns object with 'valid' and 'reason' keys","title":"Callback functions"},{"location":"pages/input_types/jsonnet/#jsonschema-validation","text":"Given the follow example inventory: mysql : storage : 10G storage_class : standard image : mysql:latest The yaml inventory structure can be validated with the new jsonschema() function: local schema = { t ype : \"object\" , proper t ies : { s t orage : { t ype : \"string\" , pa ttern : \"^[0-9]+[MGT]{1}$\" }, image : { t ype : \"string\" }, } } ; // run jsonschema validation local valida t io n = kap.jso ns chema(i n v.parame ters .mysql , schema); // assert valid, otherwise error with validation.reason asser t valida t io n .valid : valida t io n .reaso n ; If validation.valid is not true, it will then fail compilation and display validation.reason . Fails validation because storage has an invalid pattern ( 10Z ) Jsonnet error: failed to compile /code/components/mysql/main.jsonnet: RUNTIME ERROR: '10Z' does not match '^[0-9]+[MGT]{1}$' Failed validating 'pattern' in schema [ 'properties' ][ 'storage' ] : { 'pattern' : '^[0-9]+[MGT]{1}$' , 'type' : 'string' } On instance [ 'storage' ] : '10Z' /code/mysql/main.jsonnet: ( 19 :1 ) - ( 43 :2 ) Compile error: failed to compile target: minikube-mysql","title":"Jsonschema validation"},{"location":"pages/input_types/kadet/","text":"Input Type | Kadet Kadet is an extensible input type for Kapitan that enables you to generate templates using Python . The key benefit being the ability to utilize familiar programing principles while having access to Kapitan 's powerful inventory system. A library that defines resources as classes using the Base Object class is required. These can then be utilized within components to render output. The following functions are provided by the class BaseObj() . Method definitions: new() : Provides parameter checking capabilities body() : Enables in-depth parameter configuration Method functions: root() : Defines values that will be compiled into the output need() : Ability to check & define input parameters update_root() : Updates the template file associated with the class A class can be a resource such as a Kubernetes Deployment as shown here: class Deployment ( BaseObj ): # (1)! def new ( self ): # (2)! self . need ( \"name\" , \"name string needed\" ) self . need ( \"labels\" , \"labels dict needed\" ) self . need ( \"containers\" , \"containers dict needed\" ) self . update_root ( \"lib/kubelib/deployment.yml\" ) def body ( self ): # (3)! self . root . metadata . name = self . kwargs . name # (4)! self . root . metadata . namespace = inv . parameters . target_name self . root . spec . template . metadata . labels = self . kwargs . labels self . root . spec . template . spec . containers = self . kwargs . containers The deployment is an BaseObj() which has two main functions. new(self) is used to perform parameter validation & template compilation body(self) is utilized to set those parameters to be rendered. self.root.metadata.name is a direct reference to a key in the corresponding yaml. Kadet supports importing libraries as you would normally do with Python. These libraries can then be used by the components to generate the required output. ... kubelib = kadet . load_from_search_paths ( \"kubelib\" ) #(1)! ... name = \"nginx\" labels = kadet . BaseObj . from_dict ({ \"app\" : name }) nginx_container = kubelib . Container ( #(2)! name = name , image = inv . parameters . nginx . image , ports = [{ \"containerPort\" : 80 }] ) ... def main (): output = kadet . BaseObj () #(3)! output . root . nginx_deployment = kubelib . Deployment ( name = name , labels = labels , containers = [ nginx_container ]) #(4)! output . root . nginx_service = kubelib . Service ( #(5)! name = name , labels = labels , ports = [ svc_port ], selector = svc_selector ) return output #(6)! We import a library called kubelib using load_from_search_paths() We use kubelib to create a Container We create an output of type BaseObj and we will be updating the root element of this output. We use kubelib to create a Deployment kind. The Deployment makes use of the Container created. We use kubelib to create a Service kind. We return the object. Kapitan will render everything under output.root Kadet uses a library called addict to organise the parameters inline with the yaml templates. As shown above we create a BaseObject() named output. We update the root of this output with the data structure returned from kubelib. This output is what is then returned to kapitan to be compiled into the desired output type. For a deeper understanding please refer to github.com/kapicorp/kadet Supported output types: yaml (default) json","title":"Kadet"},{"location":"pages/input_types/kadet/#input-type-kadet","text":"Kadet is an extensible input type for Kapitan that enables you to generate templates using Python . The key benefit being the ability to utilize familiar programing principles while having access to Kapitan 's powerful inventory system. A library that defines resources as classes using the Base Object class is required. These can then be utilized within components to render output. The following functions are provided by the class BaseObj() . Method definitions: new() : Provides parameter checking capabilities body() : Enables in-depth parameter configuration Method functions: root() : Defines values that will be compiled into the output need() : Ability to check & define input parameters update_root() : Updates the template file associated with the class A class can be a resource such as a Kubernetes Deployment as shown here: class Deployment ( BaseObj ): # (1)! def new ( self ): # (2)! self . need ( \"name\" , \"name string needed\" ) self . need ( \"labels\" , \"labels dict needed\" ) self . need ( \"containers\" , \"containers dict needed\" ) self . update_root ( \"lib/kubelib/deployment.yml\" ) def body ( self ): # (3)! self . root . metadata . name = self . kwargs . name # (4)! self . root . metadata . namespace = inv . parameters . target_name self . root . spec . template . metadata . labels = self . kwargs . labels self . root . spec . template . spec . containers = self . kwargs . containers The deployment is an BaseObj() which has two main functions. new(self) is used to perform parameter validation & template compilation body(self) is utilized to set those parameters to be rendered. self.root.metadata.name is a direct reference to a key in the corresponding yaml. Kadet supports importing libraries as you would normally do with Python. These libraries can then be used by the components to generate the required output. ... kubelib = kadet . load_from_search_paths ( \"kubelib\" ) #(1)! ... name = \"nginx\" labels = kadet . BaseObj . from_dict ({ \"app\" : name }) nginx_container = kubelib . Container ( #(2)! name = name , image = inv . parameters . nginx . image , ports = [{ \"containerPort\" : 80 }] ) ... def main (): output = kadet . BaseObj () #(3)! output . root . nginx_deployment = kubelib . Deployment ( name = name , labels = labels , containers = [ nginx_container ]) #(4)! output . root . nginx_service = kubelib . Service ( #(5)! name = name , labels = labels , ports = [ svc_port ], selector = svc_selector ) return output #(6)! We import a library called kubelib using load_from_search_paths() We use kubelib to create a Container We create an output of type BaseObj and we will be updating the root element of this output. We use kubelib to create a Deployment kind. The Deployment makes use of the Container created. We use kubelib to create a Service kind. We return the object. Kapitan will render everything under output.root Kadet uses a library called addict to organise the parameters inline with the yaml templates. As shown above we create a BaseObject() named output. We update the root of this output with the data structure returned from kubelib. This output is what is then returned to kapitan to be compiled into the desired output type. For a deeper understanding please refer to github.com/kapicorp/kadet Supported output types: yaml (default) json","title":" Input Type | Kadet"},{"location":"pages/input_types/remove/","text":"Remove This input type simply removes files or directories. This can be helpful if you can't control particular files generated during other compile inputs. For example, to remove a file named copy_target , specify an entry to input_paths , compiled/${kapitan:vars:target}/copy_target . parameters : target_name : removal kapitan : vars : target : ${target_name} compile : - input_type : copy input_paths : - copy_target output_path : . # test removal of a file - input_type : remove input_paths : - compiled/${kapitan:vars:target}/copy_target output_path : . As a reminder, each input block within the compile array is run sequentially for a target in Kapitan. If we reversed the order of the inputs above like so: parameters : target_name : removal kapitan : vars : target : ${target_name} compile : - input_type : remove input_paths : - compiled/${kapitan:vars:target}/copy_target output_path : . - input_type : copy input_paths : - copy_target output_path : . The first input block would throw an error because the copy input command hasn't run yet to produce the file being removed by the remove input block. Supported output types : N/A (no need to specify output_type )","title":"Remove"},{"location":"pages/input_types/remove/#remove","text":"This input type simply removes files or directories. This can be helpful if you can't control particular files generated during other compile inputs. For example, to remove a file named copy_target , specify an entry to input_paths , compiled/${kapitan:vars:target}/copy_target . parameters : target_name : removal kapitan : vars : target : ${target_name} compile : - input_type : copy input_paths : - copy_target output_path : . # test removal of a file - input_type : remove input_paths : - compiled/${kapitan:vars:target}/copy_target output_path : . As a reminder, each input block within the compile array is run sequentially for a target in Kapitan. If we reversed the order of the inputs above like so: parameters : target_name : removal kapitan : vars : target : ${target_name} compile : - input_type : remove input_paths : - compiled/${kapitan:vars:target}/copy_target output_path : . - input_type : copy input_paths : - copy_target output_path : . The first input block would throw an error because the copy input command hasn't run yet to produce the file being removed by the remove input block. Supported output types : N/A (no need to specify output_type )","title":"  Remove"},{"location":"pages/inventory/advanced/","text":"Advanced Inventory Features Target labels Kapitan allows you to define labels in your inventory, which can then be used to group together targets with similar labels. For instance you could define the following: Defines a class to add the customer label to selected targets inventory/classes/type/customer_project.yml parameters : customer_name : ${target_name} # Defaults to the target_name kapitan : labels : customer : ${customer_name} Apply the class to the target for customer acme inventory/targets/customers/acme.yml classes : ... - type.customer_project parameters : ... You can now selectively compile targets for customer acme using the following (see see Labels for more details ) kapitan compile -l customer = acme Compiled acme ( 0 .06s ) Compiled acme-documentation ( 0 .09s )","title":"Advanced"},{"location":"pages/inventory/advanced/#advanced-inventory-features","text":"","title":"Advanced Inventory Features"},{"location":"pages/inventory/advanced/#target-labels","text":"Kapitan allows you to define labels in your inventory, which can then be used to group together targets with similar labels. For instance you could define the following: Defines a class to add the customer label to selected targets inventory/classes/type/customer_project.yml parameters : customer_name : ${target_name} # Defaults to the target_name kapitan : labels : customer : ${customer_name} Apply the class to the target for customer acme inventory/targets/customers/acme.yml classes : ... - type.customer_project parameters : ... You can now selectively compile targets for customer acme using the following (see see Labels for more details ) kapitan compile -l customer = acme Compiled acme ( 0 .06s ) Compiled acme-documentation ( 0 .09s )","title":"Target labels"},{"location":"pages/inventory/classes/","text":"Classes Usage The next thing you want to learn about the inventory are classes . A class is a yaml file containing a fragment of yaml that we want to import and merge into the inventory. Classes are fragments of yaml: feature sets, commonalities between targets. Classes let you compose your Inventory from smaller bits, eliminating duplication and exposing all important parameters from a single, logically organised place. As the Inventory lets you reference other parameters in the hierarchy, classes become places where you can define something that will then get referenced from another section of the inventory, allowing for composition. Classes are organised under the inventory/classes directory substructure. They are organised hierarchically in subfolders, and the way they can be imported into a target or other classes depends on their location relative to the inventory/classes directory. Importing classes To import a class from within another file of the Inventory , you can follow these instructions: take the file path relative to the inventory/classes/ directory remove the .yml file extension replace / with . For example, this will import the class inventory/classes/applications/sock-shop.yaml classes : - applications.sock-shop Definition Let's take a look at the common class which appears in the example above: As explained, because the common.yaml is directly under the inventory/classes subdirectory, it can be imported directly into a target with: classes : - common If we open the file, we find another familiar yaml fragment. inventory/classes/common.yml classes : - kapitan.common parameters : namespace : ${target_name} target_name : ${_reclass_:name:short} Notice that this class includes an import definition for another class, kapitan.common . We've already learned this means that kapitan will import a file on disk called inventory/classes/kapitan/common.yml You can also see that in the parameters section we now encounter a new syntax which unlocks another powerful inventory feature: parameters interpolation !","title":"Classes"},{"location":"pages/inventory/classes/#classes","text":"","title":"Classes"},{"location":"pages/inventory/classes/#usage","text":"The next thing you want to learn about the inventory are classes . A class is a yaml file containing a fragment of yaml that we want to import and merge into the inventory. Classes are fragments of yaml: feature sets, commonalities between targets. Classes let you compose your Inventory from smaller bits, eliminating duplication and exposing all important parameters from a single, logically organised place. As the Inventory lets you reference other parameters in the hierarchy, classes become places where you can define something that will then get referenced from another section of the inventory, allowing for composition. Classes are organised under the inventory/classes directory substructure. They are organised hierarchically in subfolders, and the way they can be imported into a target or other classes depends on their location relative to the inventory/classes directory.","title":"Usage"},{"location":"pages/inventory/classes/#importing-classes","text":"To import a class from within another file of the Inventory , you can follow these instructions: take the file path relative to the inventory/classes/ directory remove the .yml file extension replace / with . For example, this will import the class inventory/classes/applications/sock-shop.yaml classes : - applications.sock-shop","title":"Importing classes"},{"location":"pages/inventory/classes/#definition","text":"Let's take a look at the common class which appears in the example above: As explained, because the common.yaml is directly under the inventory/classes subdirectory, it can be imported directly into a target with: classes : - common If we open the file, we find another familiar yaml fragment. inventory/classes/common.yml classes : - kapitan.common parameters : namespace : ${target_name} target_name : ${_reclass_:name:short} Notice that this class includes an import definition for another class, kapitan.common . We've already learned this means that kapitan will import a file on disk called inventory/classes/kapitan/common.yml You can also see that in the parameters section we now encounter a new syntax which unlocks another powerful inventory feature: parameters interpolation !","title":"Definition"},{"location":"pages/inventory/introduction/","text":"Overview The Inventory is a core component of Kapitan: this section aims to explain how it works and how to best take advantage of it. The Inventory is a hierarchical YAML based structure which you use to capture anything that you want to make available to Kapitan , so that it can be passed on to its templating engines. The first concept to learn about the Inventory is the target . A target is a file, found under the inventory/targets substructure, that tells Kapitan what you want to compile. It will usually map to something you want to do with Kapitan . For instance, you might want to define a target for each environment that you want to deploy using Kapitan . The Inventory lets you also define and reuse common configurations through YAML files that are referred to as classes : by listing classes into target , their content gets merged together and allows you to compose complex configurations without repetitions. By combining target and classes , the Inventory becomes the SSOT for your whole configuration, and learning how to use it will unleash the real power of Kapitan . Info The Kapitan Inventory is based on an open source project called reclass and you can find the full documentation on our Github clone. However we discourage you to look directly at the reclass documentation before you learn more about Kapitan , because Kapitan uses a fork of reclass and greatly simplifies the reclass experience. Note Kapitan enforces very little structure for the Inventory , so that you can adapt it to your specific needs: this might be overwhelming at the beginning: don\u2019t worry, we will explain best practice and give guidelines soon. By default, Kapitan will search for its Inventory under inventory/classes and inventory/targets . inventory/ \u251c\u2500\u2500 classes \u2502 \u251c\u2500\u2500 applications \u2502 \u251c\u2500\u2500 components \u2502 \u251c\u2500\u2500 features \u2502 \u251c\u2500\u2500 kapitan \u2502 \u251c\u2500\u2500 projects \u2502 \u2514\u2500\u2500 terraform \u2514\u2500\u2500 targets \u251c\u2500\u2500 examples \u251c\u2500\u2500 kapicorp \u2514\u2500\u2500 terraform","title":"Introduction"},{"location":"pages/inventory/introduction/#overview","text":"The Inventory is a core component of Kapitan: this section aims to explain how it works and how to best take advantage of it. The Inventory is a hierarchical YAML based structure which you use to capture anything that you want to make available to Kapitan , so that it can be passed on to its templating engines. The first concept to learn about the Inventory is the target . A target is a file, found under the inventory/targets substructure, that tells Kapitan what you want to compile. It will usually map to something you want to do with Kapitan . For instance, you might want to define a target for each environment that you want to deploy using Kapitan . The Inventory lets you also define and reuse common configurations through YAML files that are referred to as classes : by listing classes into target , their content gets merged together and allows you to compose complex configurations without repetitions. By combining target and classes , the Inventory becomes the SSOT for your whole configuration, and learning how to use it will unleash the real power of Kapitan . Info The Kapitan Inventory is based on an open source project called reclass and you can find the full documentation on our Github clone. However we discourage you to look directly at the reclass documentation before you learn more about Kapitan , because Kapitan uses a fork of reclass and greatly simplifies the reclass experience. Note Kapitan enforces very little structure for the Inventory , so that you can adapt it to your specific needs: this might be overwhelming at the beginning: don\u2019t worry, we will explain best practice and give guidelines soon. By default, Kapitan will search for its Inventory under inventory/classes and inventory/targets . inventory/ \u251c\u2500\u2500 classes \u2502 \u251c\u2500\u2500 applications \u2502 \u251c\u2500\u2500 components \u2502 \u251c\u2500\u2500 features \u2502 \u251c\u2500\u2500 kapitan \u2502 \u251c\u2500\u2500 projects \u2502 \u2514\u2500\u2500 terraform \u2514\u2500\u2500 targets \u251c\u2500\u2500 examples \u251c\u2500\u2500 kapicorp \u2514\u2500\u2500 terraform","title":"Overview"},{"location":"pages/inventory/parameters_interpolation/","text":"Parameters Interpolation Note as a shorthand, when we encounter deep yaml structures like the following: parameters : components : nginx : image : nginx:latest Usually when we want to talk about the image subkey, we normally use either of the following: parameters.components.nginx.image components.nginx.image However, when used in parameter expansion, remember to: replace the . with : omit the parameters initial key which is implied wrap it into the ${} variable interpolation syntax The correct way to reference parameters.nginx.image then becomes ${components:nginx:image} . The Inventory allows you to refer to other values defined elsewhere in the structure, using parameter interpolation. Given the example: parameters : cluster : location : europe application : location : ${cluster:location} namespace : ${target_name} target_name : dev Here we tell Kapitan that: namespace should take the same value defined in target_name target_name should take the literal string dev application.location should take the same value as defined in cluster.location It is important to notice that the inventory can refer to values defined in other classes, as long as they are imported by the target. So for instance with the following example classes : - project.production parameters : application : location : ${cluster.location} Here in this case application.location refers to a value location which has been defined elsewhere, perhaps (but not necessarily) in the project.production class. Also notice that the class name ( project.production ) is not in any ways influencing the name or the structed of the yaml it imports into the file","title":"Parameters Interpolation"},{"location":"pages/inventory/parameters_interpolation/#parameters-interpolation","text":"Note as a shorthand, when we encounter deep yaml structures like the following: parameters : components : nginx : image : nginx:latest Usually when we want to talk about the image subkey, we normally use either of the following: parameters.components.nginx.image components.nginx.image However, when used in parameter expansion, remember to: replace the . with : omit the parameters initial key which is implied wrap it into the ${} variable interpolation syntax The correct way to reference parameters.nginx.image then becomes ${components:nginx:image} . The Inventory allows you to refer to other values defined elsewhere in the structure, using parameter interpolation. Given the example: parameters : cluster : location : europe application : location : ${cluster:location} namespace : ${target_name} target_name : dev Here we tell Kapitan that: namespace should take the same value defined in target_name target_name should take the literal string dev application.location should take the same value as defined in cluster.location It is important to notice that the inventory can refer to values defined in other classes, as long as they are imported by the target. So for instance with the following example classes : - project.production parameters : application : location : ${cluster.location} Here in this case application.location refers to a value location which has been defined elsewhere, perhaps (but not necessarily) in the project.production class. Also notice that the class name ( project.production ) is not in any ways influencing the name or the structed of the yaml it imports into the file","title":"Parameters Interpolation"},{"location":"pages/inventory/targets/","text":"Targets Usage A target is a file that lives under the inventory/targets subdirectory, and that tells Kapitan what you want it to do for you. Kapitan will recognise all YAML files in the inventory/targets subtree as targets. Note Only use .yml as extension for Inventory files. .yaml will not be recognised as a valid Inventory file. What you do with a target is largely up to you and your setup. Common examples: clusters : Map each target to a cluster, capturing all configurations needed for a given cluster. For instance: targets/clusters/production-cluster1.yml applications : When using Kapitan to manage Kubernetes applications, you might define a target for everything that you would normally deploy in a single namespace, including all its resources, scripts, secrets and documentation. For instance: targets/mysql.yml environments : You might have want to define a different target for each environment you have, like dev.yml , test.yml and prod.yml cloud projects : When working with Terraform , it may be convenient to group target by cloud project. For instance: targets/gcp/projects/engineering-prod.yml . single tenancy : When deploying a single-tenancy application, you might combine the approaches above, and have a target acme.yml that is used to define both Terraform and Kubernetes resources for a given tenant, perhaps also with some ArgoCD or Spinnaker pipelines to go with it. Example If you have configured your kapitan repository like in Quick Start instructions, you can run the commands we give during the course of this documentation. kapitan compile Compiled gke-pvm-killer ( 0 .09s ) Compiled vault ( 0 .18s ) Compiled pritunl ( 0 .17s ) Compiled mysql ( 0 .07s ) Compiled examples ( 0 .25s ) Compiled postgres-proxy ( 0 .06s ) Compiled echo-server ( 0 .08s ) Compiled global ( 0 .05s ) Compiled tutorial ( 0 .09s ) Compiled guestbook-argocd ( 0 .08s ) Compiled sock-shop ( 0 .30s ) Compiled kapicorp-demo-march ( 0 .04s ) Compiled kapicorp-project-123 ( 0 .03s ) Compiled kapicorp-terraform-admin ( 0 .08s ) Compiled tesoro ( 0 .09s ) Compiled prod-sockshop ( 0 .34s ) Compiled dev-sockshop ( 0 .41s ) Compiled argocd ( 2 .53s ) When you run kapitan compile , you instruct Kapitan to generate for each given target a directory under compiled with the same name. Under this directory you will find all the files that have been generated by Kapitan for that target. tree compiled/mysql/ compiled/mysql/ \u251c\u2500\u2500 argocd \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 mysql-readme.md \u2502 \u2514\u2500\u2500 README.md \u251c\u2500\u2500 manifests \u2502 \u251c\u2500\u2500 mysql-bundle.yml \u2502 \u251c\u2500\u2500 mysql-config.yml \u2502 \u251c\u2500\u2500 mysql-namespace.yml \u2502 \u2514\u2500\u2500 mysql-secret.yml \u251c\u2500\u2500 pre-deploy \u251c\u2500\u2500 rabbitmq \u251c\u2500\u2500 scripts \u2514\u2500\u2500 terraform 7 directories, 6 files Definition A typical target might look like this: inventory/targets/acme/dev.yaml classes : - common - components.acme.frontend - components.acme.backend parameters : target_name : dev Note that it is made of 2 sections: classes is a list of class files you will want to import. parameters allows for local override of what is unique to this target. Info the kapitan key under the root parameters is reserved for kapitan usage. Some examples: parameters : kapitan : compile : # input types configuration section dependencies : # dependencies configuration section to download resources secrets : # secret encryption/decryption configuration section validate : # items which indicate which compiled output to validate vars : # which are also passed down to input types as context","title":"Targets"},{"location":"pages/inventory/targets/#targets","text":"","title":"Targets"},{"location":"pages/inventory/targets/#usage","text":"A target is a file that lives under the inventory/targets subdirectory, and that tells Kapitan what you want it to do for you. Kapitan will recognise all YAML files in the inventory/targets subtree as targets. Note Only use .yml as extension for Inventory files. .yaml will not be recognised as a valid Inventory file. What you do with a target is largely up to you and your setup. Common examples: clusters : Map each target to a cluster, capturing all configurations needed for a given cluster. For instance: targets/clusters/production-cluster1.yml applications : When using Kapitan to manage Kubernetes applications, you might define a target for everything that you would normally deploy in a single namespace, including all its resources, scripts, secrets and documentation. For instance: targets/mysql.yml environments : You might have want to define a different target for each environment you have, like dev.yml , test.yml and prod.yml cloud projects : When working with Terraform , it may be convenient to group target by cloud project. For instance: targets/gcp/projects/engineering-prod.yml . single tenancy : When deploying a single-tenancy application, you might combine the approaches above, and have a target acme.yml that is used to define both Terraform and Kubernetes resources for a given tenant, perhaps also with some ArgoCD or Spinnaker pipelines to go with it. Example If you have configured your kapitan repository like in Quick Start instructions, you can run the commands we give during the course of this documentation. kapitan compile Compiled gke-pvm-killer ( 0 .09s ) Compiled vault ( 0 .18s ) Compiled pritunl ( 0 .17s ) Compiled mysql ( 0 .07s ) Compiled examples ( 0 .25s ) Compiled postgres-proxy ( 0 .06s ) Compiled echo-server ( 0 .08s ) Compiled global ( 0 .05s ) Compiled tutorial ( 0 .09s ) Compiled guestbook-argocd ( 0 .08s ) Compiled sock-shop ( 0 .30s ) Compiled kapicorp-demo-march ( 0 .04s ) Compiled kapicorp-project-123 ( 0 .03s ) Compiled kapicorp-terraform-admin ( 0 .08s ) Compiled tesoro ( 0 .09s ) Compiled prod-sockshop ( 0 .34s ) Compiled dev-sockshop ( 0 .41s ) Compiled argocd ( 2 .53s ) When you run kapitan compile , you instruct Kapitan to generate for each given target a directory under compiled with the same name. Under this directory you will find all the files that have been generated by Kapitan for that target. tree compiled/mysql/ compiled/mysql/ \u251c\u2500\u2500 argocd \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 mysql-readme.md \u2502 \u2514\u2500\u2500 README.md \u251c\u2500\u2500 manifests \u2502 \u251c\u2500\u2500 mysql-bundle.yml \u2502 \u251c\u2500\u2500 mysql-config.yml \u2502 \u251c\u2500\u2500 mysql-namespace.yml \u2502 \u2514\u2500\u2500 mysql-secret.yml \u251c\u2500\u2500 pre-deploy \u251c\u2500\u2500 rabbitmq \u251c\u2500\u2500 scripts \u2514\u2500\u2500 terraform 7 directories, 6 files","title":"Usage"},{"location":"pages/inventory/targets/#definition","text":"A typical target might look like this: inventory/targets/acme/dev.yaml classes : - common - components.acme.frontend - components.acme.backend parameters : target_name : dev Note that it is made of 2 sections: classes is a list of class files you will want to import. parameters allows for local override of what is unique to this target. Info the kapitan key under the root parameters is reserved for kapitan usage. Some examples: parameters : kapitan : compile : # input types configuration section dependencies : # dependencies configuration section to download resources secrets : # secret encryption/decryption configuration section validate : # items which indicate which compiled output to validate vars : # which are also passed down to input types as context","title":"Definition"},{"location":"tags/","text":"community Proposals Kapitan Code Documentation Sponsor Us kadet Kadet kubernetes Kadet Kubernetes terraform Terraform","title":"Tags"},{"location":"tags/#community","text":"Proposals Kapitan Code Documentation Sponsor Us","title":"community"},{"location":"tags/#kadet","text":"Kadet","title":"kadet"},{"location":"tags/#kubernetes","text":"Kadet Kubernetes","title":"kubernetes"},{"location":"tags/#terraform","text":"Terraform","title":"terraform"}]}